{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transfer_Model_Utils import *\n",
    "from tensorflow.keras.models import load_model\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalizationV1 (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_1 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 106,544\n",
      "Trainable params: 105,808\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pavia_50 = load_model('..\\\\..\\\\Trained Models\\\\Sub_Model\\\\Pavia\\\\Sub_model_Transfer_Pavia_overlap_ratio_50_percent.h5')\n",
    "model_pavia_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalizationV1 (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_1 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fc_256 (Dense)                  (None, 256)          16640       global_max_pooling3d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fc9 (Dense)                     (None, 9)            2313        fc_256[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 125,497\n",
      "Trainable params: 124,761\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pavia_50_F = load_model('..\\\\..\\\\Trained Models\\\\Full_Model\\\\Pavia\\\\Full_Model_best_Pavia_overlap_ratio_50_percent.h5')\n",
    "model_pavia_50_F.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 217, 204) (512, 217)\n",
      "(204, 512, 217) (512, 217)\n"
     ]
    }
   ],
   "source": [
    "uSalinas = sio.loadmat('C:\\\\Users\\\\de991521\\\\Desktop\\\\EE_297_PROJECT\\\\Salinas\\\\Salinas_corrected.mat')\n",
    "gt_uSalinas = sio.loadmat('C:\\\\Users\\\\de991521\\\\Desktop\\\\EE_297_PROJECT\\\\Salinas\\\\Salinas_gt.mat')\n",
    "data_SA = uSalinas['salinas_corrected']\n",
    "gt_SA = gt_uSalinas['salinas_gt']\n",
    "print(data_SA.shape, gt_SA.shape)\n",
    "data_SA = np.moveaxis(data_SA, 2, 0)\n",
    "print(data_SA.shape, gt_SA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16] [56975  2009  3726  1976  1394  2678  3959  3579 11271  6203  3278  1068\n",
      "  1927   916  1070  7268  1807]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values,counts = np.unique(gt_SA, return_counts=True)\n",
    "print(values,counts)\n",
    "range_of_class = list(values)\n",
    "if 0 in range_of_class:\n",
    "    range_of_class.pop(0)\n",
    "range_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples per class: [15, 32, 17, 14, 26, 35, 30, 80, 51, 27, 10, 17, 9, 10, 47, 9], Total number of samples is 429.\n",
      "\n",
      "unique classes in Ytest: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16], Total number of samples in Ytest is 91.\n",
      "number of samples per class in Ytest: [ 3  7  4  3  6  7  6 16 11  6  2  4  2  2 10  2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overlap_ratio = 50 / 100\n",
    "Xtrain, Xtest, Ytrain, Ytest, class_len, counts = prepare_data_for_training(range_of_class=range_of_class,\n",
    "                                                                            Cube_size=25, Data=data_SA,\n",
    "                                                                            Gt=gt_SA, small_segmented_1=[],\n",
    "                                                                            small_seg_gt_1=[], percentage=80,\n",
    "                                                                            overlap_ratio=overlap_ratio, ch=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain => (338, 103, 24, 24, 1)\n",
      "Xtest  => (91, 103, 24, 24, 1)\n",
      "Ytrain => (338, 16)\n",
      "Ytest  => (91, 16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Xtrain => ' + str(Xtrain.shape) + '\\n' +\n",
    "      'Xtest  => ' + str(Xtest.shape) + '\\n' +\n",
    "      'Ytrain => ' + str(Ytrain.shape) + '\\n' +\n",
    "      'Ytest  => ' + str(Ytest.shape) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_transfer = model_pavia_50.predict(Xtrain)\n",
    "Xtest_transfer = model_pavia_50.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain => (338, 64)\n",
      "Xtest  => (91, 64)\n",
      "Ytrain => (338, 16)\n",
      "Ytest  => (91, 16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Xtrain => ' + str(Xtrain_transfer.shape) + '\\n' +\n",
    "      'Xtest  => ' + str(Xtest_transfer.shape) + '\\n' +\n",
    "      'Ytrain => ' + str(Ytrain.shape) + '\\n' +\n",
    "      'Ytest  => ' + str(Ytest.shape) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_transfer(input_shape=(64), classes=9):\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Dense(256, input_dim=X_input.shape, activation='relu', name='fc_256',\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X_input)\n",
    "    X = Dense(classes, input_dim=X.shape, activation='softmax', name='fc' + str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    model = Model(inputs=X_input, outputs=X, name=\"model_transfer\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc_256 (Dense)               (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "fc16 (Dense)                 (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 20,752\n",
      "Trainable params: 20,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = model_transfer(input_shape=Xtrain_transfer[0].shape, classes=len(range_of_class))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source_data_name= 'Pavia44'\n",
    "Target_data_name='Pavia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 338 samples, validate on 91 samples\n",
      "Epoch 1/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 6.1136 - categorical_accuracy: 0.2105\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.17582, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 1s 4ms/sample - loss: 6.0139 - categorical_accuracy: 0.2041 - val_loss: 3.8717 - val_categorical_accuracy: 0.1758\n",
      "Epoch 2/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 3.5076 - categorical_accuracy: 0.1840\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.17582\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 3.5272 - categorical_accuracy: 0.2071 - val_loss: 3.3918 - val_categorical_accuracy: 0.1209\n",
      "Epoch 3/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 3.3428 - categorical_accuracy: 0.2961\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.17582 to 0.26374, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 299us/sample - loss: 3.2701 - categorical_accuracy: 0.3077 - val_loss: 3.1226 - val_categorical_accuracy: 0.2637\n",
      "Epoch 4/300\n",
      "272/338 [=======================>......] - ETA: 0s - loss: 3.1433 - categorical_accuracy: 0.3051\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.26374 to 0.30769, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 308us/sample - loss: 3.1488 - categorical_accuracy: 0.3195 - val_loss: 3.0172 - val_categorical_accuracy: 0.3077\n",
      "Epoch 5/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 3.0437 - categorical_accuracy: 0.3191\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.30769\n",
      "338/338 [==============================] - 0s 234us/sample - loss: 3.0533 - categorical_accuracy: 0.3225 - val_loss: 2.8931 - val_categorical_accuracy: 0.3077\n",
      "Epoch 6/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 3.0395 - categorical_accuracy: 0.3684\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.30769\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 2.9526 - categorical_accuracy: 0.3580 - val_loss: 2.9221 - val_categorical_accuracy: 0.2527\n",
      "Epoch 7/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.8395 - categorical_accuracy: 0.3656\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.30769 to 0.31868, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 299us/sample - loss: 2.9088 - categorical_accuracy: 0.3669 - val_loss: 2.8331 - val_categorical_accuracy: 0.3187\n",
      "Epoch 8/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.8424 - categorical_accuracy: 0.3661\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.31868 to 0.36264, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 281us/sample - loss: 2.8425 - categorical_accuracy: 0.3669 - val_loss: 2.7807 - val_categorical_accuracy: 0.3626\n",
      "Epoch 9/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.8114 - categorical_accuracy: 0.4167\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.36264 to 0.43956, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 287us/sample - loss: 2.8025 - categorical_accuracy: 0.4172 - val_loss: 2.8003 - val_categorical_accuracy: 0.4396\n",
      "Epoch 10/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 2.8003 - categorical_accuracy: 0.4271\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.43956\n",
      "338/338 [==============================] - 0s 231us/sample - loss: 2.7854 - categorical_accuracy: 0.4290 - val_loss: 2.7419 - val_categorical_accuracy: 0.4066\n",
      "Epoch 11/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.6527 - categorical_accuracy: 0.4156\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.43956\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 2.7043 - categorical_accuracy: 0.4142 - val_loss: 2.6626 - val_categorical_accuracy: 0.3956\n",
      "Epoch 12/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 2.6653 - categorical_accuracy: 0.4671\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.43956 to 0.47253, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 296us/sample - loss: 2.6446 - categorical_accuracy: 0.4675 - val_loss: 2.6223 - val_categorical_accuracy: 0.4725\n",
      "Epoch 13/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.4891 - categorical_accuracy: 0.4719\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.47253\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 2.6145 - categorical_accuracy: 0.4645 - val_loss: 2.6081 - val_categorical_accuracy: 0.3956\n",
      "Epoch 14/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 2.5441 - categorical_accuracy: 0.4704\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.47253\n",
      "338/338 [==============================] - 0s 249us/sample - loss: 2.6031 - categorical_accuracy: 0.4586 - val_loss: 2.5725 - val_categorical_accuracy: 0.3846\n",
      "Epoch 15/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 2.5427 - categorical_accuracy: 0.4722\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.47253\n",
      "338/338 [==============================] - 0s 237us/sample - loss: 2.5607 - categorical_accuracy: 0.4645 - val_loss: 2.5466 - val_categorical_accuracy: 0.4066\n",
      "Epoch 16/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.5257 - categorical_accuracy: 0.4812\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.47253\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 2.5140 - categorical_accuracy: 0.4852 - val_loss: 2.6331 - val_categorical_accuracy: 0.4066\n",
      "Epoch 17/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 2.5956 - categorical_accuracy: 0.4671\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.47253\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 2.5341 - categorical_accuracy: 0.4734 - val_loss: 2.5179 - val_categorical_accuracy: 0.4725\n",
      "Epoch 18/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.4432 - categorical_accuracy: 0.5000\n",
      "Epoch 00018: val_categorical_accuracy improved from 0.47253 to 0.50549, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 290us/sample - loss: 2.5208 - categorical_accuracy: 0.4970 - val_loss: 2.4343 - val_categorical_accuracy: 0.5055\n",
      "Epoch 19/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.3903 - categorical_accuracy: 0.5000\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.50549\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 2.4252 - categorical_accuracy: 0.5000 - val_loss: 2.4238 - val_categorical_accuracy: 0.5055\n",
      "Epoch 20/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.4206 - categorical_accuracy: 0.5089\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.50549\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 2.4111 - categorical_accuracy: 0.5118 - val_loss: 2.4114 - val_categorical_accuracy: 0.5055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 2.4759 - categorical_accuracy: 0.5000\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.50549\n",
      "338/338 [==============================] - 0s 252us/sample - loss: 2.4220 - categorical_accuracy: 0.5118 - val_loss: 2.4102 - val_categorical_accuracy: 0.4835\n",
      "Epoch 22/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 2.3906 - categorical_accuracy: 0.5362\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.50549\n",
      "338/338 [==============================] - 0s 234us/sample - loss: 2.3659 - categorical_accuracy: 0.5355 - val_loss: 2.3545 - val_categorical_accuracy: 0.4945\n",
      "Epoch 23/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.3461 - categorical_accuracy: 0.5268\n",
      "Epoch 00023: val_categorical_accuracy improved from 0.50549 to 0.52747, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 278us/sample - loss: 2.3356 - categorical_accuracy: 0.5296 - val_loss: 2.3679 - val_categorical_accuracy: 0.5275\n",
      "Epoch 24/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.3812 - categorical_accuracy: 0.5469\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.52747\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 2.3333 - categorical_accuracy: 0.5473 - val_loss: 2.3710 - val_categorical_accuracy: 0.4835\n",
      "Epoch 25/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.2661 - categorical_accuracy: 0.5536\n",
      "Epoch 00025: val_categorical_accuracy improved from 0.52747 to 0.53846, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 284us/sample - loss: 2.3038 - categorical_accuracy: 0.5503 - val_loss: 2.3543 - val_categorical_accuracy: 0.5385\n",
      "Epoch 26/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.3157 - categorical_accuracy: 0.5344\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.53846\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 2.2854 - categorical_accuracy: 0.5237 - val_loss: 2.3198 - val_categorical_accuracy: 0.5275\n",
      "Epoch 27/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.3560 - categorical_accuracy: 0.5500\n",
      "Epoch 00027: val_categorical_accuracy improved from 0.53846 to 0.54945, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 299us/sample - loss: 2.3180 - categorical_accuracy: 0.5562 - val_loss: 2.2977 - val_categorical_accuracy: 0.5495\n",
      "Epoch 28/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 2.2672 - categorical_accuracy: 0.5493\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.54945\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 2.2463 - categorical_accuracy: 0.5621 - val_loss: 2.2672 - val_categorical_accuracy: 0.5275\n",
      "Epoch 29/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.2258 - categorical_accuracy: 0.5594\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.54945\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 2.2281 - categorical_accuracy: 0.5562 - val_loss: 2.2732 - val_categorical_accuracy: 0.5275\n",
      "Epoch 30/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.1821 - categorical_accuracy: 0.5469\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.54945\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 2.2225 - categorical_accuracy: 0.5355 - val_loss: 2.2475 - val_categorical_accuracy: 0.5385\n",
      "Epoch 31/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.2599 - categorical_accuracy: 0.5688\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.54945\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 2.2015 - categorical_accuracy: 0.5680 - val_loss: 2.2847 - val_categorical_accuracy: 0.4945\n",
      "Epoch 32/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.2048 - categorical_accuracy: 0.5446\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.54945\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 2.1953 - categorical_accuracy: 0.5473 - val_loss: 2.2774 - val_categorical_accuracy: 0.5275\n",
      "Epoch 33/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.1855 - categorical_accuracy: 0.5744\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.54945\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 2.1759 - categorical_accuracy: 0.5769 - val_loss: 2.2217 - val_categorical_accuracy: 0.5275\n",
      "Epoch 34/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.2037 - categorical_accuracy: 0.5625\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.54945\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 2.1501 - categorical_accuracy: 0.5680 - val_loss: 2.2526 - val_categorical_accuracy: 0.5385\n",
      "Epoch 35/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.0272 - categorical_accuracy: 0.5844\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.54945\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 2.1542 - categorical_accuracy: 0.5858 - val_loss: 2.2479 - val_categorical_accuracy: 0.5165\n",
      "Epoch 36/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.1513 - categorical_accuracy: 0.5833\n",
      "Epoch 00036: val_categorical_accuracy improved from 0.54945 to 0.57143, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 272us/sample - loss: 2.1437 - categorical_accuracy: 0.5858 - val_loss: 2.1857 - val_categorical_accuracy: 0.5714\n",
      "Epoch 37/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.0470 - categorical_accuracy: 0.6000\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.57143\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 2.1296 - categorical_accuracy: 0.5947 - val_loss: 2.2379 - val_categorical_accuracy: 0.5165\n",
      "Epoch 38/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.2088 - categorical_accuracy: 0.5656\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.57143\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 2.1337 - categorical_accuracy: 0.5740 - val_loss: 2.1831 - val_categorical_accuracy: 0.5604\n",
      "Epoch 39/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.0878 - categorical_accuracy: 0.6161\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.57143\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 2.0867 - categorical_accuracy: 0.6124 - val_loss: 2.1729 - val_categorical_accuracy: 0.5385\n",
      "Epoch 40/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 2.0172 - categorical_accuracy: 0.7500\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.57143\n",
      "338/338 [==============================] - 0s 189us/sample - loss: 2.0895 - categorical_accuracy: 0.6065 - val_loss: 2.1861 - val_categorical_accuracy: 0.5275\n",
      "Epoch 41/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 2.1377 - categorical_accuracy: 0.5000\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.57143\n",
      "338/338 [==============================] - 0s 189us/sample - loss: 2.0757 - categorical_accuracy: 0.6036 - val_loss: 2.1539 - val_categorical_accuracy: 0.5165\n",
      "Epoch 42/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.8905 - categorical_accuracy: 0.6250\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.57143\n",
      "338/338 [==============================] - 0s 195us/sample - loss: 2.0627 - categorical_accuracy: 0.6213 - val_loss: 2.1357 - val_categorical_accuracy: 0.5495\n",
      "Epoch 43/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/338 [============================>.] - ETA: 0s - loss: 2.0739 - categorical_accuracy: 0.6280\n",
      "Epoch 00043: val_categorical_accuracy improved from 0.57143 to 0.58242, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 272us/sample - loss: 2.0659 - categorical_accuracy: 0.6272 - val_loss: 2.1705 - val_categorical_accuracy: 0.5824\n",
      "Epoch 44/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 2.1020 - categorical_accuracy: 0.6217\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 2.0724 - categorical_accuracy: 0.6243 - val_loss: 2.1605 - val_categorical_accuracy: 0.5385\n",
      "Epoch 45/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 2.1049 - categorical_accuracy: 0.6217\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 2.0243 - categorical_accuracy: 0.6302 - val_loss: 2.1450 - val_categorical_accuracy: 0.5275\n",
      "Epoch 46/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.0474 - categorical_accuracy: 0.6438\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 2.0290 - categorical_accuracy: 0.6420 - val_loss: 2.1508 - val_categorical_accuracy: 0.5495\n",
      "Epoch 47/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.0153 - categorical_accuracy: 0.6429\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 2.0142 - categorical_accuracy: 0.6420 - val_loss: 2.1414 - val_categorical_accuracy: 0.5495\n",
      "Epoch 48/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.9321 - categorical_accuracy: 0.6086\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 2.0150 - categorical_accuracy: 0.6065 - val_loss: 2.1458 - val_categorical_accuracy: 0.5824\n",
      "Epoch 49/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 2.0938 - categorical_accuracy: 0.6579\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 2.0101 - categorical_accuracy: 0.6538 - val_loss: 2.0987 - val_categorical_accuracy: 0.5604\n",
      "Epoch 50/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.9938 - categorical_accuracy: 0.6656\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.9799 - categorical_accuracy: 0.6657 - val_loss: 2.1203 - val_categorical_accuracy: 0.5824\n",
      "Epoch 51/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.9883 - categorical_accuracy: 0.6577\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.9798 - categorical_accuracy: 0.6598 - val_loss: 2.2208 - val_categorical_accuracy: 0.5495\n",
      "Epoch 52/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 2.0411 - categorical_accuracy: 0.6250\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 2.0203 - categorical_accuracy: 0.6302 - val_loss: 2.1069 - val_categorical_accuracy: 0.5824\n",
      "Epoch 53/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.9638 - categorical_accuracy: 0.6607\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.9546 - categorical_accuracy: 0.6627 - val_loss: 2.0696 - val_categorical_accuracy: 0.5824\n",
      "Epoch 54/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.9629 - categorical_accuracy: 0.6607\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.9555 - categorical_accuracy: 0.6598 - val_loss: 2.0572 - val_categorical_accuracy: 0.5714\n",
      "Epoch 55/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.5997 - categorical_accuracy: 0.8125\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.58242\n",
      "338/338 [==============================] - 0s 195us/sample - loss: 1.9397 - categorical_accuracy: 0.6746 - val_loss: 2.1007 - val_categorical_accuracy: 0.5275\n",
      "Epoch 56/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.9462 - categorical_accuracy: 0.4375\n",
      "Epoch 00056: val_categorical_accuracy improved from 0.58242 to 0.60440, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 252us/sample - loss: 1.9549 - categorical_accuracy: 0.6657 - val_loss: 2.0509 - val_categorical_accuracy: 0.6044\n",
      "Epoch 57/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.9033 - categorical_accuracy: 0.6488\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.60440\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.9430 - categorical_accuracy: 0.6479 - val_loss: 2.1054 - val_categorical_accuracy: 0.5604\n",
      "Epoch 58/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.9151 - categorical_accuracy: 0.6518\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.60440\n",
      "338/338 [==============================] - 0s 201us/sample - loss: 1.9569 - categorical_accuracy: 0.6479 - val_loss: 2.0525 - val_categorical_accuracy: 0.5714\n",
      "Epoch 59/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.9270 - categorical_accuracy: 0.6750\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.60440\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.9278 - categorical_accuracy: 0.6686 - val_loss: 2.0572 - val_categorical_accuracy: 0.5604\n",
      "Epoch 60/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.9412 - categorical_accuracy: 0.6809\n",
      "Epoch 00060: val_categorical_accuracy improved from 0.60440 to 0.61538, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 275us/sample - loss: 1.9208 - categorical_accuracy: 0.6834 - val_loss: 2.0440 - val_categorical_accuracy: 0.6154\n",
      "Epoch 61/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.8449 - categorical_accuracy: 0.6812\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.9114 - categorical_accuracy: 0.6864 - val_loss: 2.0603 - val_categorical_accuracy: 0.5714\n",
      "Epoch 62/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.8984 - categorical_accuracy: 0.6845\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.8955 - categorical_accuracy: 0.6805 - val_loss: 2.0504 - val_categorical_accuracy: 0.5824\n",
      "Epoch 63/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 2.0323 - categorical_accuracy: 0.6429\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 2.0229 - categorical_accuracy: 0.6450 - val_loss: 2.0599 - val_categorical_accuracy: 0.5824\n",
      "Epoch 64/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.7631 - categorical_accuracy: 0.7500\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 189us/sample - loss: 1.9023 - categorical_accuracy: 0.6893 - val_loss: 2.0206 - val_categorical_accuracy: 0.5495\n",
      "Epoch 65/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.6058 - categorical_accuracy: 0.7500\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 192us/sample - loss: 1.8763 - categorical_accuracy: 0.7041 - val_loss: 2.0537 - val_categorical_accuracy: 0.5604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.8849 - categorical_accuracy: 0.7083\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.8794 - categorical_accuracy: 0.7071 - val_loss: 2.0442 - val_categorical_accuracy: 0.5934\n",
      "Epoch 67/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.8894 - categorical_accuracy: 0.6844\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.8917 - categorical_accuracy: 0.6686 - val_loss: 2.0234 - val_categorical_accuracy: 0.5714\n",
      "Epoch 68/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.8704 - categorical_accuracy: 0.7143\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.8627 - categorical_accuracy: 0.7160 - val_loss: 2.0098 - val_categorical_accuracy: 0.5934\n",
      "Epoch 69/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.8258 - categorical_accuracy: 0.6875\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.8607 - categorical_accuracy: 0.6834 - val_loss: 2.0022 - val_categorical_accuracy: 0.6044\n",
      "Epoch 70/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.8276 - categorical_accuracy: 0.7125\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.8634 - categorical_accuracy: 0.7101 - val_loss: 1.9952 - val_categorical_accuracy: 0.5934\n",
      "Epoch 71/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.9749 - categorical_accuracy: 0.7138\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.8466 - categorical_accuracy: 0.7189 - val_loss: 2.0054 - val_categorical_accuracy: 0.5495\n",
      "Epoch 72/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.8592 - categorical_accuracy: 0.6994\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.8531 - categorical_accuracy: 0.7012 - val_loss: 2.0521 - val_categorical_accuracy: 0.5714\n",
      "Epoch 73/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.8122 - categorical_accuracy: 0.6875\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 184us/sample - loss: 1.8571 - categorical_accuracy: 0.6657 - val_loss: 2.0318 - val_categorical_accuracy: 0.5714\n",
      "Epoch 74/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.6333 - categorical_accuracy: 0.8125\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 195us/sample - loss: 1.8612 - categorical_accuracy: 0.7189 - val_loss: 2.0194 - val_categorical_accuracy: 0.5934\n",
      "Epoch 75/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 3.5229 - categorical_accuracy: 0.7500\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 192us/sample - loss: 1.8435 - categorical_accuracy: 0.6953 - val_loss: 1.9899 - val_categorical_accuracy: 0.5824\n",
      "Epoch 76/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.6882 - categorical_accuracy: 0.8125\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 189us/sample - loss: 1.8331 - categorical_accuracy: 0.7130 - val_loss: 1.9740 - val_categorical_accuracy: 0.6044\n",
      "Epoch 77/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.8203 - categorical_accuracy: 0.7530\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.8108 - categorical_accuracy: 0.7544 - val_loss: 2.0125 - val_categorical_accuracy: 0.5714\n",
      "Epoch 78/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6822 - categorical_accuracy: 0.7250\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.8170 - categorical_accuracy: 0.7130 - val_loss: 1.9706 - val_categorical_accuracy: 0.5824\n",
      "Epoch 79/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.8320 - categorical_accuracy: 0.7469\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.8163 - categorical_accuracy: 0.7485 - val_loss: 1.9764 - val_categorical_accuracy: 0.5934\n",
      "Epoch 80/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7717 - categorical_accuracy: 0.7173\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.8098 - categorical_accuracy: 0.7160 - val_loss: 1.9579 - val_categorical_accuracy: 0.6044\n",
      "Epoch 81/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.8219 - categorical_accuracy: 0.7094\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.8025 - categorical_accuracy: 0.7130 - val_loss: 2.0218 - val_categorical_accuracy: 0.5714\n",
      "Epoch 82/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.8729 - categorical_accuracy: 0.7250\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.8176 - categorical_accuracy: 0.7249 - val_loss: 1.9869 - val_categorical_accuracy: 0.5934\n",
      "Epoch 83/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.6223 - categorical_accuracy: 0.7500\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 187us/sample - loss: 1.8103 - categorical_accuracy: 0.7130 - val_loss: 1.9577 - val_categorical_accuracy: 0.6044\n",
      "Epoch 84/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7916 - categorical_accuracy: 0.7500\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.7826 - categorical_accuracy: 0.7515 - val_loss: 1.9648 - val_categorical_accuracy: 0.5824\n",
      "Epoch 85/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.8509 - categorical_accuracy: 0.7219\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.7908 - categorical_accuracy: 0.7160 - val_loss: 1.9999 - val_categorical_accuracy: 0.6044\n",
      "Epoch 86/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.8067 - categorical_accuracy: 0.7281\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.7837 - categorical_accuracy: 0.7396 - val_loss: 1.9736 - val_categorical_accuracy: 0.5824\n",
      "Epoch 87/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7847 - categorical_accuracy: 0.7470\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.7788 - categorical_accuracy: 0.7485 - val_loss: 1.9745 - val_categorical_accuracy: 0.6044\n",
      "Epoch 88/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.8202 - categorical_accuracy: 0.7202\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.8122 - categorical_accuracy: 0.7219 - val_loss: 1.9464 - val_categorical_accuracy: 0.5714\n",
      "Epoch 89/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7746 - categorical_accuracy: 0.7202\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.7695 - categorical_accuracy: 0.7189 - val_loss: 1.9576 - val_categorical_accuracy: 0.5934\n",
      "Epoch 90/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.8278 - categorical_accuracy: 0.7500\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.7674 - categorical_accuracy: 0.7515 - val_loss: 1.9483 - val_categorical_accuracy: 0.5934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.8339 - categorical_accuracy: 0.7237\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 1.7652 - categorical_accuracy: 0.7367 - val_loss: 1.9652 - val_categorical_accuracy: 0.6044\n",
      "Epoch 92/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.5398 - categorical_accuracy: 0.6875\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 198us/sample - loss: 1.8131 - categorical_accuracy: 0.7249 - val_loss: 1.9218 - val_categorical_accuracy: 0.6044\n",
      "Epoch 93/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.6271 - categorical_accuracy: 0.7401\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 231us/sample - loss: 1.7629 - categorical_accuracy: 0.7367 - val_loss: 1.9283 - val_categorical_accuracy: 0.6044\n",
      "Epoch 94/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.7559 - categorical_accuracy: 0.7656\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.7401 - categorical_accuracy: 0.7633 - val_loss: 2.0300 - val_categorical_accuracy: 0.5385\n",
      "Epoch 95/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7610 - categorical_accuracy: 0.7381\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.7574 - categorical_accuracy: 0.7367 - val_loss: 1.9246 - val_categorical_accuracy: 0.6044\n",
      "Epoch 96/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.8439 - categorical_accuracy: 0.5625\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 189us/sample - loss: 1.7528 - categorical_accuracy: 0.7426 - val_loss: 1.9350 - val_categorical_accuracy: 0.5714\n",
      "Epoch 97/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6928 - categorical_accuracy: 0.7594\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.7376 - categorical_accuracy: 0.7485 - val_loss: 1.9023 - val_categorical_accuracy: 0.6154\n",
      "Epoch 98/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.7311 - categorical_accuracy: 0.7375\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.7615 - categorical_accuracy: 0.7396 - val_loss: 1.9193 - val_categorical_accuracy: 0.6044\n",
      "Epoch 99/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7467 - categorical_accuracy: 0.7530\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 204us/sample - loss: 1.7426 - categorical_accuracy: 0.7544 - val_loss: 1.9241 - val_categorical_accuracy: 0.6154\n",
      "Epoch 100/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6971 - categorical_accuracy: 0.7469\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.7313 - categorical_accuracy: 0.7426 - val_loss: 1.9604 - val_categorical_accuracy: 0.5934\n",
      "Epoch 101/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6794 - categorical_accuracy: 0.7470\n",
      "Epoch 00101: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.7179 - categorical_accuracy: 0.7456 - val_loss: 1.9172 - val_categorical_accuracy: 0.5934\n",
      "Epoch 102/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7177 - categorical_accuracy: 0.7589\n",
      "Epoch 00102: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.7122 - categorical_accuracy: 0.7574 - val_loss: 2.0053 - val_categorical_accuracy: 0.6044\n",
      "Epoch 103/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 2.6097 - categorical_accuracy: 0.7500\n",
      "Epoch 00103: val_categorical_accuracy did not improve from 0.61538\n",
      "338/338 [==============================] - 0s 189us/sample - loss: 1.7243 - categorical_accuracy: 0.7604 - val_loss: 1.9311 - val_categorical_accuracy: 0.6154\n",
      "Epoch 104/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7438 - categorical_accuracy: 0.7321\n",
      "Epoch 00104: val_categorical_accuracy improved from 0.61538 to 0.62637, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 272us/sample - loss: 1.7367 - categorical_accuracy: 0.7337 - val_loss: 1.9566 - val_categorical_accuracy: 0.6264\n",
      "Epoch 105/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.7958 - categorical_accuracy: 0.7312\n",
      "Epoch 00105: val_categorical_accuracy improved from 0.62637 to 0.63736, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 278us/sample - loss: 1.7271 - categorical_accuracy: 0.7367 - val_loss: 1.9038 - val_categorical_accuracy: 0.6374\n",
      "Epoch 106/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7244 - categorical_accuracy: 0.7381\n",
      "Epoch 00106: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.7179 - categorical_accuracy: 0.7396 - val_loss: 1.9104 - val_categorical_accuracy: 0.6154\n",
      "Epoch 107/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.6664 - categorical_accuracy: 0.6250\n",
      "Epoch 00107: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 192us/sample - loss: 1.7076 - categorical_accuracy: 0.7574 - val_loss: 1.9188 - val_categorical_accuracy: 0.6044\n",
      "Epoch 108/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 2.4892 - categorical_accuracy: 0.8125\n",
      "Epoch 00108: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 201us/sample - loss: 1.7166 - categorical_accuracy: 0.7633 - val_loss: 1.8858 - val_categorical_accuracy: 0.6264\n",
      "Epoch 109/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 3.2876 - categorical_accuracy: 0.8125\n",
      "Epoch 00109: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 189us/sample - loss: 1.7130 - categorical_accuracy: 0.7367 - val_loss: 1.9027 - val_categorical_accuracy: 0.6044\n",
      "Epoch 110/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.7682 - categorical_accuracy: 0.7437\n",
      "Epoch 00110: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.7098 - categorical_accuracy: 0.7485 - val_loss: 1.9144 - val_categorical_accuracy: 0.6154\n",
      "Epoch 111/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6644 - categorical_accuracy: 0.7500\n",
      "Epoch 00111: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.7053 - categorical_accuracy: 0.7485 - val_loss: 1.9384 - val_categorical_accuracy: 0.5934\n",
      "Epoch 112/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7292 - categorical_accuracy: 0.7560\n",
      "Epoch 00112: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.7217 - categorical_accuracy: 0.7574 - val_loss: 1.9140 - val_categorical_accuracy: 0.5934\n",
      "Epoch 113/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7033 - categorical_accuracy: 0.7440\n",
      "Epoch 00113: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 204us/sample - loss: 1.6993 - categorical_accuracy: 0.7426 - val_loss: 1.8848 - val_categorical_accuracy: 0.6264\n",
      "Epoch 114/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/338 [============================>.] - ETA: 0s - loss: 1.7145 - categorical_accuracy: 0.7649\n",
      "Epoch 00114: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 204us/sample - loss: 1.7071 - categorical_accuracy: 0.7663 - val_loss: 1.8899 - val_categorical_accuracy: 0.6264\n",
      "Epoch 115/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6867 - categorical_accuracy: 0.7619\n",
      "Epoch 00115: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.6795 - categorical_accuracy: 0.7633 - val_loss: 1.8932 - val_categorical_accuracy: 0.6264\n",
      "Epoch 116/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.7441 - categorical_accuracy: 0.7625\n",
      "Epoch 00116: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.6798 - categorical_accuracy: 0.7722 - val_loss: 1.8716 - val_categorical_accuracy: 0.6374\n",
      "Epoch 117/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6764 - categorical_accuracy: 0.7768\n",
      "Epoch 00117: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.6703 - categorical_accuracy: 0.7781 - val_loss: 1.8687 - val_categorical_accuracy: 0.6374\n",
      "Epoch 118/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.8750\n",
      "Epoch 00118: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 192us/sample - loss: 1.6879 - categorical_accuracy: 0.7781 - val_loss: 1.9010 - val_categorical_accuracy: 0.5824\n",
      "Epoch 119/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5999 - categorical_accuracy: 0.7750\n",
      "Epoch 00119: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.6757 - categorical_accuracy: 0.7751 - val_loss: 1.8974 - val_categorical_accuracy: 0.5824\n",
      "Epoch 120/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6738 - categorical_accuracy: 0.7619\n",
      "Epoch 00120: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 204us/sample - loss: 1.6703 - categorical_accuracy: 0.7604 - val_loss: 1.8631 - val_categorical_accuracy: 0.6374\n",
      "Epoch 121/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.7012 - categorical_accuracy: 0.7563\n",
      "Epoch 00121: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.6911 - categorical_accuracy: 0.7604 - val_loss: 1.8894 - val_categorical_accuracy: 0.5934\n",
      "Epoch 122/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.4285 - categorical_accuracy: 0.8750\n",
      "Epoch 00122: val_categorical_accuracy did not improve from 0.63736\n",
      "338/338 [==============================] - 0s 195us/sample - loss: 1.6618 - categorical_accuracy: 0.7781 - val_loss: 1.9939 - val_categorical_accuracy: 0.5934\n",
      "Epoch 123/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6402 - categorical_accuracy: 0.7594\n",
      "Epoch 00123: val_categorical_accuracy improved from 0.63736 to 0.64835, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 290us/sample - loss: 1.6744 - categorical_accuracy: 0.7604 - val_loss: 1.8682 - val_categorical_accuracy: 0.6484\n",
      "Epoch 124/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.7014 - categorical_accuracy: 0.7594\n",
      "Epoch 00124: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.6883 - categorical_accuracy: 0.7574 - val_loss: 1.9313 - val_categorical_accuracy: 0.5495\n",
      "Epoch 125/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.7410 - categorical_accuracy: 0.7232\n",
      "Epoch 00125: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.7332 - categorical_accuracy: 0.7249 - val_loss: 1.9015 - val_categorical_accuracy: 0.6154\n",
      "Epoch 126/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6561 - categorical_accuracy: 0.7827\n",
      "Epoch 00126: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.6510 - categorical_accuracy: 0.7811 - val_loss: 1.9497 - val_categorical_accuracy: 0.5824\n",
      "Epoch 127/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6945 - categorical_accuracy: 0.7351\n",
      "Epoch 00127: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.6879 - categorical_accuracy: 0.7367 - val_loss: 1.8920 - val_categorical_accuracy: 0.6154\n",
      "Epoch 128/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 2.4753 - categorical_accuracy: 0.7500\n",
      "Epoch 00128: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 189us/sample - loss: 1.6590 - categorical_accuracy: 0.7663 - val_loss: 1.9063 - val_categorical_accuracy: 0.6044\n",
      "Epoch 129/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6686 - categorical_accuracy: 0.7857\n",
      "Epoch 00129: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.6650 - categorical_accuracy: 0.7840 - val_loss: 1.8845 - val_categorical_accuracy: 0.6044\n",
      "Epoch 130/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6755 - categorical_accuracy: 0.7679\n",
      "Epoch 00130: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.6662 - categorical_accuracy: 0.7692 - val_loss: 1.9262 - val_categorical_accuracy: 0.6044\n",
      "Epoch 131/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 3.3376 - categorical_accuracy: 0.7500\n",
      "Epoch 00131: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 192us/sample - loss: 1.6743 - categorical_accuracy: 0.7604 - val_loss: 1.8846 - val_categorical_accuracy: 0.6154\n",
      "Epoch 132/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6489 - categorical_accuracy: 0.7887\n",
      "Epoch 00132: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.6414 - categorical_accuracy: 0.7899 - val_loss: 1.9085 - val_categorical_accuracy: 0.5824\n",
      "Epoch 133/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.7219 - categorical_accuracy: 0.7719\n",
      "Epoch 00133: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.6489 - categorical_accuracy: 0.7811 - val_loss: 1.8629 - val_categorical_accuracy: 0.6154\n",
      "Epoch 134/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6354 - categorical_accuracy: 0.7976\n",
      "Epoch 00134: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 204us/sample - loss: 1.6335 - categorical_accuracy: 0.7959 - val_loss: 1.9094 - val_categorical_accuracy: 0.5714\n",
      "Epoch 135/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6748 - categorical_accuracy: 0.7656\n",
      "Epoch 00135: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.6600 - categorical_accuracy: 0.7692 - val_loss: 1.8719 - val_categorical_accuracy: 0.6044\n",
      "Epoch 136/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6462 - categorical_accuracy: 0.7679\n",
      "Epoch 00136: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 204us/sample - loss: 1.6373 - categorical_accuracy: 0.7692 - val_loss: 1.8633 - val_categorical_accuracy: 0.6484\n",
      "Epoch 137/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6604 - categorical_accuracy: 0.7470\n",
      "Epoch 00137: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.6553 - categorical_accuracy: 0.7456 - val_loss: 1.8753 - val_categorical_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6527 - categorical_accuracy: 0.7887\n",
      "Epoch 00138: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.6448 - categorical_accuracy: 0.7899 - val_loss: 1.8593 - val_categorical_accuracy: 0.6484\n",
      "Epoch 139/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6456 - categorical_accuracy: 0.7679\n",
      "Epoch 00139: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.6413 - categorical_accuracy: 0.7692 - val_loss: 1.8579 - val_categorical_accuracy: 0.6264\n",
      "Epoch 140/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5138 - categorical_accuracy: 0.7796\n",
      "Epoch 00140: val_categorical_accuracy did not improve from 0.64835\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.6420 - categorical_accuracy: 0.7692 - val_loss: 1.8622 - val_categorical_accuracy: 0.5824\n",
      "Epoch 141/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6397 - categorical_accuracy: 0.7781\n",
      "Epoch 00141: val_categorical_accuracy improved from 0.64835 to 0.65934, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 290us/sample - loss: 1.6285 - categorical_accuracy: 0.7811 - val_loss: 1.8389 - val_categorical_accuracy: 0.6593\n",
      "Epoch 142/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5993 - categorical_accuracy: 0.7906\n",
      "Epoch 00142: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.6271 - categorical_accuracy: 0.7870 - val_loss: 1.8616 - val_categorical_accuracy: 0.6154\n",
      "Epoch 143/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.5892 - categorical_accuracy: 0.8750\n",
      "Epoch 00143: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 195us/sample - loss: 1.6363 - categorical_accuracy: 0.7840 - val_loss: 1.9017 - val_categorical_accuracy: 0.6154\n",
      "Epoch 144/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6427 - categorical_accuracy: 0.7906\n",
      "Epoch 00144: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.6300 - categorical_accuracy: 0.7899 - val_loss: 1.8654 - val_categorical_accuracy: 0.6154\n",
      "Epoch 145/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6229 - categorical_accuracy: 0.7857\n",
      "Epoch 00145: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.6159 - categorical_accuracy: 0.7870 - val_loss: 1.8530 - val_categorical_accuracy: 0.6264\n",
      "Epoch 146/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6787 - categorical_accuracy: 0.7844\n",
      "Epoch 00146: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.6149 - categorical_accuracy: 0.7870 - val_loss: 1.8539 - val_categorical_accuracy: 0.6154\n",
      "Epoch 147/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4786 - categorical_accuracy: 0.7937\n",
      "Epoch 00147: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.6111 - categorical_accuracy: 0.7870 - val_loss: 1.8421 - val_categorical_accuracy: 0.6374\n",
      "Epoch 148/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 2.4061 - categorical_accuracy: 0.7500\n",
      "Epoch 00148: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 192us/sample - loss: 1.6189 - categorical_accuracy: 0.7899 - val_loss: 1.8400 - val_categorical_accuracy: 0.6374\n",
      "Epoch 149/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6250 - categorical_accuracy: 0.7857\n",
      "Epoch 00149: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.6166 - categorical_accuracy: 0.7870 - val_loss: 1.8494 - val_categorical_accuracy: 0.6154\n",
      "Epoch 150/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6097 - categorical_accuracy: 0.7917\n",
      "Epoch 00150: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.6048 - categorical_accuracy: 0.7899 - val_loss: 1.8839 - val_categorical_accuracy: 0.6264\n",
      "Epoch 151/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5768 - categorical_accuracy: 0.8031\n",
      "Epoch 00151: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.6178 - categorical_accuracy: 0.7959 - val_loss: 1.8504 - val_categorical_accuracy: 0.5934\n",
      "Epoch 152/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5762 - categorical_accuracy: 0.7798\n",
      "Epoch 00152: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.6150 - categorical_accuracy: 0.7781 - val_loss: 1.8604 - val_categorical_accuracy: 0.6044\n",
      "Epoch 153/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 3.3906 - categorical_accuracy: 0.8125\n",
      "Epoch 00153: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 198us/sample - loss: 1.6072 - categorical_accuracy: 0.7929 - val_loss: 1.8663 - val_categorical_accuracy: 0.6374\n",
      "Epoch 154/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 2.3716 - categorical_accuracy: 0.7500\n",
      "Epoch 00154: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 189us/sample - loss: 1.6141 - categorical_accuracy: 0.7988 - val_loss: 1.8247 - val_categorical_accuracy: 0.6593\n",
      "Epoch 155/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.4138 - categorical_accuracy: 0.8125\n",
      "Epoch 00155: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 192us/sample - loss: 1.6000 - categorical_accuracy: 0.8077 - val_loss: 1.8584 - val_categorical_accuracy: 0.6044\n",
      "Epoch 156/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6222 - categorical_accuracy: 0.7875\n",
      "Epoch 00156: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.6048 - categorical_accuracy: 0.7929 - val_loss: 1.8373 - val_categorical_accuracy: 0.6374\n",
      "Epoch 157/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6065 - categorical_accuracy: 0.7946\n",
      "Epoch 00157: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.6057 - categorical_accuracy: 0.7929 - val_loss: 1.8275 - val_categorical_accuracy: 0.6374\n",
      "Epoch 158/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 2.3270 - categorical_accuracy: 0.8125\n",
      "Epoch 00158: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 195us/sample - loss: 1.6265 - categorical_accuracy: 0.7722 - val_loss: 1.8311 - val_categorical_accuracy: 0.6264\n",
      "Epoch 159/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6049 - categorical_accuracy: 0.7887\n",
      "Epoch 00159: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.6006 - categorical_accuracy: 0.7840 - val_loss: 1.8561 - val_categorical_accuracy: 0.6593\n",
      "Epoch 160/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.7643 - categorical_accuracy: 0.7895\n",
      "Epoch 00160: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 231us/sample - loss: 1.6313 - categorical_accuracy: 0.7959 - val_loss: 1.8380 - val_categorical_accuracy: 0.6374\n",
      "Epoch 161/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.6056 - categorical_accuracy: 0.7976\n",
      "Epoch 00161: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5998 - categorical_accuracy: 0.7988 - val_loss: 1.8724 - val_categorical_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6053 - categorical_accuracy: 0.7937\n",
      "Epoch 00162: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.5958 - categorical_accuracy: 0.7899 - val_loss: 1.8993 - val_categorical_accuracy: 0.6374\n",
      "Epoch 163/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6179 - categorical_accuracy: 0.7875\n",
      "Epoch 00163: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.6029 - categorical_accuracy: 0.7870 - val_loss: 1.8233 - val_categorical_accuracy: 0.6264\n",
      "Epoch 164/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5446 - categorical_accuracy: 0.7946\n",
      "Epoch 00164: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.5850 - categorical_accuracy: 0.7929 - val_loss: 1.8798 - val_categorical_accuracy: 0.6264\n",
      "Epoch 165/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.6578 - categorical_accuracy: 0.7961\n",
      "Epoch 00165: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.5874 - categorical_accuracy: 0.7988 - val_loss: 1.8268 - val_categorical_accuracy: 0.6593\n",
      "Epoch 166/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.3274 - categorical_accuracy: 1.0000\n",
      "Epoch 00166: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 181us/sample - loss: 1.5977 - categorical_accuracy: 0.8195 - val_loss: 1.8206 - val_categorical_accuracy: 0.6484\n",
      "Epoch 167/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6424 - categorical_accuracy: 0.7906\n",
      "Epoch 00167: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 1.5824 - categorical_accuracy: 0.7959 - val_loss: 1.8280 - val_categorical_accuracy: 0.6264\n",
      "Epoch 168/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5855 - categorical_accuracy: 0.8094\n",
      "Epoch 00168: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5807 - categorical_accuracy: 0.8047 - val_loss: 1.8318 - val_categorical_accuracy: 0.6374\n",
      "Epoch 169/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5903 - categorical_accuracy: 0.7768\n",
      "Epoch 00169: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.5825 - categorical_accuracy: 0.7781 - val_loss: 1.8292 - val_categorical_accuracy: 0.6374\n",
      "Epoch 170/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5799 - categorical_accuracy: 0.8036\n",
      "Epoch 00170: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5752 - categorical_accuracy: 0.8018 - val_loss: 1.8072 - val_categorical_accuracy: 0.6593\n",
      "Epoch 171/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.4306 - categorical_accuracy: 0.8750\n",
      "Epoch 00171: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 192us/sample - loss: 1.5717 - categorical_accuracy: 0.8077 - val_loss: 1.8579 - val_categorical_accuracy: 0.6484\n",
      "Epoch 172/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6020 - categorical_accuracy: 0.8031\n",
      "Epoch 00172: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.5872 - categorical_accuracy: 0.8018 - val_loss: 1.8447 - val_categorical_accuracy: 0.6374\n",
      "Epoch 173/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5379 - categorical_accuracy: 0.8031\n",
      "Epoch 00173: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.5718 - categorical_accuracy: 0.8047 - val_loss: 1.8811 - val_categorical_accuracy: 0.6154\n",
      "Epoch 174/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5838 - categorical_accuracy: 0.7827\n",
      "Epoch 00174: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.5787 - categorical_accuracy: 0.7840 - val_loss: 1.8280 - val_categorical_accuracy: 0.6593\n",
      "Epoch 175/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.3441 - categorical_accuracy: 0.9375\n",
      "Epoch 00175: val_categorical_accuracy did not improve from 0.65934\n",
      "338/338 [==============================] - 0s 192us/sample - loss: 1.5848 - categorical_accuracy: 0.7840 - val_loss: 1.8027 - val_categorical_accuracy: 0.6593\n",
      "Epoch 176/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5378 - categorical_accuracy: 0.8065\n",
      "Epoch 00176: val_categorical_accuracy improved from 0.65934 to 0.67033, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 269us/sample - loss: 1.5778 - categorical_accuracy: 0.8047 - val_loss: 1.8133 - val_categorical_accuracy: 0.6703\n",
      "Epoch 177/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5955 - categorical_accuracy: 0.7906\n",
      "Epoch 00177: val_categorical_accuracy did not improve from 0.67033\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.5807 - categorical_accuracy: 0.7929 - val_loss: 1.8123 - val_categorical_accuracy: 0.6264\n",
      "Epoch 178/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5364 - categorical_accuracy: 0.8031\n",
      "Epoch 00178: val_categorical_accuracy did not improve from 0.67033\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5717 - categorical_accuracy: 0.7988 - val_loss: 1.8153 - val_categorical_accuracy: 0.6484\n",
      "Epoch 179/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5327 - categorical_accuracy: 0.8026\n",
      "Epoch 00179: val_categorical_accuracy did not improve from 0.67033\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.5679 - categorical_accuracy: 0.8018 - val_loss: 1.8094 - val_categorical_accuracy: 0.6703\n",
      "Epoch 180/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5903 - categorical_accuracy: 0.8065\n",
      "Epoch 00180: val_categorical_accuracy did not improve from 0.67033\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.5830 - categorical_accuracy: 0.8077 - val_loss: 1.8275 - val_categorical_accuracy: 0.6374\n",
      "Epoch 181/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5610 - categorical_accuracy: 0.7917\n",
      "Epoch 00181: val_categorical_accuracy did not improve from 0.67033\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.6002 - categorical_accuracy: 0.7899 - val_loss: 1.8378 - val_categorical_accuracy: 0.6374\n",
      "Epoch 182/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5577 - categorical_accuracy: 0.7844\n",
      "Epoch 00182: val_categorical_accuracy improved from 0.67033 to 0.68132, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 261us/sample - loss: 1.5945 - categorical_accuracy: 0.7870 - val_loss: 1.8108 - val_categorical_accuracy: 0.6813\n",
      "Epoch 183/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5957 - categorical_accuracy: 0.7768\n",
      "Epoch 00183: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 204us/sample - loss: 1.5876 - categorical_accuracy: 0.7781 - val_loss: 1.8264 - val_categorical_accuracy: 0.6154\n",
      "Epoch 184/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5689 - categorical_accuracy: 0.8281\n",
      "Epoch 00184: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.5576 - categorical_accuracy: 0.8254 - val_loss: 1.8491 - val_categorical_accuracy: 0.6154\n",
      "Epoch 185/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4155 - categorical_accuracy: 0.8250\n",
      "Epoch 00185: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 1.5539 - categorical_accuracy: 0.8107 - val_loss: 1.8069 - val_categorical_accuracy: 0.6484\n",
      "Epoch 186/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5800 - categorical_accuracy: 0.8000\n",
      "Epoch 00186: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.5644 - categorical_accuracy: 0.7988 - val_loss: 1.8100 - val_categorical_accuracy: 0.6593\n",
      "Epoch 187/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.3144 - categorical_accuracy: 0.8750\n",
      "Epoch 00187: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 201us/sample - loss: 1.5497 - categorical_accuracy: 0.8107 - val_loss: 1.8164 - val_categorical_accuracy: 0.6374\n",
      "Epoch 188/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5162 - categorical_accuracy: 0.8094\n",
      "Epoch 00188: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.5566 - categorical_accuracy: 0.8077 - val_loss: 1.8272 - val_categorical_accuracy: 0.6374\n",
      "Epoch 189/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5715 - categorical_accuracy: 0.8095\n",
      "Epoch 00189: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.5623 - categorical_accuracy: 0.8107 - val_loss: 1.8270 - val_categorical_accuracy: 0.6484\n",
      "Epoch 190/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5602 - categorical_accuracy: 0.8185\n",
      "Epoch 00190: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5523 - categorical_accuracy: 0.8195 - val_loss: 1.8432 - val_categorical_accuracy: 0.6374\n",
      "Epoch 191/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5450 - categorical_accuracy: 0.8125\n",
      "Epoch 00191: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5427 - categorical_accuracy: 0.8107 - val_loss: 1.7959 - val_categorical_accuracy: 0.6703\n",
      "Epoch 192/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5712 - categorical_accuracy: 0.8219\n",
      "Epoch 00192: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5536 - categorical_accuracy: 0.8284 - val_loss: 1.8736 - val_categorical_accuracy: 0.6264\n",
      "Epoch 193/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5732 - categorical_accuracy: 0.7857\n",
      "Epoch 00193: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.5654 - categorical_accuracy: 0.7870 - val_loss: 1.8095 - val_categorical_accuracy: 0.6374\n",
      "Epoch 194/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5612 - categorical_accuracy: 0.8036\n",
      "Epoch 00194: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5529 - categorical_accuracy: 0.8047 - val_loss: 1.8149 - val_categorical_accuracy: 0.6264\n",
      "Epoch 195/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5562 - categorical_accuracy: 0.8185\n",
      "Epoch 00195: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.5484 - categorical_accuracy: 0.8195 - val_loss: 1.7978 - val_categorical_accuracy: 0.6374\n",
      "Epoch 196/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5455 - categorical_accuracy: 0.8250\n",
      "Epoch 00196: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.5382 - categorical_accuracy: 0.8195 - val_loss: 1.8132 - val_categorical_accuracy: 0.6484\n",
      "Epoch 197/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5525 - categorical_accuracy: 0.8062\n",
      "Epoch 00197: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.5474 - categorical_accuracy: 0.7988 - val_loss: 1.7870 - val_categorical_accuracy: 0.6593\n",
      "Epoch 198/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.6144 - categorical_accuracy: 0.8031\n",
      "Epoch 00198: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.5432 - categorical_accuracy: 0.8136 - val_loss: 1.8374 - val_categorical_accuracy: 0.6484\n",
      "Epoch 199/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 2.4528 - categorical_accuracy: 0.7500\n",
      "Epoch 00199: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 195us/sample - loss: 1.5469 - categorical_accuracy: 0.8136 - val_loss: 1.7983 - val_categorical_accuracy: 0.6484\n",
      "Epoch 200/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5403 - categorical_accuracy: 0.8155\n",
      "Epoch 00200: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 198us/sample - loss: 1.5319 - categorical_accuracy: 0.8166 - val_loss: 1.7870 - val_categorical_accuracy: 0.6593\n",
      "Epoch 201/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5906 - categorical_accuracy: 0.8062\n",
      "Epoch 00201: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.5407 - categorical_accuracy: 0.8047 - val_loss: 1.7882 - val_categorical_accuracy: 0.6593\n",
      "Epoch 202/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.5680 - categorical_accuracy: 0.8750\n",
      "Epoch 00202: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 192us/sample - loss: 1.5295 - categorical_accuracy: 0.8225 - val_loss: 1.7898 - val_categorical_accuracy: 0.6703\n",
      "Epoch 203/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5480 - categorical_accuracy: 0.8250\n",
      "Epoch 00203: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.5320 - categorical_accuracy: 0.8254 - val_loss: 1.8227 - val_categorical_accuracy: 0.6593\n",
      "Epoch 204/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4927 - categorical_accuracy: 0.8188\n",
      "Epoch 00204: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.5323 - categorical_accuracy: 0.8136 - val_loss: 1.8118 - val_categorical_accuracy: 0.6264\n",
      "Epoch 205/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5468 - categorical_accuracy: 0.8185\n",
      "Epoch 00205: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5397 - categorical_accuracy: 0.8195 - val_loss: 1.8029 - val_categorical_accuracy: 0.6593\n",
      "Epoch 206/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5443 - categorical_accuracy: 0.8062\n",
      "Epoch 00206: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.5327 - categorical_accuracy: 0.8107 - val_loss: 1.7959 - val_categorical_accuracy: 0.6374\n",
      "Epoch 207/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5356 - categorical_accuracy: 0.8185\n",
      "Epoch 00207: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5280 - categorical_accuracy: 0.8195 - val_loss: 1.7861 - val_categorical_accuracy: 0.6813\n",
      "Epoch 208/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5400 - categorical_accuracy: 0.8036\n",
      "Epoch 00208: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.5322 - categorical_accuracy: 0.8047 - val_loss: 1.7891 - val_categorical_accuracy: 0.6484\n",
      "Epoch 209/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.6466 - categorical_accuracy: 0.8191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00209: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 246us/sample - loss: 1.5221 - categorical_accuracy: 0.8254 - val_loss: 1.8078 - val_categorical_accuracy: 0.6593\n",
      "Epoch 210/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.4521 - categorical_accuracy: 0.8229\n",
      "Epoch 00210: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 243us/sample - loss: 1.5322 - categorical_accuracy: 0.8166 - val_loss: 1.8182 - val_categorical_accuracy: 0.6374\n",
      "Epoch 211/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5419 - categorical_accuracy: 0.8125\n",
      "Epoch 00211: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 1.5264 - categorical_accuracy: 0.8136 - val_loss: 1.7951 - val_categorical_accuracy: 0.6374\n",
      "Epoch 212/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4837 - categorical_accuracy: 0.8062\n",
      "Epoch 00212: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.5225 - categorical_accuracy: 0.8047 - val_loss: 1.7988 - val_categorical_accuracy: 0.6484\n",
      "Epoch 213/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.3007 - categorical_accuracy: 0.8507\n",
      "Epoch 00213: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 240us/sample - loss: 1.5156 - categorical_accuracy: 0.8225 - val_loss: 1.7920 - val_categorical_accuracy: 0.6264\n",
      "Epoch 214/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.6113 - categorical_accuracy: 0.8026\n",
      "Epoch 00214: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 1.5401 - categorical_accuracy: 0.8018 - val_loss: 1.8002 - val_categorical_accuracy: 0.6484\n",
      "Epoch 215/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5358 - categorical_accuracy: 0.8281\n",
      "Epoch 00215: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 1.5214 - categorical_accuracy: 0.8284 - val_loss: 1.8215 - val_categorical_accuracy: 0.6264\n",
      "Epoch 216/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5873 - categorical_accuracy: 0.8281\n",
      "Epoch 00216: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.5155 - categorical_accuracy: 0.8373 - val_loss: 1.8028 - val_categorical_accuracy: 0.6593\n",
      "Epoch 217/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.6028 - categorical_accuracy: 0.8191\n",
      "Epoch 00217: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 1.5278 - categorical_accuracy: 0.8254 - val_loss: 1.8292 - val_categorical_accuracy: 0.6484\n",
      "Epoch 218/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.4515 - categorical_accuracy: 0.8056\n",
      "Epoch 00218: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 1.5241 - categorical_accuracy: 0.8077 - val_loss: 1.7958 - val_categorical_accuracy: 0.6374\n",
      "Epoch 219/300\n",
      "272/338 [=======================>......] - ETA: 0s - loss: 1.4572 - categorical_accuracy: 0.8272\n",
      "Epoch 00219: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 246us/sample - loss: 1.5165 - categorical_accuracy: 0.8225 - val_loss: 1.8370 - val_categorical_accuracy: 0.6154\n",
      "Epoch 220/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5169 - categorical_accuracy: 0.8158\n",
      "Epoch 00220: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.5380 - categorical_accuracy: 0.8166 - val_loss: 1.7853 - val_categorical_accuracy: 0.6593\n",
      "Epoch 221/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5195 - categorical_accuracy: 0.8155\n",
      "Epoch 00221: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5128 - categorical_accuracy: 0.8136 - val_loss: 1.7797 - val_categorical_accuracy: 0.6703\n",
      "Epoch 222/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.3910 - categorical_accuracy: 0.8250\n",
      "Epoch 00222: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.5206 - categorical_accuracy: 0.8225 - val_loss: 1.7862 - val_categorical_accuracy: 0.6703\n",
      "Epoch 223/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.4780 - categorical_accuracy: 0.8224\n",
      "Epoch 00223: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.5120 - categorical_accuracy: 0.8166 - val_loss: 1.7903 - val_categorical_accuracy: 0.6374\n",
      "Epoch 224/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5063 - categorical_accuracy: 0.8274\n",
      "Epoch 00224: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.4998 - categorical_accuracy: 0.8284 - val_loss: 1.7848 - val_categorical_accuracy: 0.6484\n",
      "Epoch 225/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5695 - categorical_accuracy: 0.8219\n",
      "Epoch 00225: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 1.5098 - categorical_accuracy: 0.8225 - val_loss: 1.7880 - val_categorical_accuracy: 0.6593\n",
      "Epoch 226/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5230 - categorical_accuracy: 0.8219\n",
      "Epoch 00226: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 1.5130 - categorical_accuracy: 0.8166 - val_loss: 1.8174 - val_categorical_accuracy: 0.6044\n",
      "Epoch 227/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5280 - categorical_accuracy: 0.8125\n",
      "Epoch 00227: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 240us/sample - loss: 1.5123 - categorical_accuracy: 0.8107 - val_loss: 1.7799 - val_categorical_accuracy: 0.6703\n",
      "Epoch 228/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5513 - categorical_accuracy: 0.8059\n",
      "Epoch 00228: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.5250 - categorical_accuracy: 0.8047 - val_loss: 1.7915 - val_categorical_accuracy: 0.6703\n",
      "Epoch 229/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.3679 - categorical_accuracy: 0.9375\n",
      "Epoch 00229: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 201us/sample - loss: 1.5143 - categorical_accuracy: 0.8225 - val_loss: 1.7964 - val_categorical_accuracy: 0.6264\n",
      "Epoch 230/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5320 - categorical_accuracy: 0.8281\n",
      "Epoch 00230: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 1.5174 - categorical_accuracy: 0.8314 - val_loss: 1.8106 - val_categorical_accuracy: 0.6374\n",
      "Epoch 231/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5451 - categorical_accuracy: 0.7961\n",
      "Epoch 00231: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 231us/sample - loss: 1.5254 - categorical_accuracy: 0.8018 - val_loss: 1.8370 - val_categorical_accuracy: 0.6154\n",
      "Epoch 232/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5335 - categorical_accuracy: 0.8191\n",
      "Epoch 00232: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 234us/sample - loss: 1.5162 - categorical_accuracy: 0.8166 - val_loss: 1.8024 - val_categorical_accuracy: 0.6154\n",
      "Epoch 233/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.4336 - categorical_accuracy: 0.8125\n",
      "Epoch 00233: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 231us/sample - loss: 1.5000 - categorical_accuracy: 0.8195 - val_loss: 1.7731 - val_categorical_accuracy: 0.6703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.6211 - categorical_accuracy: 0.8421\n",
      "Epoch 00234: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 1.4960 - categorical_accuracy: 0.8432 - val_loss: 1.8113 - val_categorical_accuracy: 0.6264\n",
      "Epoch 235/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.6035 - categorical_accuracy: 0.8322\n",
      "Epoch 00235: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.4918 - categorical_accuracy: 0.8314 - val_loss: 1.7842 - val_categorical_accuracy: 0.6813\n",
      "Epoch 236/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.4668 - categorical_accuracy: 0.8322\n",
      "Epoch 00236: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.4936 - categorical_accuracy: 0.8373 - val_loss: 1.8148 - val_categorical_accuracy: 0.6154\n",
      "Epoch 237/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5863 - categorical_accuracy: 0.8059\n",
      "Epoch 00237: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 1.5075 - categorical_accuracy: 0.8136 - val_loss: 1.7903 - val_categorical_accuracy: 0.6593\n",
      "Epoch 238/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.4783 - categorical_accuracy: 0.8299\n",
      "Epoch 00238: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 246us/sample - loss: 1.4940 - categorical_accuracy: 0.8402 - val_loss: 1.7832 - val_categorical_accuracy: 0.6593\n",
      "Epoch 239/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.4080 - categorical_accuracy: 0.8289\n",
      "Epoch 00239: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 240us/sample - loss: 1.4964 - categorical_accuracy: 0.8225 - val_loss: 1.7873 - val_categorical_accuracy: 0.6374\n",
      "Epoch 240/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.3587 - categorical_accuracy: 0.8289\n",
      "Epoch 00240: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 231us/sample - loss: 1.5016 - categorical_accuracy: 0.8195 - val_loss: 1.7966 - val_categorical_accuracy: 0.6264\n",
      "Epoch 241/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5146 - categorical_accuracy: 0.8250\n",
      "Epoch 00241: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.5027 - categorical_accuracy: 0.8254 - val_loss: 1.7735 - val_categorical_accuracy: 0.6813\n",
      "Epoch 242/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5583 - categorical_accuracy: 0.8355\n",
      "Epoch 00242: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 231us/sample - loss: 1.5174 - categorical_accuracy: 0.8195 - val_loss: 1.8333 - val_categorical_accuracy: 0.6154\n",
      "Epoch 243/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5020 - categorical_accuracy: 0.8224\n",
      "Epoch 00243: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 1.5293 - categorical_accuracy: 0.8225 - val_loss: 1.8157 - val_categorical_accuracy: 0.6703\n",
      "Epoch 244/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5234 - categorical_accuracy: 0.8375\n",
      "Epoch 00244: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.5030 - categorical_accuracy: 0.8402 - val_loss: 1.8089 - val_categorical_accuracy: 0.6593\n",
      "Epoch 245/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5718 - categorical_accuracy: 0.8125\n",
      "Epoch 00245: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.5052 - categorical_accuracy: 0.8166 - val_loss: 1.7859 - val_categorical_accuracy: 0.6484\n",
      "Epoch 246/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.5970 - categorical_accuracy: 0.8194\n",
      "Epoch 00246: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 237us/sample - loss: 1.5048 - categorical_accuracy: 0.8343 - val_loss: 1.7692 - val_categorical_accuracy: 0.6703\n",
      "Epoch 247/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.5653 - categorical_accuracy: 0.8322\n",
      "Epoch 00247: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 231us/sample - loss: 1.4902 - categorical_accuracy: 0.8373 - val_loss: 1.7911 - val_categorical_accuracy: 0.6484\n",
      "Epoch 248/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.3987 - categorical_accuracy: 0.8322\n",
      "Epoch 00248: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 231us/sample - loss: 1.4890 - categorical_accuracy: 0.8225 - val_loss: 1.8241 - val_categorical_accuracy: 0.6484\n",
      "Epoch 249/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5215 - categorical_accuracy: 0.8062\n",
      "Epoch 00249: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.5026 - categorical_accuracy: 0.8136 - val_loss: 1.7963 - val_categorical_accuracy: 0.6593\n",
      "Epoch 250/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.5566 - categorical_accuracy: 0.8299\n",
      "Epoch 00250: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.4856 - categorical_accuracy: 0.8225 - val_loss: 1.7652 - val_categorical_accuracy: 0.6703\n",
      "Epoch 251/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.5159 - categorical_accuracy: 0.8036\n",
      "Epoch 00251: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.5083 - categorical_accuracy: 0.8047 - val_loss: 1.7669 - val_categorical_accuracy: 0.6484\n",
      "Epoch 252/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4605 - categorical_accuracy: 0.8393\n",
      "Epoch 00252: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.4996 - categorical_accuracy: 0.8373 - val_loss: 1.7646 - val_categorical_accuracy: 0.6813\n",
      "Epoch 253/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4992 - categorical_accuracy: 0.8250\n",
      "Epoch 00253: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4829 - categorical_accuracy: 0.8284 - val_loss: 1.8051 - val_categorical_accuracy: 0.6264\n",
      "Epoch 254/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5539 - categorical_accuracy: 0.8344\n",
      "Epoch 00254: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4886 - categorical_accuracy: 0.8402 - val_loss: 1.7887 - val_categorical_accuracy: 0.6484\n",
      "Epoch 255/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4407 - categorical_accuracy: 0.8423\n",
      "Epoch 00255: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.4813 - categorical_accuracy: 0.8402 - val_loss: 1.7687 - val_categorical_accuracy: 0.6593\n",
      "Epoch 256/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 1.3871 - categorical_accuracy: 0.8125\n",
      "Epoch 00256: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 187us/sample - loss: 1.4836 - categorical_accuracy: 0.8314 - val_loss: 1.7945 - val_categorical_accuracy: 0.6593\n",
      "Epoch 257/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4519 - categorical_accuracy: 0.8313\n",
      "Epoch 00257: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 1.4851 - categorical_accuracy: 0.8314 - val_loss: 1.7916 - val_categorical_accuracy: 0.6374\n",
      "Epoch 258/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/338 [============================>.] - ETA: 0s - loss: 1.4871 - categorical_accuracy: 0.8363\n",
      "Epoch 00258: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 204us/sample - loss: 1.4801 - categorical_accuracy: 0.8373 - val_loss: 1.8001 - val_categorical_accuracy: 0.6484\n",
      "Epoch 259/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4485 - categorical_accuracy: 0.8406\n",
      "Epoch 00259: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.4950 - categorical_accuracy: 0.8254 - val_loss: 1.8185 - val_categorical_accuracy: 0.6374\n",
      "Epoch 260/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.4143 - categorical_accuracy: 0.8333\n",
      "Epoch 00260: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 240us/sample - loss: 1.4837 - categorical_accuracy: 0.8314 - val_loss: 1.7931 - val_categorical_accuracy: 0.6154\n",
      "Epoch 261/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.5655 - categorical_accuracy: 0.8299\n",
      "Epoch 00261: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 237us/sample - loss: 1.4782 - categorical_accuracy: 0.8402 - val_loss: 1.7828 - val_categorical_accuracy: 0.6374\n",
      "Epoch 262/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.5647 - categorical_accuracy: 0.8160\n",
      "Epoch 00262: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 269us/sample - loss: 1.4751 - categorical_accuracy: 0.8284 - val_loss: 1.7873 - val_categorical_accuracy: 0.6703\n",
      "Epoch 263/300\n",
      " 16/338 [>.............................] - ETA: 0s - loss: 0.3411 - categorical_accuracy: 0.9375\n",
      "Epoch 00263: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 187us/sample - loss: 1.4768 - categorical_accuracy: 0.8432 - val_loss: 1.7770 - val_categorical_accuracy: 0.6374\n",
      "Epoch 264/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4015 - categorical_accuracy: 0.8219\n",
      "Epoch 00264: val_categorical_accuracy did not improve from 0.68132\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4792 - categorical_accuracy: 0.8225 - val_loss: 1.7649 - val_categorical_accuracy: 0.6703\n",
      "Epoch 265/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.4932 - categorical_accuracy: 0.8651\n",
      "Epoch 00265: val_categorical_accuracy improved from 0.68132 to 0.70330, saving model to ..\\..\\Trained Models\\Transfered_Models\\Fully_Connected_Layers_Only\\Pavia\\Fully_Connected_Layers_for_Pavia_With_source_data_as_Pavia44_overlap_ratio_50_percent.h5\n",
      "338/338 [==============================] - 0s 302us/sample - loss: 1.4843 - categorical_accuracy: 0.8580 - val_loss: 1.7655 - val_categorical_accuracy: 0.7033\n",
      "Epoch 266/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4798 - categorical_accuracy: 0.8512\n",
      "Epoch 00266: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4736 - categorical_accuracy: 0.8521 - val_loss: 1.8918 - val_categorical_accuracy: 0.6484\n",
      "Epoch 267/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4568 - categorical_accuracy: 0.8274\n",
      "Epoch 00267: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 210us/sample - loss: 1.4963 - categorical_accuracy: 0.8254 - val_loss: 1.7969 - val_categorical_accuracy: 0.6484\n",
      "Epoch 268/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.3945 - categorical_accuracy: 0.8322\n",
      "Epoch 00268: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.4742 - categorical_accuracy: 0.8254 - val_loss: 1.7792 - val_categorical_accuracy: 0.6484\n",
      "Epoch 269/300\n",
      "288/338 [========================>.....] - ETA: 0s - loss: 1.3863 - categorical_accuracy: 0.8646\n",
      "Epoch 00269: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 240us/sample - loss: 1.4699 - categorical_accuracy: 0.8491 - val_loss: 1.8006 - val_categorical_accuracy: 0.6484\n",
      "Epoch 270/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.3872 - categorical_accuracy: 0.8375\n",
      "Epoch 00270: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 1.4737 - categorical_accuracy: 0.8314 - val_loss: 1.7532 - val_categorical_accuracy: 0.6703\n",
      "Epoch 271/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.3985 - categorical_accuracy: 0.8158\n",
      "Epoch 00271: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 231us/sample - loss: 1.4785 - categorical_accuracy: 0.8136 - val_loss: 1.7560 - val_categorical_accuracy: 0.6923\n",
      "Epoch 272/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.3358 - categorical_accuracy: 0.8375\n",
      "Epoch 00272: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.4663 - categorical_accuracy: 0.8314 - val_loss: 1.7715 - val_categorical_accuracy: 0.6813\n",
      "Epoch 273/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4209 - categorical_accuracy: 0.8423\n",
      "Epoch 00273: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.4604 - categorical_accuracy: 0.8402 - val_loss: 1.8369 - val_categorical_accuracy: 0.6264\n",
      "Epoch 274/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4406 - categorical_accuracy: 0.8469\n",
      "Epoch 00274: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 222us/sample - loss: 1.4768 - categorical_accuracy: 0.8402 - val_loss: 1.7880 - val_categorical_accuracy: 0.6374\n",
      "Epoch 275/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4735 - categorical_accuracy: 0.8393\n",
      "Epoch 00275: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 204us/sample - loss: 1.4666 - categorical_accuracy: 0.8402 - val_loss: 1.8000 - val_categorical_accuracy: 0.6374\n",
      "Epoch 276/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4716 - categorical_accuracy: 0.8363\n",
      "Epoch 00276: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4675 - categorical_accuracy: 0.8343 - val_loss: 1.7611 - val_categorical_accuracy: 0.6703\n",
      "Epoch 277/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4761 - categorical_accuracy: 0.8452\n",
      "Epoch 00277: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.4694 - categorical_accuracy: 0.8462 - val_loss: 1.7576 - val_categorical_accuracy: 0.6703\n",
      "Epoch 278/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4703 - categorical_accuracy: 0.8333\n",
      "Epoch 00278: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 1.4632 - categorical_accuracy: 0.8343 - val_loss: 1.7734 - val_categorical_accuracy: 0.6484\n",
      "Epoch 279/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4673 - categorical_accuracy: 0.8542\n",
      "Epoch 00279: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4629 - categorical_accuracy: 0.8521 - val_loss: 1.7817 - val_categorical_accuracy: 0.6374\n",
      "Epoch 280/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4612 - categorical_accuracy: 0.8452\n",
      "Epoch 00280: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4553 - categorical_accuracy: 0.8462 - val_loss: 1.7577 - val_categorical_accuracy: 0.6703\n",
      "Epoch 281/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.4499 - categorical_accuracy: 0.8125\n",
      "Epoch 00281: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.4787 - categorical_accuracy: 0.8195 - val_loss: 1.7731 - val_categorical_accuracy: 0.6484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/300\n",
      "304/338 [=========================>....] - ETA: 0s - loss: 1.4227 - categorical_accuracy: 0.8553\n",
      "Epoch 00282: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 228us/sample - loss: 1.4576 - categorical_accuracy: 0.8521 - val_loss: 1.7770 - val_categorical_accuracy: 0.6264\n",
      "Epoch 283/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4857 - categorical_accuracy: 0.8313\n",
      "Epoch 00283: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4714 - categorical_accuracy: 0.8343 - val_loss: 1.8312 - val_categorical_accuracy: 0.6374\n",
      "Epoch 284/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4265 - categorical_accuracy: 0.8393\n",
      "Epoch 00284: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4696 - categorical_accuracy: 0.8343 - val_loss: 1.7707 - val_categorical_accuracy: 0.6484\n",
      "Epoch 285/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4696 - categorical_accuracy: 0.8482\n",
      "Epoch 00285: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.4626 - categorical_accuracy: 0.8491 - val_loss: 1.7888 - val_categorical_accuracy: 0.6593\n",
      "Epoch 286/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4651 - categorical_accuracy: 0.8512\n",
      "Epoch 00286: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 204us/sample - loss: 1.4569 - categorical_accuracy: 0.8521 - val_loss: 1.7742 - val_categorical_accuracy: 0.6484\n",
      "Epoch 287/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4254 - categorical_accuracy: 0.8375\n",
      "Epoch 00287: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.4566 - categorical_accuracy: 0.8343 - val_loss: 1.7784 - val_categorical_accuracy: 0.6703\n",
      "Epoch 288/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4673 - categorical_accuracy: 0.8571\n",
      "Epoch 00288: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.4591 - categorical_accuracy: 0.8580 - val_loss: 1.7671 - val_categorical_accuracy: 0.6703\n",
      "Epoch 289/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4227 - categorical_accuracy: 0.8469\n",
      "Epoch 00289: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.4566 - categorical_accuracy: 0.8462 - val_loss: 1.8129 - val_categorical_accuracy: 0.6264\n",
      "Epoch 290/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4730 - categorical_accuracy: 0.8469\n",
      "Epoch 00290: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.4545 - categorical_accuracy: 0.8491 - val_loss: 1.7491 - val_categorical_accuracy: 0.6593\n",
      "Epoch 291/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4151 - categorical_accuracy: 0.8469\n",
      "Epoch 00291: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.4482 - categorical_accuracy: 0.8432 - val_loss: 1.8639 - val_categorical_accuracy: 0.6593\n",
      "Epoch 292/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5046 - categorical_accuracy: 0.8313\n",
      "Epoch 00292: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 225us/sample - loss: 1.4865 - categorical_accuracy: 0.8343 - val_loss: 1.7716 - val_categorical_accuracy: 0.6593\n",
      "Epoch 293/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.5099 - categorical_accuracy: 0.8469\n",
      "Epoch 00293: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.4494 - categorical_accuracy: 0.8491 - val_loss: 1.7858 - val_categorical_accuracy: 0.6593\n",
      "Epoch 294/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4602 - categorical_accuracy: 0.8562\n",
      "Epoch 00294: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4530 - categorical_accuracy: 0.8550 - val_loss: 1.7584 - val_categorical_accuracy: 0.6813\n",
      "Epoch 295/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4557 - categorical_accuracy: 0.8601\n",
      "Epoch 00295: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.4506 - categorical_accuracy: 0.8580 - val_loss: 1.7521 - val_categorical_accuracy: 0.6813\n",
      "Epoch 296/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4191 - categorical_accuracy: 0.8281\n",
      "Epoch 00296: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 219us/sample - loss: 1.4553 - categorical_accuracy: 0.8284 - val_loss: 1.7768 - val_categorical_accuracy: 0.6703\n",
      "Epoch 297/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4230 - categorical_accuracy: 0.8438\n",
      "Epoch 00297: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 213us/sample - loss: 1.4572 - categorical_accuracy: 0.8462 - val_loss: 1.7588 - val_categorical_accuracy: 0.6593\n",
      "Epoch 298/300\n",
      "320/338 [===========================>..] - ETA: 0s - loss: 1.4627 - categorical_accuracy: 0.8375\n",
      "Epoch 00298: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 216us/sample - loss: 1.4580 - categorical_accuracy: 0.8343 - val_loss: 1.7681 - val_categorical_accuracy: 0.7033\n",
      "Epoch 299/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4264 - categorical_accuracy: 0.8393\n",
      "Epoch 00299: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 201us/sample - loss: 1.4661 - categorical_accuracy: 0.8373 - val_loss: 1.7604 - val_categorical_accuracy: 0.6813\n",
      "Epoch 300/300\n",
      "336/338 [============================>.] - ETA: 0s - loss: 1.4487 - categorical_accuracy: 0.8512\n",
      "Epoch 00300: val_categorical_accuracy did not improve from 0.70330\n",
      "338/338 [==============================] - 0s 207us/sample - loss: 1.4413 - categorical_accuracy: 0.8521 - val_loss: 1.7934 - val_categorical_accuracy: 0.6484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c49c663c18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint('..\\\\..\\\\Trained Models\\\\Transfered_Models\\\\Fully_Connected_Layers_Only\\\\'\n",
    "                                   +Target_data_name+'\\\\Fully_Connected_Layers_for_'+ Target_data_name +\n",
    "                                   '_With_source_data_as_'+ Source_data_name +'_overlap_ratio_' + \n",
    "                                   str(int(overlap_ratio * 100)) + '_percent.h5',\n",
    "                                   monitor='val_categorical_accuracy', verbose=1, save_best_only=True)\n",
    "model_1.compile(optimizer=keras.optimizers.SGD(lr=0.0001, decay=1e-5, momentum=0.9, nesterov=True),\n",
    "                loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_1.fit(Xtrain_transfer, Ytrain, epochs=300, batch_size=16, validation_data=(Xtest_transfer, Ytest), verbose=1,\n",
    "            callbacks=[model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 132us/sample - loss: 1.7934 - categorical_accuracy: 0.6484\n",
      "Test Accuracy = 0.64835167\n"
     ]
    }
   ],
   "source": [
    "preds = model_1.evaluate(Xtest_transfer, Ytest)\n",
    "# print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 1ms/sample\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_1.predict(Xtest_transfer, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  6,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  2,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 15,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1,  9,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  3,  0,  2,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  3,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,  0,  0,  0,  0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = sklearn.metrics.confusion_matrix(np.argmax(Ytest, axis=1), np.argmax(y_pred, axis=1))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  7,  4,  3,  6,  7,  6, 16, 11,  6,  2,  4,  2,  2, 10,  2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

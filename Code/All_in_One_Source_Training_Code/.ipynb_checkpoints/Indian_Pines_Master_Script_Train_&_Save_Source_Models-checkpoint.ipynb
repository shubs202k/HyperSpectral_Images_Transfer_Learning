{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indian Pines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source_Model_Utils import *\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 145, 200) (145, 145)\n",
      "(200, 145, 145) (145, 145)\n"
     ]
    }
   ],
   "source": [
    "uIndian_pines = sio.loadmat('..\\\\..\\\\Indian Pines\\\\Indian_pines_corrected.mat')\n",
    "gt_uIndian_pines = sio.loadmat('..\\\\..\\\\Indian Pines\\\\Indian_pines_gt.mat')\n",
    "data_IN = uIndian_pines['indian_pines_corrected']\n",
    "gt_IN = gt_uIndian_pines['indian_pines_gt']\n",
    "print(data_IN.shape, gt_IN.shape)\n",
    "data_IN = np.moveaxis(data_IN, 2, 0)\n",
    "print(data_IN.shape, gt_IN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16] [10776    46  1428   830   237   483   730    28   478    20   972  2455\n",
      "   593   205  1265   386    93]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values,counts = np.unique(gt_IN, return_counts=True)\n",
    "print(values,counts)\n",
    "range_of_class = list(values)\n",
    "if 0 in range_of_class:\n",
    "    range_of_class.pop(0)\n",
    "range_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0             1\n",
      "0  Test Accuracy Table  Indian Pines\n",
      "1      Data_Overlap_50          None\n",
      "2      Data_Overlap_75          None\n",
      "3      Data_Overlap_85          None\n",
      "4      Data_Overlap_95          None\n",
      "\n",
      "\n",
      "===============================================================================================================================\n",
      "======================================== Data with overlap ratio of 50% will be trained =======================================\n",
      "===============================================================================================================================\n",
      "\n",
      "\n",
      "(75, 103, 24, 24, 1) (22, 103, 24, 24, 1) (75,) (22,)\n",
      "Total samples per class: [0, 15, 8, 0, 7, 10, 0, 4, 0, 12, 24, 5, 0, 12, 0, 0], Total number of samples is 97.\n",
      "\n",
      "unique classes in Ytest: [ 2  3  5  6  8 10 11 12 14], Total number of samples in Ytest is 22.\n",
      "number of samples per class in Ytest: [3 2 2 2 1 3 5 1 3]\n",
      "\n",
      "Xtrain => (75, 103, 24, 24, 1)\n",
      "Xtest  => (22, 103, 24, 24, 1)\n",
      "Ytrain => (75, 9)\n",
      "Ytest  => (22, 9)\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d (GlobalMax (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fc_256 (Dense)                  (None, 256)          16640       global_max_pooling3d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fc9 (Dense)                     (None, 9)            2313        fc_256[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 125,497\n",
      "Trainable params: 124,761\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 6.1638 - categorical_accuracy: 0.2083\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.04545, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 8s 105ms/step - loss: 6.1736 - categorical_accuracy: 0.2000 - val_loss: 7.3703 - val_categorical_accuracy: 0.0455\n",
      "Epoch 2/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 5.3531 - categorical_accuracy: 0.2000\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.04545 to 0.09091, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 5.3367 - categorical_accuracy: 0.2000 - val_loss: 6.6623 - val_categorical_accuracy: 0.0909\n",
      "Epoch 3/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 4.9761 - categorical_accuracy: 0.2838\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.09091 to 0.13636, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 4.9766 - categorical_accuracy: 0.2800 - val_loss: 6.3790 - val_categorical_accuracy: 0.1364\n",
      "Epoch 4/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 4.7612 - categorical_accuracy: 0.3429\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.13636\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 4.7902 - categorical_accuracy: 0.3333 - val_loss: 5.5306 - val_categorical_accuracy: 0.1364\n",
      "Epoch 5/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 4.6284 - categorical_accuracy: 0.3971\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.13636\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 4.6986 - categorical_accuracy: 0.3867 - val_loss: 5.8846 - val_categorical_accuracy: 0.1364\n",
      "Epoch 6/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 4.5631 - categorical_accuracy: 0.4143\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.13636 to 0.22727, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 4.5594 - categorical_accuracy: 0.4267 - val_loss: 5.2253 - val_categorical_accuracy: 0.2273\n",
      "Epoch 7/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 4.4019 - categorical_accuracy: 0.4595\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.22727 to 0.27273, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 4.4196 - categorical_accuracy: 0.4533 - val_loss: 5.1219 - val_categorical_accuracy: 0.2727\n",
      "Epoch 8/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 4.3603 - categorical_accuracy: 0.4324\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.27273\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 4.3608 - categorical_accuracy: 0.4267 - val_loss: 5.2213 - val_categorical_accuracy: 0.2273\n",
      "Epoch 9/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 4.2206 - categorical_accuracy: 0.5429\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.27273\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 4.2781 - categorical_accuracy: 0.5067 - val_loss: 4.7913 - val_categorical_accuracy: 0.2727\n",
      "Epoch 10/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 4.0685 - categorical_accuracy: 0.5417\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.27273\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 4.0604 - categorical_accuracy: 0.5600 - val_loss: 5.3077 - val_categorical_accuracy: 0.2273\n",
      "Epoch 11/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 3.9944 - categorical_accuracy: 0.6429\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.27273\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 4.0019 - categorical_accuracy: 0.6267 - val_loss: 5.3259 - val_categorical_accuracy: 0.1818\n",
      "Epoch 12/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 3.8776 - categorical_accuracy: 0.6667\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.27273\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 3.8754 - categorical_accuracy: 0.6667 - val_loss: 5.1686 - val_categorical_accuracy: 0.1818\n",
      "Epoch 13/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 3.6975 - categorical_accuracy: 0.7027\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.27273\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 3.7138 - categorical_accuracy: 0.6933 - val_loss: 5.0707 - val_categorical_accuracy: 0.2727\n",
      "Epoch 14/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 3.6073 - categorical_accuracy: 0.8056\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.27273 to 0.40909, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 3.5871 - categorical_accuracy: 0.8133 - val_loss: 4.8494 - val_categorical_accuracy: 0.4091\n",
      "Epoch 15/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 3.5212 - categorical_accuracy: 0.8000\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.40909\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 3.5529 - categorical_accuracy: 0.7867 - val_loss: 4.6967 - val_categorical_accuracy: 0.4091\n",
      "Epoch 16/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 3.3469 - categorical_accuracy: 0.9054\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.40909\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 3.3433 - categorical_accuracy: 0.9067 - val_loss: 4.8213 - val_categorical_accuracy: 0.3636\n",
      "Epoch 17/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 3.1635 - categorical_accuracy: 0.9865\n",
      "Epoch 00017: val_categorical_accuracy improved from 0.40909 to 0.45455, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 3.1601 - categorical_accuracy: 0.9867 - val_loss: 4.7104 - val_categorical_accuracy: 0.4545\n",
      "Epoch 18/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 3.1896 - categorical_accuracy: 0.9143\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 3.2011 - categorical_accuracy: 0.9067 - val_loss: 4.8651 - val_categorical_accuracy: 0.3636\n",
      "Epoch 19/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 3.1435 - categorical_accuracy: 0.9714\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 3.1401 - categorical_accuracy: 0.9733 - val_loss: 4.7485 - val_categorical_accuracy: 0.2727\n",
      "Epoch 20/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 3.1272 - categorical_accuracy: 0.9595\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 3.1241 - categorical_accuracy: 0.9600 - val_loss: 5.0114 - val_categorical_accuracy: 0.3182\n",
      "Epoch 21/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 3.0801 - categorical_accuracy: 0.9571\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 3.0841 - categorical_accuracy: 0.9600 - val_loss: 4.8663 - val_categorical_accuracy: 0.3182\n",
      "Epoch 22/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 3.0310 - categorical_accuracy: 0.9559\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 3.0205 - categorical_accuracy: 0.9600 - val_loss: 4.6403 - val_categorical_accuracy: 0.1818\n",
      "Epoch 23/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 3.0218 - categorical_accuracy: 0.9595\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 3.0207 - categorical_accuracy: 0.9600 - val_loss: 4.7121 - val_categorical_accuracy: 0.4091\n",
      "Epoch 24/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.9337 - categorical_accuracy: 1.0000\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.9359 - categorical_accuracy: 1.0000 - val_loss: 4.5891 - val_categorical_accuracy: 0.4545\n",
      "Epoch 25/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.9162 - categorical_accuracy: 1.0000\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.9128 - categorical_accuracy: 1.0000 - val_loss: 4.6146 - val_categorical_accuracy: 0.4545\n",
      "Epoch 26/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.8993 - categorical_accuracy: 1.0000\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.8981 - categorical_accuracy: 1.0000 - val_loss: 4.6387 - val_categorical_accuracy: 0.3182\n",
      "Epoch 27/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.8930 - categorical_accuracy: 1.0000\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.8924 - categorical_accuracy: 1.0000 - val_loss: 4.7078 - val_categorical_accuracy: 0.4545\n",
      "Epoch 28/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.8858 - categorical_accuracy: 1.0000\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.8859 - categorical_accuracy: 1.0000 - val_loss: 4.9139 - val_categorical_accuracy: 0.2727\n",
      "Epoch 29/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.8600 - categorical_accuracy: 1.0000\n",
      "Epoch 00029: val_categorical_accuracy improved from 0.45455 to 0.50000, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 2.8591 - categorical_accuracy: 1.0000 - val_loss: 4.6768 - val_categorical_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.8456 - categorical_accuracy: 1.0000\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.8418 - categorical_accuracy: 1.0000 - val_loss: 4.6852 - val_categorical_accuracy: 0.4091\n",
      "Epoch 31/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.8369 - categorical_accuracy: 1.0000\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.8370 - categorical_accuracy: 1.0000 - val_loss: 4.7191 - val_categorical_accuracy: 0.4545\n",
      "Epoch 32/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.8211 - categorical_accuracy: 1.0000\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.8215 - categorical_accuracy: 1.0000 - val_loss: 4.7685 - val_categorical_accuracy: 0.4545\n",
      "Epoch 33/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.8143 - categorical_accuracy: 1.0000\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.8138 - categorical_accuracy: 1.0000 - val_loss: 4.7509 - val_categorical_accuracy: 0.4545\n",
      "Epoch 34/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.8050 - categorical_accuracy: 1.0000\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.8049 - categorical_accuracy: 1.0000 - val_loss: 4.6936 - val_categorical_accuracy: 0.4545\n",
      "Epoch 35/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7988 - categorical_accuracy: 1.0000\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7982 - categorical_accuracy: 1.0000 - val_loss: 4.7449 - val_categorical_accuracy: 0.4545\n",
      "Epoch 36/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7927 - categorical_accuracy: 1.0000\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7927 - categorical_accuracy: 1.0000 - val_loss: 4.6560 - val_categorical_accuracy: 0.4545\n",
      "Epoch 37/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.8003 - categorical_accuracy: 1.0000\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7995 - categorical_accuracy: 1.0000 - val_loss: 4.7674 - val_categorical_accuracy: 0.3182\n",
      "Epoch 38/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7792 - categorical_accuracy: 1.0000\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7787 - categorical_accuracy: 1.0000 - val_loss: 4.8893 - val_categorical_accuracy: 0.4091\n",
      "Epoch 39/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.7724 - categorical_accuracy: 1.0000\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7795 - categorical_accuracy: 1.0000 - val_loss: 4.6862 - val_categorical_accuracy: 0.4545\n",
      "Epoch 40/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7734 - categorical_accuracy: 1.0000\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7740 - categorical_accuracy: 1.0000 - val_loss: 4.7207 - val_categorical_accuracy: 0.4091\n",
      "Epoch 41/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.7695 - categorical_accuracy: 1.0000\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7686 - categorical_accuracy: 1.0000 - val_loss: 4.7795 - val_categorical_accuracy: 0.4091\n",
      "Epoch 42/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7551 - categorical_accuracy: 1.0000\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7556 - categorical_accuracy: 1.0000 - val_loss: 4.7356 - val_categorical_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.7445 - categorical_accuracy: 1.0000\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7451 - categorical_accuracy: 1.0000 - val_loss: 4.6607 - val_categorical_accuracy: 0.4545\n",
      "Epoch 44/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7401 - categorical_accuracy: 1.0000\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7400 - categorical_accuracy: 1.0000 - val_loss: 4.7302 - val_categorical_accuracy: 0.4545\n",
      "Epoch 45/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.7382 - categorical_accuracy: 1.0000\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7379 - categorical_accuracy: 1.0000 - val_loss: 4.6415 - val_categorical_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7331 - categorical_accuracy: 1.0000\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7329 - categorical_accuracy: 1.0000 - val_loss: 4.7392 - val_categorical_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.7230 - categorical_accuracy: 1.0000\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7225 - categorical_accuracy: 1.0000 - val_loss: 4.6997 - val_categorical_accuracy: 0.4545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.7225 - categorical_accuracy: 1.0000\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.50000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7223 - categorical_accuracy: 1.0000 - val_loss: 4.6347 - val_categorical_accuracy: 0.4545\n",
      "Epoch 49/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7198 - categorical_accuracy: 1.0000\n",
      "Epoch 00049: val_categorical_accuracy improved from 0.50000 to 0.54545, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 2.7197 - categorical_accuracy: 1.0000 - val_loss: 4.6316 - val_categorical_accuracy: 0.5455\n",
      "Epoch 50/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7111 - categorical_accuracy: 1.0000\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7108 - categorical_accuracy: 1.0000 - val_loss: 4.6308 - val_categorical_accuracy: 0.4545\n",
      "Epoch 51/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.7061 - categorical_accuracy: 1.0000\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7055 - categorical_accuracy: 1.0000 - val_loss: 4.6606 - val_categorical_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.7111 - categorical_accuracy: 1.0000\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.7112 - categorical_accuracy: 1.0000 - val_loss: 4.6683 - val_categorical_accuracy: 0.4545\n",
      "Epoch 53/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6986 - categorical_accuracy: 1.0000\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6989 - categorical_accuracy: 1.0000 - val_loss: 4.6509 - val_categorical_accuracy: 0.4545\n",
      "Epoch 54/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.6944 - categorical_accuracy: 1.0000\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 2.6944 - categorical_accuracy: 1.0000 - val_loss: 4.7442 - val_categorical_accuracy: 0.4545\n",
      "Epoch 55/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6957 - categorical_accuracy: 1.0000\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6954 - categorical_accuracy: 1.0000 - val_loss: 4.6920 - val_categorical_accuracy: 0.4545\n",
      "Epoch 56/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6887 - categorical_accuracy: 1.0000\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6881 - categorical_accuracy: 1.0000 - val_loss: 4.6651 - val_categorical_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6820 - categorical_accuracy: 1.0000\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6815 - categorical_accuracy: 1.0000 - val_loss: 4.6218 - val_categorical_accuracy: 0.4545\n",
      "Epoch 58/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6710 - categorical_accuracy: 1.0000\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6709 - categorical_accuracy: 1.0000 - val_loss: 4.8019 - val_categorical_accuracy: 0.4091\n",
      "Epoch 59/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6705 - categorical_accuracy: 1.0000\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6697 - categorical_accuracy: 1.0000 - val_loss: 4.6448 - val_categorical_accuracy: 0.4545\n",
      "Epoch 60/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6643 - categorical_accuracy: 1.0000\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 2.6640 - categorical_accuracy: 1.0000 - val_loss: 4.6588 - val_categorical_accuracy: 0.4545\n",
      "Epoch 61/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.6590 - categorical_accuracy: 1.0000\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6591 - categorical_accuracy: 1.0000 - val_loss: 4.6285 - val_categorical_accuracy: 0.4545\n",
      "Epoch 62/100\n",
      "66/75 [=========================>....] - ETA: 0s - loss: 2.6573 - categorical_accuracy: 1.0000\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6566 - categorical_accuracy: 1.0000 - val_loss: 4.6901 - val_categorical_accuracy: 0.4545\n",
      "Epoch 63/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6494 - categorical_accuracy: 1.0000\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6494 - categorical_accuracy: 1.0000 - val_loss: 4.6779 - val_categorical_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.6503 - categorical_accuracy: 1.0000\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6520 - categorical_accuracy: 1.0000 - val_loss: 4.7106 - val_categorical_accuracy: 0.4545\n",
      "Epoch 65/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.6465 - categorical_accuracy: 1.0000\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6463 - categorical_accuracy: 1.0000 - val_loss: 4.6878 - val_categorical_accuracy: 0.4091\n",
      "Epoch 66/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6401 - categorical_accuracy: 1.0000\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6396 - categorical_accuracy: 1.0000 - val_loss: 4.7039 - val_categorical_accuracy: 0.4545\n",
      "Epoch 67/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.6328 - categorical_accuracy: 1.0000\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6327 - categorical_accuracy: 1.0000 - val_loss: 4.6943 - val_categorical_accuracy: 0.4545\n",
      "Epoch 68/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6284 - categorical_accuracy: 1.0000\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6280 - categorical_accuracy: 1.0000 - val_loss: 4.7433 - val_categorical_accuracy: 0.4545\n",
      "Epoch 69/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6268 - categorical_accuracy: 1.0000\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6264 - categorical_accuracy: 1.0000 - val_loss: 4.6798 - val_categorical_accuracy: 0.4545\n",
      "Epoch 70/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.6211 - categorical_accuracy: 1.0000\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6213 - categorical_accuracy: 1.0000 - val_loss: 4.6875 - val_categorical_accuracy: 0.4545\n",
      "Epoch 71/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.6168 - categorical_accuracy: 1.0000\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6174 - categorical_accuracy: 1.0000 - val_loss: 4.6916 - val_categorical_accuracy: 0.4545\n",
      "Epoch 72/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6120 - categorical_accuracy: 1.0000\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6119 - categorical_accuracy: 1.0000 - val_loss: 4.6739 - val_categorical_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6070 - categorical_accuracy: 1.0000\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6071 - categorical_accuracy: 1.0000 - val_loss: 4.6713 - val_categorical_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6077 - categorical_accuracy: 1.0000\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6072 - categorical_accuracy: 1.0000 - val_loss: 4.6161 - val_categorical_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6038 - categorical_accuracy: 1.0000\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.6033 - categorical_accuracy: 1.0000 - val_loss: 4.6063 - val_categorical_accuracy: 0.4545\n",
      "Epoch 76/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5971 - categorical_accuracy: 1.0000\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5971 - categorical_accuracy: 1.0000 - val_loss: 4.7068 - val_categorical_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.5933 - categorical_accuracy: 1.0000\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5930 - categorical_accuracy: 1.0000 - val_loss: 4.6939 - val_categorical_accuracy: 0.4545\n",
      "Epoch 78/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.5905 - categorical_accuracy: 1.0000\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5900 - categorical_accuracy: 1.0000 - val_loss: 4.6748 - val_categorical_accuracy: 0.4545\n",
      "Epoch 79/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.5909 - categorical_accuracy: 1.0000\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5906 - categorical_accuracy: 1.0000 - val_loss: 4.5424 - val_categorical_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5809 - categorical_accuracy: 1.0000\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5810 - categorical_accuracy: 1.0000 - val_loss: 4.7008 - val_categorical_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.5752 - categorical_accuracy: 1.0000\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5749 - categorical_accuracy: 1.0000 - val_loss: 4.6563 - val_categorical_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5758 - categorical_accuracy: 1.0000\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5761 - categorical_accuracy: 1.0000 - val_loss: 4.6111 - val_categorical_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.5695 - categorical_accuracy: 1.0000\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5690 - categorical_accuracy: 1.0000 - val_loss: 4.6562 - val_categorical_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5664 - categorical_accuracy: 1.0000\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5664 - categorical_accuracy: 1.0000 - val_loss: 4.6267 - val_categorical_accuracy: 0.4545\n",
      "Epoch 85/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.5632 - categorical_accuracy: 1.0000\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5630 - categorical_accuracy: 1.0000 - val_loss: 4.6664 - val_categorical_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5574 - categorical_accuracy: 1.0000\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5575 - categorical_accuracy: 1.0000 - val_loss: 4.6928 - val_categorical_accuracy: 0.4545\n",
      "Epoch 87/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.5538 - categorical_accuracy: 1.0000\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5532 - categorical_accuracy: 1.0000 - val_loss: 4.7358 - val_categorical_accuracy: 0.4545\n",
      "Epoch 88/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5497 - categorical_accuracy: 1.0000\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5496 - categorical_accuracy: 1.0000 - val_loss: 4.6896 - val_categorical_accuracy: 0.4545\n",
      "Epoch 89/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5470 - categorical_accuracy: 1.0000\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5469 - categorical_accuracy: 1.0000 - val_loss: 4.6302 - val_categorical_accuracy: 0.4545\n",
      "Epoch 90/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5414 - categorical_accuracy: 1.0000\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5412 - categorical_accuracy: 1.0000 - val_loss: 4.6150 - val_categorical_accuracy: 0.4545\n",
      "Epoch 91/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.5380 - categorical_accuracy: 1.0000\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 2.5397 - categorical_accuracy: 1.0000 - val_loss: 4.5225 - val_categorical_accuracy: 0.4545\n",
      "Epoch 92/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.5348 - categorical_accuracy: 1.0000\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5343 - categorical_accuracy: 1.0000 - val_loss: 4.5604 - val_categorical_accuracy: 0.4545\n",
      "Epoch 93/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5304 - categorical_accuracy: 1.0000\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5307 - categorical_accuracy: 1.0000 - val_loss: 4.5640 - val_categorical_accuracy: 0.4545\n",
      "Epoch 94/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5263 - categorical_accuracy: 1.0000\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5264 - categorical_accuracy: 1.0000 - val_loss: 4.5646 - val_categorical_accuracy: 0.4545\n",
      "Epoch 95/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5234 - categorical_accuracy: 1.0000\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5230 - categorical_accuracy: 1.0000 - val_loss: 4.5635 - val_categorical_accuracy: 0.4545\n",
      "Epoch 96/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5180 - categorical_accuracy: 1.0000\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5180 - categorical_accuracy: 1.0000 - val_loss: 4.6036 - val_categorical_accuracy: 0.4545\n",
      "Epoch 97/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.5141 - categorical_accuracy: 1.0000\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5138 - categorical_accuracy: 1.0000 - val_loss: 4.5974 - val_categorical_accuracy: 0.4545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5120 - categorical_accuracy: 1.0000\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5119 - categorical_accuracy: 1.0000 - val_loss: 4.6186 - val_categorical_accuracy: 0.4545\n",
      "Epoch 99/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.5070 - categorical_accuracy: 1.0000\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 2.5069 - categorical_accuracy: 1.0000 - val_loss: 4.5646 - val_categorical_accuracy: 0.4545\n",
      "Epoch 100/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5038 - categorical_accuracy: 1.0000\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.54545\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 2.5037 - categorical_accuracy: 1.0000 - val_loss: 4.5664 - val_categorical_accuracy: 0.4545\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "Test Accuracy = 0.4545454680919647\n",
      "22/22 [==============================] - 0s 11ms/step\n",
      "\n",
      "===============================================================================================================================\n",
      "=============================== Confusion_matrix for data with overlap ratio of 50% is as below ===============================\n",
      "===============================================================================================================================\n",
      "\n",
      "[[1 0 0 0 0 1 1 0 0]\n",
      " [1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 4 0 1]\n",
      " [1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3]]\n",
      "==============================================================================================================================\n",
      "[3 2 2 2 1 3 5 1 3]\n",
      "==============================================================================================================================\n",
      "\n",
      "==============================================================================================================================\n",
      "=============================== Sub Model below will be saved to be used for transfer learning  ==============================\n",
      "==============================================================================================================================\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d (GlobalMax (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 106,544\n",
      "Trainable params: 105,808\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "===============================================================================================================================\n",
      "======================================== Data with overlap ratio of 75% will be trained =======================================\n",
      "===============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(224, 103, 24, 24, 1) (61, 103, 24, 24, 1) (224,) (61,)\n",
      "Total samples per class: [0, 49, 14, 5, 13, 26, 0, 10, 0, 30, 71, 17, 9, 31, 5, 5], Total number of samples is 285.\n",
      "\n",
      "unique classes in Ytest: [ 2  3  4  5  6  8 10 11 12 13 14 15 16], Total number of samples in Ytest is 61.\n",
      "number of samples per class in Ytest: [10  3  1  3  6  2  6 15  4  2  7  1  1]\n",
      "\n",
      "Xtrain => (224, 103, 24, 24, 1)\n",
      "Xtest  => (61, 103, 24, 24, 1)\n",
      "Ytrain => (224, 13)\n",
      "Ytest  => (61, 13)\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_1 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fc_256 (Dense)                  (None, 256)          16640       global_max_pooling3d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fc13 (Dense)                    (None, 13)           3341        fc_256[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 126,525\n",
      "Trainable params: 125,789\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 224 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 5.8956 - categorical_accuracy: 0.2453\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.11475, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 6s 28ms/step - loss: 5.8621 - categorical_accuracy: 0.2411 - val_loss: 5.5728 - val_categorical_accuracy: 0.1148\n",
      "Epoch 2/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 4.9836 - categorical_accuracy: 0.3182\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.11475\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 4.9781 - categorical_accuracy: 0.3170 - val_loss: 6.5986 - val_categorical_accuracy: 0.1148\n",
      "Epoch 3/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 4.8179 - categorical_accuracy: 0.3380\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.11475\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 4.8026 - categorical_accuracy: 0.3393 - val_loss: 5.7174 - val_categorical_accuracy: 0.1148\n",
      "Epoch 4/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 4.7219 - categorical_accuracy: 0.3935\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.11475 to 0.13115, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 4.6913 - categorical_accuracy: 0.4018 - val_loss: 5.4185 - val_categorical_accuracy: 0.1311\n",
      "Epoch 5/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 4.5314 - categorical_accuracy: 0.4815\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.13115 to 0.36066, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 4.5188 - categorical_accuracy: 0.4911 - val_loss: 4.8710 - val_categorical_accuracy: 0.3607\n",
      "Epoch 6/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 4.4317 - categorical_accuracy: 0.4670\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.36066\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 4.4331 - categorical_accuracy: 0.4643 - val_loss: 4.9834 - val_categorical_accuracy: 0.3443\n",
      "Epoch 7/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 4.2489 - categorical_accuracy: 0.5755\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.36066\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 4.2361 - categorical_accuracy: 0.5714 - val_loss: 4.9556 - val_categorical_accuracy: 0.3443\n",
      "Epoch 8/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 4.0561 - categorical_accuracy: 0.6182\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.36066\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 4.0501 - categorical_accuracy: 0.6205 - val_loss: 4.7642 - val_categorical_accuracy: 0.2787\n",
      "Epoch 9/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 3.9316 - categorical_accuracy: 0.6818\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.36066 to 0.40984, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 3.9409 - categorical_accuracy: 0.6786 - val_loss: 4.6618 - val_categorical_accuracy: 0.4098\n",
      "Epoch 10/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 3.8869 - categorical_accuracy: 0.6852\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.40984\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 3.8742 - categorical_accuracy: 0.6875 - val_loss: 4.6500 - val_categorical_accuracy: 0.3934\n",
      "Epoch 11/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 3.7598 - categorical_accuracy: 0.7264\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.40984\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 3.7580 - categorical_accuracy: 0.7321 - val_loss: 4.6336 - val_categorical_accuracy: 0.3934\n",
      "Epoch 12/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 3.6800 - categorical_accuracy: 0.7837\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.40984\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 3.6672 - categorical_accuracy: 0.7902 - val_loss: 4.5375 - val_categorical_accuracy: 0.4098\n",
      "Epoch 13/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 3.5562 - categorical_accuracy: 0.8443\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.40984\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 3.5425 - categorical_accuracy: 0.8527 - val_loss: 4.4557 - val_categorical_accuracy: 0.4098\n",
      "Epoch 14/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 3.4326 - categorical_accuracy: 0.8894\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.40984\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 3.4381 - categorical_accuracy: 0.8795 - val_loss: 4.4845 - val_categorical_accuracy: 0.4098\n",
      "Epoch 15/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 3.3589 - categorical_accuracy: 0.9259\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.40984\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 3.3554 - categorical_accuracy: 0.9286 - val_loss: 4.4076 - val_categorical_accuracy: 0.3607\n",
      "Epoch 16/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 3.2868 - categorical_accuracy: 0.9409\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.40984 to 0.50820, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 3.2819 - categorical_accuracy: 0.9420 - val_loss: 4.2351 - val_categorical_accuracy: 0.5082\n",
      "Epoch 17/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 3.2375 - categorical_accuracy: 0.9375\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.50820\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 3.2266 - categorical_accuracy: 0.9420 - val_loss: 4.4038 - val_categorical_accuracy: 0.4426\n",
      "Epoch 18/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 3.1893 - categorical_accuracy: 0.9292\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.50820\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 3.1839 - categorical_accuracy: 0.9330 - val_loss: 4.3677 - val_categorical_accuracy: 0.4754\n",
      "Epoch 19/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 3.1435 - categorical_accuracy: 0.9491\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.50820\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 3.1397 - categorical_accuracy: 0.9509 - val_loss: 4.4194 - val_categorical_accuracy: 0.4262\n",
      "Epoch 20/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 3.0965 - categorical_accuracy: 0.9630\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.50820\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 3.0969 - categorical_accuracy: 0.9598 - val_loss: 4.4666 - val_categorical_accuracy: 0.4098\n",
      "Epoch 21/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 3.0400 - categorical_accuracy: 0.9861\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.50820\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 3.0359 - categorical_accuracy: 0.9866 - val_loss: 4.2551 - val_categorical_accuracy: 0.4918\n",
      "Epoch 22/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.9752 - categorical_accuracy: 0.9907\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.50820\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.9733 - categorical_accuracy: 0.9911 - val_loss: 4.5351 - val_categorical_accuracy: 0.4262\n",
      "Epoch 23/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.9742 - categorical_accuracy: 0.9906\n",
      "Epoch 00023: val_categorical_accuracy improved from 0.50820 to 0.57377, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_75_percent.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 1s 5ms/step - loss: 2.9730 - categorical_accuracy: 0.9911 - val_loss: 4.1302 - val_categorical_accuracy: 0.5738\n",
      "Epoch 24/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.9376 - categorical_accuracy: 0.9953\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.57377\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 2.9421 - categorical_accuracy: 0.9955 - val_loss: 4.2797 - val_categorical_accuracy: 0.4262\n",
      "Epoch 25/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.9373 - categorical_accuracy: 0.9818\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.57377\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.9377 - categorical_accuracy: 0.9821 - val_loss: 4.2627 - val_categorical_accuracy: 0.4426\n",
      "Epoch 26/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.9084 - categorical_accuracy: 0.9907\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.57377\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.9076 - categorical_accuracy: 0.9911 - val_loss: 4.2082 - val_categorical_accuracy: 0.4918\n",
      "Epoch 27/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.8689 - categorical_accuracy: 0.9953\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.57377\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 2.8702 - categorical_accuracy: 0.9955 - val_loss: 4.2386 - val_categorical_accuracy: 0.4754\n",
      "Epoch 28/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.8652 - categorical_accuracy: 0.9906\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.57377\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.8632 - categorical_accuracy: 0.9911 - val_loss: 4.2057 - val_categorical_accuracy: 0.5082\n",
      "Epoch 29/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.8402 - categorical_accuracy: 0.9955\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.57377\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.8414 - categorical_accuracy: 0.9955 - val_loss: 4.1680 - val_categorical_accuracy: 0.4754\n",
      "Epoch 30/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.8292 - categorical_accuracy: 0.9955\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.57377\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.8284 - categorical_accuracy: 0.9955 - val_loss: 4.0964 - val_categorical_accuracy: 0.5574\n",
      "Epoch 31/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.8022 - categorical_accuracy: 0.9954\n",
      "Epoch 00031: val_categorical_accuracy improved from 0.57377 to 0.60656, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 2.8018 - categorical_accuracy: 0.9955 - val_loss: 4.0268 - val_categorical_accuracy: 0.6066\n",
      "Epoch 32/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.8014 - categorical_accuracy: 0.9953\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 2.8001 - categorical_accuracy: 0.9955 - val_loss: 4.0322 - val_categorical_accuracy: 0.4918\n",
      "Epoch 33/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.8005 - categorical_accuracy: 0.9953\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 2.7995 - categorical_accuracy: 0.9955 - val_loss: 4.1240 - val_categorical_accuracy: 0.5082\n",
      "Epoch 34/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.7808 - categorical_accuracy: 1.0000\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.7829 - categorical_accuracy: 1.0000 - val_loss: 4.2089 - val_categorical_accuracy: 0.4754\n",
      "Epoch 35/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.7687 - categorical_accuracy: 1.0000\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.7687 - categorical_accuracy: 1.0000 - val_loss: 4.0923 - val_categorical_accuracy: 0.5082\n",
      "Epoch 36/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.7483 - categorical_accuracy: 1.0000\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.7517 - categorical_accuracy: 1.0000 - val_loss: 3.9994 - val_categorical_accuracy: 0.5574\n",
      "Epoch 37/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.7502 - categorical_accuracy: 1.0000\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.7489 - categorical_accuracy: 1.0000 - val_loss: 4.1137 - val_categorical_accuracy: 0.4918\n",
      "Epoch 38/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.7374 - categorical_accuracy: 1.0000\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.7371 - categorical_accuracy: 1.0000 - val_loss: 4.0508 - val_categorical_accuracy: 0.5410\n",
      "Epoch 39/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.7298 - categorical_accuracy: 1.0000\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.7321 - categorical_accuracy: 1.0000 - val_loss: 4.1072 - val_categorical_accuracy: 0.5246\n",
      "Epoch 40/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.7179 - categorical_accuracy: 1.0000\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.7216 - categorical_accuracy: 1.0000 - val_loss: 4.0291 - val_categorical_accuracy: 0.5082\n",
      "Epoch 41/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.7127 - categorical_accuracy: 1.0000\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.7126 - categorical_accuracy: 1.0000 - val_loss: 4.1001 - val_categorical_accuracy: 0.5082\n",
      "Epoch 42/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.7017 - categorical_accuracy: 1.0000\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.7018 - categorical_accuracy: 1.0000 - val_loss: 4.0354 - val_categorical_accuracy: 0.5082\n",
      "Epoch 43/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.6985 - categorical_accuracy: 1.0000\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6977 - categorical_accuracy: 1.0000 - val_loss: 4.0771 - val_categorical_accuracy: 0.5246\n",
      "Epoch 44/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.6819 - categorical_accuracy: 1.0000\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6829 - categorical_accuracy: 1.0000 - val_loss: 4.0301 - val_categorical_accuracy: 0.5082\n",
      "Epoch 45/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.6757 - categorical_accuracy: 1.0000\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6764 - categorical_accuracy: 1.0000 - val_loss: 4.0223 - val_categorical_accuracy: 0.4918\n",
      "Epoch 46/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.6751 - categorical_accuracy: 1.0000\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6765 - categorical_accuracy: 1.0000 - val_loss: 3.9979 - val_categorical_accuracy: 0.5410\n",
      "Epoch 47/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.6706 - categorical_accuracy: 1.0000\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6704 - categorical_accuracy: 1.0000 - val_loss: 3.9918 - val_categorical_accuracy: 0.5410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.6594 - categorical_accuracy: 1.0000\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6589 - categorical_accuracy: 1.0000 - val_loss: 4.0565 - val_categorical_accuracy: 0.4918\n",
      "Epoch 49/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.6515 - categorical_accuracy: 1.0000\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6507 - categorical_accuracy: 1.0000 - val_loss: 4.0116 - val_categorical_accuracy: 0.5410\n",
      "Epoch 50/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.6472 - categorical_accuracy: 1.0000\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6465 - categorical_accuracy: 1.0000 - val_loss: 4.0585 - val_categorical_accuracy: 0.5410\n",
      "Epoch 51/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.6375 - categorical_accuracy: 1.0000\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6374 - categorical_accuracy: 1.0000 - val_loss: 3.9662 - val_categorical_accuracy: 0.5574\n",
      "Epoch 52/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.6292 - categorical_accuracy: 1.0000\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6307 - categorical_accuracy: 1.0000 - val_loss: 3.9742 - val_categorical_accuracy: 0.5246\n",
      "Epoch 53/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.6224 - categorical_accuracy: 1.0000\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6220 - categorical_accuracy: 1.0000 - val_loss: 3.9805 - val_categorical_accuracy: 0.5246\n",
      "Epoch 54/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.6132 - categorical_accuracy: 1.0000\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6138 - categorical_accuracy: 1.0000 - val_loss: 3.9944 - val_categorical_accuracy: 0.5082\n",
      "Epoch 55/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.6146 - categorical_accuracy: 1.0000\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6141 - categorical_accuracy: 1.0000 - val_loss: 3.9763 - val_categorical_accuracy: 0.4754\n",
      "Epoch 56/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.6019 - categorical_accuracy: 1.0000\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.6017 - categorical_accuracy: 1.0000 - val_loss: 4.0056 - val_categorical_accuracy: 0.5246\n",
      "Epoch 57/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5969 - categorical_accuracy: 1.0000\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5966 - categorical_accuracy: 1.0000 - val_loss: 3.9856 - val_categorical_accuracy: 0.5246\n",
      "Epoch 58/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5938 - categorical_accuracy: 1.0000\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5937 - categorical_accuracy: 1.0000 - val_loss: 3.9009 - val_categorical_accuracy: 0.5738\n",
      "Epoch 59/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5862 - categorical_accuracy: 1.0000\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5860 - categorical_accuracy: 1.0000 - val_loss: 3.9237 - val_categorical_accuracy: 0.5082\n",
      "Epoch 60/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.5758 - categorical_accuracy: 1.0000\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5762 - categorical_accuracy: 1.0000 - val_loss: 3.9462 - val_categorical_accuracy: 0.5246\n",
      "Epoch 61/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5729 - categorical_accuracy: 1.0000\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5729 - categorical_accuracy: 1.0000 - val_loss: 4.0268 - val_categorical_accuracy: 0.4754\n",
      "Epoch 62/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5678 - categorical_accuracy: 1.0000\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5678 - categorical_accuracy: 1.0000 - val_loss: 3.9262 - val_categorical_accuracy: 0.5246\n",
      "Epoch 63/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.5597 - categorical_accuracy: 1.0000\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5597 - categorical_accuracy: 1.0000 - val_loss: 3.9106 - val_categorical_accuracy: 0.5410\n",
      "Epoch 64/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.5542 - categorical_accuracy: 1.0000\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5545 - categorical_accuracy: 1.0000 - val_loss: 3.9662 - val_categorical_accuracy: 0.5902\n",
      "Epoch 65/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5460 - categorical_accuracy: 1.0000\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5461 - categorical_accuracy: 1.0000 - val_loss: 3.9073 - val_categorical_accuracy: 0.5410\n",
      "Epoch 66/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5431 - categorical_accuracy: 1.0000\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5429 - categorical_accuracy: 1.0000 - val_loss: 3.9047 - val_categorical_accuracy: 0.5082\n",
      "Epoch 67/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5350 - categorical_accuracy: 1.0000\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5349 - categorical_accuracy: 1.0000 - val_loss: 3.9028 - val_categorical_accuracy: 0.5082\n",
      "Epoch 68/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5292 - categorical_accuracy: 1.0000\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5296 - categorical_accuracy: 1.0000 - val_loss: 3.8700 - val_categorical_accuracy: 0.5246\n",
      "Epoch 69/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5244 - categorical_accuracy: 1.0000\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5242 - categorical_accuracy: 1.0000 - val_loss: 3.9250 - val_categorical_accuracy: 0.5410\n",
      "Epoch 70/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.5188 - categorical_accuracy: 1.0000\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5183 - categorical_accuracy: 1.0000 - val_loss: 3.8625 - val_categorical_accuracy: 0.5410\n",
      "Epoch 71/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5132 - categorical_accuracy: 1.0000\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5132 - categorical_accuracy: 1.0000 - val_loss: 3.8983 - val_categorical_accuracy: 0.5246\n",
      "Epoch 72/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.5090 - categorical_accuracy: 1.0000\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5088 - categorical_accuracy: 1.0000 - val_loss: 3.8655 - val_categorical_accuracy: 0.5410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5005 - categorical_accuracy: 1.0000\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.5003 - categorical_accuracy: 1.0000 - val_loss: 3.8777 - val_categorical_accuracy: 0.5082\n",
      "Epoch 74/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4954 - categorical_accuracy: 1.0000\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4955 - categorical_accuracy: 1.0000 - val_loss: 3.8889 - val_categorical_accuracy: 0.5246\n",
      "Epoch 75/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4891 - categorical_accuracy: 1.0000\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4890 - categorical_accuracy: 1.0000 - val_loss: 3.9042 - val_categorical_accuracy: 0.5246\n",
      "Epoch 76/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4848 - categorical_accuracy: 1.0000\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4846 - categorical_accuracy: 1.0000 - val_loss: 3.8900 - val_categorical_accuracy: 0.5082\n",
      "Epoch 77/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.4776 - categorical_accuracy: 1.0000\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4775 - categorical_accuracy: 1.0000 - val_loss: 3.8620 - val_categorical_accuracy: 0.5410\n",
      "Epoch 78/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4733 - categorical_accuracy: 1.0000\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4731 - categorical_accuracy: 1.0000 - val_loss: 3.8590 - val_categorical_accuracy: 0.5082\n",
      "Epoch 79/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4686 - categorical_accuracy: 1.0000\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4689 - categorical_accuracy: 1.0000 - val_loss: 3.9350 - val_categorical_accuracy: 0.5082\n",
      "Epoch 80/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4631 - categorical_accuracy: 1.0000\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4628 - categorical_accuracy: 1.0000 - val_loss: 3.8499 - val_categorical_accuracy: 0.5082\n",
      "Epoch 81/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.4560 - categorical_accuracy: 1.0000\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4561 - categorical_accuracy: 1.0000 - val_loss: 3.8694 - val_categorical_accuracy: 0.5410\n",
      "Epoch 82/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.4509 - categorical_accuracy: 1.0000\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4510 - categorical_accuracy: 1.0000 - val_loss: 3.8724 - val_categorical_accuracy: 0.5410\n",
      "Epoch 83/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.4448 - categorical_accuracy: 1.0000\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4449 - categorical_accuracy: 1.0000 - val_loss: 3.8186 - val_categorical_accuracy: 0.5082\n",
      "Epoch 84/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.4413 - categorical_accuracy: 1.0000\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4410 - categorical_accuracy: 1.0000 - val_loss: 3.8140 - val_categorical_accuracy: 0.5246\n",
      "Epoch 85/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.4350 - categorical_accuracy: 1.0000\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4349 - categorical_accuracy: 1.0000 - val_loss: 3.8219 - val_categorical_accuracy: 0.5574\n",
      "Epoch 86/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.4292 - categorical_accuracy: 1.0000\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4291 - categorical_accuracy: 1.0000 - val_loss: 3.7661 - val_categorical_accuracy: 0.5246\n",
      "Epoch 87/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.4236 - categorical_accuracy: 1.0000\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4235 - categorical_accuracy: 1.0000 - val_loss: 3.8032 - val_categorical_accuracy: 0.5082\n",
      "Epoch 88/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.4179 - categorical_accuracy: 1.0000\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4176 - categorical_accuracy: 1.0000 - val_loss: 3.7750 - val_categorical_accuracy: 0.5246\n",
      "Epoch 89/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4154 - categorical_accuracy: 1.0000\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4151 - categorical_accuracy: 1.0000 - val_loss: 3.7762 - val_categorical_accuracy: 0.5410\n",
      "Epoch 90/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.4091 - categorical_accuracy: 1.0000\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4087 - categorical_accuracy: 1.0000 - val_loss: 3.8089 - val_categorical_accuracy: 0.5082\n",
      "Epoch 91/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.4032 - categorical_accuracy: 1.0000\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.4030 - categorical_accuracy: 1.0000 - val_loss: 3.7807 - val_categorical_accuracy: 0.5246\n",
      "Epoch 92/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.3980 - categorical_accuracy: 1.0000\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.3978 - categorical_accuracy: 1.0000 - val_loss: 3.7926 - val_categorical_accuracy: 0.5410\n",
      "Epoch 93/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.3914 - categorical_accuracy: 1.0000\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.3913 - categorical_accuracy: 1.0000 - val_loss: 3.7762 - val_categorical_accuracy: 0.5574\n",
      "Epoch 94/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.3867 - categorical_accuracy: 1.0000\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.3867 - categorical_accuracy: 1.0000 - val_loss: 3.8247 - val_categorical_accuracy: 0.5246\n",
      "Epoch 95/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.3807 - categorical_accuracy: 1.0000\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.3806 - categorical_accuracy: 1.0000 - val_loss: 3.7752 - val_categorical_accuracy: 0.5246\n",
      "Epoch 96/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.3761 - categorical_accuracy: 1.0000\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.3761 - categorical_accuracy: 1.0000 - val_loss: 3.7532 - val_categorical_accuracy: 0.5246\n",
      "Epoch 97/100\n",
      "208/224 [==========================>...] - ETA: 0s - loss: 2.3710 - categorical_accuracy: 1.0000\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.3710 - categorical_accuracy: 1.0000 - val_loss: 3.7525 - val_categorical_accuracy: 0.5246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.3656 - categorical_accuracy: 1.0000\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.3656 - categorical_accuracy: 1.0000 - val_loss: 3.7803 - val_categorical_accuracy: 0.5082\n",
      "Epoch 99/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.3612 - categorical_accuracy: 1.0000\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.3607 - categorical_accuracy: 1.0000 - val_loss: 3.7586 - val_categorical_accuracy: 0.5410\n",
      "Epoch 100/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.3556 - categorical_accuracy: 1.0000\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 2.3554 - categorical_accuracy: 1.0000 - val_loss: 3.7604 - val_categorical_accuracy: 0.5082\n",
      "61/61 [==============================] - 0s 2ms/step\n",
      "Test Accuracy = 0.5081967169144115\n",
      "61/61 [==============================] - 0s 6ms/step\n",
      "\n",
      "===============================================================================================================================\n",
      "=============================== Confusion_matrix for data with overlap ratio of 75% is as below ===============================\n",
      "===============================================================================================================================\n",
      "\n",
      "[[ 4  0  0  0  2  0  0  2  2  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  4  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  1  0  1  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  2  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  1  0 12  0  0  1  0  0]\n",
      " [ 1  2  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  7  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0]]\n",
      "==============================================================================================================================\n",
      "[10  3  1  3  6  2  6 15  4  2  7  1  1]\n",
      "==============================================================================================================================\n",
      "\n",
      "==============================================================================================================================\n",
      "=============================== Sub Model below will be saved to be used for transfer learning  ==============================\n",
      "==============================================================================================================================\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_1 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 106,544\n",
      "Trainable params: 105,808\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===============================================================================================================================\n",
      "======================================== Data with overlap ratio of 85% will be trained =======================================\n",
      "===============================================================================================================================\n",
      "\n",
      "\n",
      "(639, 103, 24, 24, 1) (169, 103, 24, 24, 1) (639,) (169,)\n",
      "Total samples per class: [6, 135, 36, 11, 33, 77, 4, 29, 4, 83, 216, 43, 21, 89, 11, 10], Total number of samples is 808.\n",
      "\n",
      "unique classes in Ytest: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16], Total number of samples in Ytest is 169.\n",
      "number of samples per class in Ytest: [ 2 27  8  3  7 16  1  6  1 17 44  9  5 18  3  2]\n",
      "\n",
      "Xtrain => (639, 103, 24, 24, 1)\n",
      "Xtest  => (169, 103, 24, 24, 1)\n",
      "Ytrain => (639, 16)\n",
      "Ytest  => (169, 16)\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_2 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fc_256 (Dense)                  (None, 256)          16640       global_max_pooling3d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fc16 (Dense)                    (None, 16)           4112        fc_256[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 127,296\n",
      "Trainable params: 126,560\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 639 samples, validate on 169 samples\n",
      "Epoch 1/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 5.6004 - categorical_accuracy: 0.2971\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.10651, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 8s 13ms/step - loss: 5.5738 - categorical_accuracy: 0.2989 - val_loss: 5.4777 - val_categorical_accuracy: 0.1065\n",
      "Epoch 2/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 4.8470 - categorical_accuracy: 0.3799\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.10651 to 0.11243, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 4.8347 - categorical_accuracy: 0.3834 - val_loss: 5.3746 - val_categorical_accuracy: 0.1124\n",
      "Epoch 3/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 4.6195 - categorical_accuracy: 0.4529\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.11243 to 0.18343, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 4.6115 - categorical_accuracy: 0.4538 - val_loss: 5.4163 - val_categorical_accuracy: 0.1834\n",
      "Epoch 4/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 4.4332 - categorical_accuracy: 0.4937\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.18343 to 0.28402, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 4.4343 - categorical_accuracy: 0.4945 - val_loss: 4.9988 - val_categorical_accuracy: 0.2840\n",
      "Epoch 5/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 4.2495 - categorical_accuracy: 0.5396\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.28402\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 4.2456 - categorical_accuracy: 0.5415 - val_loss: 5.1090 - val_categorical_accuracy: 0.2781\n",
      "Epoch 6/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 4.1209 - categorical_accuracy: 0.5942\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.28402 to 0.39645, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 4.1210 - categorical_accuracy: 0.5962 - val_loss: 4.7380 - val_categorical_accuracy: 0.3964\n",
      "Epoch 7/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.9964 - categorical_accuracy: 0.6377\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.39645 to 0.55030, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.9945 - categorical_accuracy: 0.6385 - val_loss: 4.4020 - val_categorical_accuracy: 0.5503\n",
      "Epoch 8/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 3.8201 - categorical_accuracy: 0.7224\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.55030 to 0.55621, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.8253 - categorical_accuracy: 0.7167 - val_loss: 4.4849 - val_categorical_accuracy: 0.5562\n",
      "Epoch 9/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 3.7688 - categorical_accuracy: 0.7147\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.55621\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.7610 - categorical_accuracy: 0.7199 - val_loss: 4.4583 - val_categorical_accuracy: 0.5148\n",
      "Epoch 10/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 3.6446 - categorical_accuracy: 0.7660\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.55621\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 3.6393 - categorical_accuracy: 0.7684 - val_loss: 4.5044 - val_categorical_accuracy: 0.4201\n",
      "Epoch 11/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.5400 - categorical_accuracy: 0.7911 ETA: 1s - loss: 3.5\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.55621\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.5431 - categorical_accuracy: 0.7887 - val_loss: 4.3457 - val_categorical_accuracy: 0.5444\n",
      "Epoch 12/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 3.4656 - categorical_accuracy: 0.8269\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.55621 to 0.59763, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.4632 - categorical_accuracy: 0.8279 - val_loss: 4.2403 - val_categorical_accuracy: 0.5976\n",
      "Epoch 13/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.4033 - categorical_accuracy: 0.8513\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.59763\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.4005 - categorical_accuracy: 0.8529 - val_loss: 4.3343 - val_categorical_accuracy: 0.5680\n",
      "Epoch 14/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.3398 - categorical_accuracy: 0.8687\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.59763\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 3.3363 - categorical_accuracy: 0.8701 - val_loss: 4.3792 - val_categorical_accuracy: 0.5030\n",
      "Epoch 15/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 3.2493 - categorical_accuracy: 0.8945\n",
      "Epoch 00015: val_categorical_accuracy improved from 0.59763 to 0.63314, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.2459 - categorical_accuracy: 0.8967 - val_loss: 4.0531 - val_categorical_accuracy: 0.6331\n",
      "Epoch 16/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.2068 - categorical_accuracy: 0.9051\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.63314 to 0.66272, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.2095 - categorical_accuracy: 0.9045 - val_loss: 4.0018 - val_categorical_accuracy: 0.6627\n",
      "Epoch 17/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.1500 - categorical_accuracy: 0.9256\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.1491 - categorical_accuracy: 0.9264 - val_loss: 4.1315 - val_categorical_accuracy: 0.5680\n",
      "Epoch 18/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 3.0829 - categorical_accuracy: 0.9375\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 3.0835 - categorical_accuracy: 0.9358 - val_loss: 4.0980 - val_categorical_accuracy: 0.6213\n",
      "Epoch 19/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.0597 - categorical_accuracy: 0.9415\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.66272 to 0.70414, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.0598 - categorical_accuracy: 0.9421 - val_loss: 3.9487 - val_categorical_accuracy: 0.7041\n",
      "Epoch 20/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 3.0209 - categorical_accuracy: 0.9567\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.70414\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 3.0215 - categorical_accuracy: 0.9562 - val_loss: 4.3640 - val_categorical_accuracy: 0.5858\n",
      "Epoch 21/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.9924 - categorical_accuracy: 0.9562\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.70414\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.9927 - categorical_accuracy: 0.9562 - val_loss: 3.8679 - val_categorical_accuracy: 0.6923\n",
      "Epoch 22/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.9420 - categorical_accuracy: 0.9763\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.70414\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.9410 - categorical_accuracy: 0.9765 - val_loss: 3.8891 - val_categorical_accuracy: 0.6923\n",
      "Epoch 23/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.9128 - categorical_accuracy: 0.9778\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.70414\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.9116 - categorical_accuracy: 0.9781 - val_loss: 3.8805 - val_categorical_accuracy: 0.6982\n",
      "Epoch 24/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.8808 - categorical_accuracy: 0.9854\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.70414\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.8829 - categorical_accuracy: 0.9844 - val_loss: 3.8395 - val_categorical_accuracy: 0.6923\n",
      "Epoch 25/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.8645 - categorical_accuracy: 0.9873\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.70414\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.8640 - categorical_accuracy: 0.9875 - val_loss: 3.9922 - val_categorical_accuracy: 0.5917\n",
      "Epoch 26/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.8339 - categorical_accuracy: 0.9905\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.70414\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.8366 - categorical_accuracy: 0.9890 - val_loss: 3.9160 - val_categorical_accuracy: 0.6864\n",
      "Epoch 27/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.8107 - categorical_accuracy: 0.9953\n",
      "Epoch 00027: val_categorical_accuracy improved from 0.70414 to 0.72189, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.8101 - categorical_accuracy: 0.9953 - val_loss: 3.8635 - val_categorical_accuracy: 0.7219\n",
      "Epoch 28/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.8015 - categorical_accuracy: 0.9937\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.8015 - categorical_accuracy: 0.9937 - val_loss: 3.8004 - val_categorical_accuracy: 0.6627\n",
      "Epoch 29/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.7749 - categorical_accuracy: 0.9921\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.7740 - categorical_accuracy: 0.9922 - val_loss: 3.8415 - val_categorical_accuracy: 0.6864\n",
      "Epoch 30/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.7461 - categorical_accuracy: 0.9953\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.7463 - categorical_accuracy: 0.9953 - val_loss: 3.9843 - val_categorical_accuracy: 0.6568\n",
      "Epoch 31/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.7496 - categorical_accuracy: 0.9919\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.7491 - categorical_accuracy: 0.9922 - val_loss: 3.8219 - val_categorical_accuracy: 0.7101\n",
      "Epoch 32/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.7303 - categorical_accuracy: 0.9968\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.7292 - categorical_accuracy: 0.9969 - val_loss: 3.7548 - val_categorical_accuracy: 0.6805\n",
      "Epoch 33/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.7074 - categorical_accuracy: 0.9984\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.7079 - categorical_accuracy: 0.9984 - val_loss: 3.8021 - val_categorical_accuracy: 0.6864\n",
      "Epoch 34/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.6977 - categorical_accuracy: 0.9951\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.6995 - categorical_accuracy: 0.9953 - val_loss: 3.8137 - val_categorical_accuracy: 0.6746\n",
      "Epoch 35/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.6844 - categorical_accuracy: 0.9984\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.6840 - categorical_accuracy: 0.9984 - val_loss: 3.7390 - val_categorical_accuracy: 0.6746\n",
      "Epoch 36/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.6711 - categorical_accuracy: 1.0000\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.6713 - categorical_accuracy: 1.0000 - val_loss: 3.7544 - val_categorical_accuracy: 0.6982\n",
      "Epoch 37/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.6563 - categorical_accuracy: 1.0000\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.6561 - categorical_accuracy: 1.0000 - val_loss: 3.8431 - val_categorical_accuracy: 0.6805\n",
      "Epoch 38/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.6411 - categorical_accuracy: 1.0000\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.6406 - categorical_accuracy: 1.0000 - val_loss: 3.7569 - val_categorical_accuracy: 0.6805\n",
      "Epoch 39/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.6266 - categorical_accuracy: 1.0000\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.6269 - categorical_accuracy: 1.0000 - val_loss: 3.7218 - val_categorical_accuracy: 0.6923\n",
      "Epoch 40/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.6192 - categorical_accuracy: 1.0000\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.6192 - categorical_accuracy: 1.0000 - val_loss: 3.8463 - val_categorical_accuracy: 0.6746\n",
      "Epoch 41/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.6103 - categorical_accuracy: 1.0000\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.6099 - categorical_accuracy: 1.0000 - val_loss: 3.7919 - val_categorical_accuracy: 0.6923\n",
      "Epoch 42/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.5998 - categorical_accuracy: 1.0000\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.6006 - categorical_accuracy: 1.0000 - val_loss: 3.7342 - val_categorical_accuracy: 0.7219\n",
      "Epoch 43/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.5856 - categorical_accuracy: 0.9984\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.5855 - categorical_accuracy: 0.9984 - val_loss: 3.7134 - val_categorical_accuracy: 0.6982\n",
      "Epoch 44/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.5806 - categorical_accuracy: 1.0000\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.5806 - categorical_accuracy: 1.0000 - val_loss: 3.6639 - val_categorical_accuracy: 0.7101\n",
      "Epoch 45/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.5714 - categorical_accuracy: 1.0000\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.5715 - categorical_accuracy: 1.0000 - val_loss: 3.6597 - val_categorical_accuracy: 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.5601 - categorical_accuracy: 1.0000\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.5600 - categorical_accuracy: 1.0000 - val_loss: 3.7396 - val_categorical_accuracy: 0.6923\n",
      "Epoch 47/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.5556 - categorical_accuracy: 1.0000\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.5548 - categorical_accuracy: 1.0000 - val_loss: 3.7355 - val_categorical_accuracy: 0.6923\n",
      "Epoch 48/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.5420 - categorical_accuracy: 0.9984\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.5417 - categorical_accuracy: 0.9984 - val_loss: 3.6829 - val_categorical_accuracy: 0.6923\n",
      "Epoch 49/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.5309 - categorical_accuracy: 1.0000\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.5306 - categorical_accuracy: 1.0000 - val_loss: 3.7261 - val_categorical_accuracy: 0.6686\n",
      "Epoch 50/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.5244 - categorical_accuracy: 1.0000\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.5242 - categorical_accuracy: 1.0000 - val_loss: 3.6775 - val_categorical_accuracy: 0.7101\n",
      "Epoch 51/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.5146 - categorical_accuracy: 1.0000\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.5145 - categorical_accuracy: 1.0000 - val_loss: 3.7084 - val_categorical_accuracy: 0.6864\n",
      "Epoch 52/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.5066 - categorical_accuracy: 1.0000\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.5073 - categorical_accuracy: 1.0000 - val_loss: 3.6616 - val_categorical_accuracy: 0.7160\n",
      "Epoch 53/100\n",
      "608/639 [===========================>..] - ETA: 0s - loss: 2.4988 - categorical_accuracy: 1.0000\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.4983 - categorical_accuracy: 1.0000 - val_loss: 3.6327 - val_categorical_accuracy: 0.6923\n",
      "Epoch 54/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4886 - categorical_accuracy: 1.0000\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.4891 - categorical_accuracy: 1.0000 - val_loss: 3.6058 - val_categorical_accuracy: 0.7041\n",
      "Epoch 55/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.4806 - categorical_accuracy: 1.0000\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.4805 - categorical_accuracy: 1.0000 - val_loss: 3.6326 - val_categorical_accuracy: 0.6982\n",
      "Epoch 56/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4731 - categorical_accuracy: 1.0000\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.4730 - categorical_accuracy: 1.0000 - val_loss: 3.6579 - val_categorical_accuracy: 0.6982\n",
      "Epoch 57/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4634 - categorical_accuracy: 1.0000\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.4638 - categorical_accuracy: 1.0000 - val_loss: 3.6665 - val_categorical_accuracy: 0.6923\n",
      "Epoch 58/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4556 - categorical_accuracy: 1.0000\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.4554 - categorical_accuracy: 1.0000 - val_loss: 3.6495 - val_categorical_accuracy: 0.7101\n",
      "Epoch 59/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4481 - categorical_accuracy: 1.0000\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.4483 - categorical_accuracy: 1.0000 - val_loss: 3.6244 - val_categorical_accuracy: 0.6923\n",
      "Epoch 60/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4416 - categorical_accuracy: 1.0000\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.72189\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.4415 - categorical_accuracy: 1.0000 - val_loss: 3.5637 - val_categorical_accuracy: 0.7041\n",
      "Epoch 61/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4325 - categorical_accuracy: 1.0000\n",
      "Epoch 00061: val_categorical_accuracy improved from 0.72189 to 0.72781, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.4324 - categorical_accuracy: 1.0000 - val_loss: 3.6273 - val_categorical_accuracy: 0.7278\n",
      "Epoch 62/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.4231 - categorical_accuracy: 1.0000\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.4234 - categorical_accuracy: 1.0000 - val_loss: 3.5254 - val_categorical_accuracy: 0.7041\n",
      "Epoch 63/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4158 - categorical_accuracy: 1.0000\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.4159 - categorical_accuracy: 1.0000 - val_loss: 3.5774 - val_categorical_accuracy: 0.7160\n",
      "Epoch 64/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4080 - categorical_accuracy: 1.0000\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.4085 - categorical_accuracy: 1.0000 - val_loss: 3.5817 - val_categorical_accuracy: 0.6982\n",
      "Epoch 65/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3990 - categorical_accuracy: 1.0000\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3991 - categorical_accuracy: 1.0000 - val_loss: 3.6022 - val_categorical_accuracy: 0.6864\n",
      "Epoch 66/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3923 - categorical_accuracy: 1.0000\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3922 - categorical_accuracy: 1.0000 - val_loss: 3.6160 - val_categorical_accuracy: 0.6864\n",
      "Epoch 67/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.3847 - categorical_accuracy: 1.0000\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3846 - categorical_accuracy: 1.0000 - val_loss: 3.6785 - val_categorical_accuracy: 0.6746\n",
      "Epoch 68/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3759 - categorical_accuracy: 1.0000\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3763 - categorical_accuracy: 1.0000 - val_loss: 3.5581 - val_categorical_accuracy: 0.6982\n",
      "Epoch 69/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.3696 - categorical_accuracy: 1.0000\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3694 - categorical_accuracy: 1.0000 - val_loss: 3.5675 - val_categorical_accuracy: 0.6982\n",
      "Epoch 70/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3623 - categorical_accuracy: 1.0000\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3623 - categorical_accuracy: 1.0000 - val_loss: 3.5658 - val_categorical_accuracy: 0.7101\n",
      "Epoch 71/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.3544 - categorical_accuracy: 1.0000\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3541 - categorical_accuracy: 1.0000 - val_loss: 3.5063 - val_categorical_accuracy: 0.7041\n",
      "Epoch 72/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.3458 - categorical_accuracy: 1.0000\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3455 - categorical_accuracy: 1.0000 - val_loss: 3.5062 - val_categorical_accuracy: 0.6982\n",
      "Epoch 73/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3385 - categorical_accuracy: 1.0000\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3385 - categorical_accuracy: 1.0000 - val_loss: 3.5581 - val_categorical_accuracy: 0.7101\n",
      "Epoch 74/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3319 - categorical_accuracy: 1.0000\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3317 - categorical_accuracy: 1.0000 - val_loss: 3.5998 - val_categorical_accuracy: 0.7101\n",
      "Epoch 75/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3249 - categorical_accuracy: 1.0000\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3251 - categorical_accuracy: 1.0000 - val_loss: 3.5043 - val_categorical_accuracy: 0.6982\n",
      "Epoch 76/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3194 - categorical_accuracy: 1.0000\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3193 - categorical_accuracy: 1.0000 - val_loss: 3.4084 - val_categorical_accuracy: 0.6982\n",
      "Epoch 77/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3103 - categorical_accuracy: 1.0000\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.3108 - categorical_accuracy: 1.0000 - val_loss: 3.5445 - val_categorical_accuracy: 0.6864\n",
      "Epoch 78/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3018 - categorical_accuracy: 1.0000\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.3017 - categorical_accuracy: 1.0000 - val_loss: 3.5448 - val_categorical_accuracy: 0.7041\n",
      "Epoch 79/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2956 - categorical_accuracy: 1.0000 ETA: 0s - loss: 2.2974 - categorica\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2956 - categorical_accuracy: 1.0000 - val_loss: 3.5098 - val_categorical_accuracy: 0.7101\n",
      "Epoch 80/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2873 - categorical_accuracy: 1.0000\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2874 - categorical_accuracy: 1.0000 - val_loss: 3.5128 - val_categorical_accuracy: 0.6864\n",
      "Epoch 81/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2816 - categorical_accuracy: 1.0000\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2815 - categorical_accuracy: 1.0000 - val_loss: 3.4359 - val_categorical_accuracy: 0.6923\n",
      "Epoch 82/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2736 - categorical_accuracy: 1.0000\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2735 - categorical_accuracy: 1.0000 - val_loss: 3.4971 - val_categorical_accuracy: 0.7041\n",
      "Epoch 83/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.2679 - categorical_accuracy: 1.0000\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2676 - categorical_accuracy: 1.0000 - val_loss: 3.4262 - val_categorical_accuracy: 0.6923\n",
      "Epoch 84/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2603 - categorical_accuracy: 1.0000\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2605 - categorical_accuracy: 1.0000 - val_loss: 3.5214 - val_categorical_accuracy: 0.7041\n",
      "Epoch 85/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.2530 - categorical_accuracy: 1.0000\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2530 - categorical_accuracy: 1.0000 - val_loss: 3.4538 - val_categorical_accuracy: 0.6982\n",
      "Epoch 86/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2468 - categorical_accuracy: 1.0000\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2468 - categorical_accuracy: 1.0000 - val_loss: 3.4215 - val_categorical_accuracy: 0.7041\n",
      "Epoch 87/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.2393 - categorical_accuracy: 1.0000\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2397 - categorical_accuracy: 1.0000 - val_loss: 3.4361 - val_categorical_accuracy: 0.6982\n",
      "Epoch 88/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2314 - categorical_accuracy: 1.0000\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2314 - categorical_accuracy: 1.0000 - val_loss: 3.4684 - val_categorical_accuracy: 0.6982\n",
      "Epoch 89/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2278 - categorical_accuracy: 1.0000\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2277 - categorical_accuracy: 1.0000 - val_loss: 3.4293 - val_categorical_accuracy: 0.7041\n",
      "Epoch 90/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2182 - categorical_accuracy: 1.0000\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2181 - categorical_accuracy: 1.0000 - val_loss: 3.4055 - val_categorical_accuracy: 0.7219\n",
      "Epoch 91/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.2118 - categorical_accuracy: 1.0000\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2117 - categorical_accuracy: 1.0000 - val_loss: 3.3932 - val_categorical_accuracy: 0.7278\n",
      "Epoch 92/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2046 - categorical_accuracy: 1.0000\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.2045 - categorical_accuracy: 1.0000 - val_loss: 3.4544 - val_categorical_accuracy: 0.7101\n",
      "Epoch 93/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.1996 - categorical_accuracy: 1.0000\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 3ms/step - loss: 2.1995 - categorical_accuracy: 1.0000 - val_loss: 3.4244 - val_categorical_accuracy: 0.6982\n",
      "Epoch 94/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.1921 - categorical_accuracy: 1.0000\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.1922 - categorical_accuracy: 1.0000 - val_loss: 3.4218 - val_categorical_accuracy: 0.7160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.1851 - categorical_accuracy: 1.0000\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.1850 - categorical_accuracy: 1.0000 - val_loss: 3.3987 - val_categorical_accuracy: 0.7101\n",
      "Epoch 96/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.1776 - categorical_accuracy: 1.0000\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.1778 - categorical_accuracy: 1.0000 - val_loss: 3.4052 - val_categorical_accuracy: 0.7160\n",
      "Epoch 97/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.1710 - categorical_accuracy: 1.0000\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.1710 - categorical_accuracy: 1.0000 - val_loss: 3.3941 - val_categorical_accuracy: 0.7219\n",
      "Epoch 98/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.1653 - categorical_accuracy: 1.0000\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.1652 - categorical_accuracy: 1.0000 - val_loss: 3.3837 - val_categorical_accuracy: 0.7041\n",
      "Epoch 99/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.1599 - categorical_accuracy: 1.0000\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.1599 - categorical_accuracy: 1.0000 - val_loss: 3.4192 - val_categorical_accuracy: 0.7041\n",
      "Epoch 100/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.1513 - categorical_accuracy: 1.0000\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.72781\n",
      "639/639 [==============================] - 2s 2ms/step - loss: 2.1513 - categorical_accuracy: 1.0000 - val_loss: 3.3608 - val_categorical_accuracy: 0.7278\n",
      "169/169 [==============================] - 0s 691us/step\n",
      "Test Accuracy = 0.7278106519456445\n",
      "169/169 [==============================] - 1s 4ms/step\n",
      "\n",
      "===============================================================================================================================\n",
      "=============================== Confusion_matrix for data with overlap ratio of 85% is as below ===============================\n",
      "===============================================================================================================================\n",
      "\n",
      "[[ 1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 24  0  0  1  0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0]\n",
      " [ 0  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  3  2  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 15  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  4  0  0  0  0  0  0  0  9  4  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  1  0  0  0  0 38  0  4  0  0  0]\n",
      " [ 0  6  0  1  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1]]\n",
      "==============================================================================================================================\n",
      "[ 2 27  8  3  7 16  1  6  1 17 44  9  5 18  3  2]\n",
      "==============================================================================================================================\n",
      "\n",
      "==============================================================================================================================\n",
      "=============================== Sub Model below will be saved to be used for transfer learning  ==============================\n",
      "==============================================================================================================================\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_2 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 106,544\n",
      "Trainable params: 105,808\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===============================================================================================================================\n",
      "======================================== Data with overlap ratio of 95% will be trained =======================================\n",
      "===============================================================================================================================\n",
      "\n",
      "\n",
      "(3109, 103, 24, 24, 1) (785, 103, 24, 24, 1) (3109,) (785,)\n",
      "Total samples per class: [24, 668, 177, 45, 137, 365, 14, 141, 10, 408, 1067, 181, 101, 465, 46, 45], Total number of samples is 3894.\n",
      "\n",
      "unique classes in Ytest: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16], Total number of samples in Ytest is 785.\n",
      "number of samples per class in Ytest: [  5 134  36   9  28  73   3  29   2  82 214  37  21  93  10   9]\n",
      "\n",
      "Xtrain => (3109, 103, 24, 24, 1)\n",
      "Xtest  => (785, 103, 24, 24, 1)\n",
      "Ytrain => (3109, 16)\n",
      "Ytest  => (785, 16)\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_3 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fc_256 (Dense)                  (None, 256)          16640       global_max_pooling3d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fc16 (Dense)                    (None, 16)           4112        fc_256[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 127,296\n",
      "Trainable params: 126,560\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3109 samples, validate on 785 samples\n",
      "Epoch 1/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 4.8190 - categorical_accuracy: 0.4702\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.14777, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 14s 4ms/step - loss: 4.8157 - categorical_accuracy: 0.4712 - val_loss: 5.3855 - val_categorical_accuracy: 0.1478\n",
      "Epoch 2/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 3.9805 - categorical_accuracy: 0.6784\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.14777 to 0.62420, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 3.9809 - categorical_accuracy: 0.6787 - val_loss: 4.3202 - val_categorical_accuracy: 0.6242\n",
      "Epoch 3/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 3.6750 - categorical_accuracy: 0.7630\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.62420\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 3.6766 - categorical_accuracy: 0.7623 - val_loss: 4.3019 - val_categorical_accuracy: 0.5478\n",
      "Epoch 4/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 3.4573 - categorical_accuracy: 0.8280\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.62420\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 3.4580 - categorical_accuracy: 0.8273 - val_loss: 4.3507 - val_categorical_accuracy: 0.5847\n",
      "Epoch 5/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 3.2943 - categorical_accuracy: 0.8744\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.62420 to 0.68790, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 3.2952 - categorical_accuracy: 0.8742 - val_loss: 3.7769 - val_categorical_accuracy: 0.6879\n",
      "Epoch 6/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 3.1717 - categorical_accuracy: 0.9050\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.68790\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 3.1721 - categorical_accuracy: 0.9048 - val_loss: 4.1800 - val_categorical_accuracy: 0.6025\n",
      "Epoch 7/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 3.0709 - categorical_accuracy: 0.9303\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.68790\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 3.0706 - categorical_accuracy: 0.9302 - val_loss: 3.9040 - val_categorical_accuracy: 0.6624\n",
      "Epoch 8/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.9912 - categorical_accuracy: 0.9497\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.68790 to 0.69554, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.9916 - categorical_accuracy: 0.9495 - val_loss: 3.7429 - val_categorical_accuracy: 0.6955\n",
      "Epoch 9/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.9230 - categorical_accuracy: 0.9630\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.69554\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.9228 - categorical_accuracy: 0.9630 - val_loss: 3.8365 - val_categorical_accuracy: 0.6752\n",
      "Epoch 10/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.8672 - categorical_accuracy: 0.9694\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.69554 to 0.73503, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.8694 - categorical_accuracy: 0.9691 - val_loss: 3.5563 - val_categorical_accuracy: 0.7350\n",
      "Epoch 11/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.8222 - categorical_accuracy: 0.9808\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.73503\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.8214 - categorical_accuracy: 0.9807 - val_loss: 3.5684 - val_categorical_accuracy: 0.7197\n",
      "Epoch 12/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.7741 - categorical_accuracy: 0.9837\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.73503\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.7741 - categorical_accuracy: 0.9836 - val_loss: 3.6006 - val_categorical_accuracy: 0.7197\n",
      "Epoch 13/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.7393 - categorical_accuracy: 0.9878\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.73503\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.7392 - categorical_accuracy: 0.9878 - val_loss: 3.6000 - val_categorical_accuracy: 0.7210\n",
      "Epoch 14/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.7065 - categorical_accuracy: 0.9896\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.73503\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.7058 - categorical_accuracy: 0.9897 - val_loss: 3.5663 - val_categorical_accuracy: 0.7057\n",
      "Epoch 15/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.6728 - categorical_accuracy: 0.9929\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.73503\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.6728 - categorical_accuracy: 0.9929 - val_loss: 3.5856 - val_categorical_accuracy: 0.7159\n",
      "Epoch 16/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.6451 - categorical_accuracy: 0.9916\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.73503\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.6451 - categorical_accuracy: 0.9916 - val_loss: 3.5279 - val_categorical_accuracy: 0.7248\n",
      "Epoch 17/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.6161 - categorical_accuracy: 0.9951\n",
      "Epoch 00017: val_categorical_accuracy improved from 0.73503 to 0.74395, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.6162 - categorical_accuracy: 0.9952 - val_loss: 3.4099 - val_categorical_accuracy: 0.7439\n",
      "Epoch 18/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.5923 - categorical_accuracy: 0.9955\n",
      "Epoch 00018: val_categorical_accuracy improved from 0.74395 to 0.74904, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.5923 - categorical_accuracy: 0.9955 - val_loss: 3.3954 - val_categorical_accuracy: 0.7490\n",
      "Epoch 19/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.5704 - categorical_accuracy: 0.9961\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.74904 to 0.75541, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.5701 - categorical_accuracy: 0.9961 - val_loss: 3.3573 - val_categorical_accuracy: 0.7554\n",
      "Epoch 20/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.5429 - categorical_accuracy: 0.9974\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.75541\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.5429 - categorical_accuracy: 0.9974 - val_loss: 3.3908 - val_categorical_accuracy: 0.7478\n",
      "Epoch 21/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.5201 - categorical_accuracy: 0.9977\n",
      "Epoch 00021: val_categorical_accuracy improved from 0.75541 to 0.75796, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.5199 - categorical_accuracy: 0.9977 - val_loss: 3.3838 - val_categorical_accuracy: 0.7580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.4962 - categorical_accuracy: 0.9987\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.75796\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.4960 - categorical_accuracy: 0.9987 - val_loss: 3.3620 - val_categorical_accuracy: 0.7363\n",
      "Epoch 23/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.4735 - categorical_accuracy: 0.9990\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.75796\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.4735 - categorical_accuracy: 0.9990 - val_loss: 3.3004 - val_categorical_accuracy: 0.7503\n",
      "Epoch 24/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.4548 - categorical_accuracy: 0.9997\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.75796\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.4546 - categorical_accuracy: 0.9997 - val_loss: 3.3756 - val_categorical_accuracy: 0.7452\n",
      "Epoch 25/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.4342 - categorical_accuracy: 0.9993\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.75796\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.4339 - categorical_accuracy: 0.9994 - val_loss: 3.3079 - val_categorical_accuracy: 0.7478\n",
      "Epoch 26/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.4144 - categorical_accuracy: 0.9990\n",
      "Epoch 00026: val_categorical_accuracy improved from 0.75796 to 0.76943, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.4141 - categorical_accuracy: 0.9990 - val_loss: 3.2409 - val_categorical_accuracy: 0.7694\n",
      "Epoch 27/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.3932 - categorical_accuracy: 0.9997\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.76943\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.3933 - categorical_accuracy: 0.9997 - val_loss: 3.2650 - val_categorical_accuracy: 0.7669\n",
      "Epoch 28/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.3765 - categorical_accuracy: 0.9993\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.76943\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.3765 - categorical_accuracy: 0.9994 - val_loss: 3.2628 - val_categorical_accuracy: 0.7478\n",
      "Epoch 29/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.3568 - categorical_accuracy: 0.9993\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.76943\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.3565 - categorical_accuracy: 0.9994 - val_loss: 3.3046 - val_categorical_accuracy: 0.7439\n",
      "Epoch 30/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.3377 - categorical_accuracy: 0.9990\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.76943\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.3376 - categorical_accuracy: 0.9990 - val_loss: 3.3239 - val_categorical_accuracy: 0.7363\n",
      "Epoch 31/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.3205 - categorical_accuracy: 0.9997\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.76943\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.3205 - categorical_accuracy: 0.9997 - val_loss: 3.2241 - val_categorical_accuracy: 0.7643\n",
      "Epoch 32/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.3011 - categorical_accuracy: 0.9994\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.76943\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.3011 - categorical_accuracy: 0.9994 - val_loss: 3.3206 - val_categorical_accuracy: 0.7210\n",
      "Epoch 33/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.2838 - categorical_accuracy: 0.9997 ETA: 0s - loss: 2.2836 - categori\n",
      "Epoch 00033: val_categorical_accuracy improved from 0.76943 to 0.77962, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.2838 - categorical_accuracy: 0.9997 - val_loss: 3.1234 - val_categorical_accuracy: 0.7796\n",
      "Epoch 34/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.2672 - categorical_accuracy: 1.0000\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.2670 - categorical_accuracy: 1.0000 - val_loss: 3.1283 - val_categorical_accuracy: 0.7783\n",
      "Epoch 35/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.2491 - categorical_accuracy: 1.0000\n",
      "Epoch 00035: val_categorical_accuracy improved from 0.77962 to 0.78217, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.2491 - categorical_accuracy: 1.0000 - val_loss: 3.0474 - val_categorical_accuracy: 0.7822\n",
      "Epoch 36/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.2315 - categorical_accuracy: 1.0000\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.78217\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.2315 - categorical_accuracy: 1.0000 - val_loss: 3.0956 - val_categorical_accuracy: 0.7745\n",
      "Epoch 37/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.2141 - categorical_accuracy: 1.0000 ETA: 0s - loss: 2.2149 - categorical_accura\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.78217\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.2140 - categorical_accuracy: 1.0000 - val_loss: 3.1266 - val_categorical_accuracy: 0.7618\n",
      "Epoch 38/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.1988 - categorical_accuracy: 0.9997\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.78217\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.1987 - categorical_accuracy: 0.9997 - val_loss: 3.1381 - val_categorical_accuracy: 0.7389\n",
      "Epoch 39/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.1819 - categorical_accuracy: 1.0000\n",
      "Epoch 00039: val_categorical_accuracy improved from 0.78217 to 0.78344, saving model to ..\\..\\Trained Models\\Full_Model\\Indian Pines\\Full_Model_best_Indian Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.1818 - categorical_accuracy: 1.0000 - val_loss: 3.1046 - val_categorical_accuracy: 0.7834\n",
      "Epoch 40/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.1664 - categorical_accuracy: 1.0000\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.1664 - categorical_accuracy: 1.0000 - val_loss: 3.0611 - val_categorical_accuracy: 0.7631\n",
      "Epoch 41/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.1494 - categorical_accuracy: 1.0000\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.1494 - categorical_accuracy: 1.0000 - val_loss: 3.0730 - val_categorical_accuracy: 0.7682\n",
      "Epoch 42/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.1337 - categorical_accuracy: 1.0000\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.1337 - categorical_accuracy: 1.0000 - val_loss: 3.0119 - val_categorical_accuracy: 0.7720\n",
      "Epoch 43/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.1178 - categorical_accuracy: 1.0000\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.1178 - categorical_accuracy: 1.0000 - val_loss: 3.0602 - val_categorical_accuracy: 0.7465\n",
      "Epoch 44/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.1025 - categorical_accuracy: 1.0000\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.1025 - categorical_accuracy: 1.0000 - val_loss: 3.0316 - val_categorical_accuracy: 0.7490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.0864 - categorical_accuracy: 1.0000\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.0864 - categorical_accuracy: 1.0000 - val_loss: 3.0008 - val_categorical_accuracy: 0.7631\n",
      "Epoch 46/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.0717 - categorical_accuracy: 1.0000\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.0717 - categorical_accuracy: 1.0000 - val_loss: 2.9222 - val_categorical_accuracy: 0.7732\n",
      "Epoch 47/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.0569 - categorical_accuracy: 1.0000\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.0568 - categorical_accuracy: 1.0000 - val_loss: 2.9819 - val_categorical_accuracy: 0.7516\n",
      "Epoch 48/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.0417 - categorical_accuracy: 1.0000\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.0417 - categorical_accuracy: 1.0000 - val_loss: 2.9332 - val_categorical_accuracy: 0.7643\n",
      "Epoch 49/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.0278 - categorical_accuracy: 1.0000\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.0276 - categorical_accuracy: 1.0000 - val_loss: 3.0005 - val_categorical_accuracy: 0.7490\n",
      "Epoch 50/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.0124 - categorical_accuracy: 1.0000\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 2.0124 - categorical_accuracy: 1.0000 - val_loss: 2.9506 - val_categorical_accuracy: 0.7643\n",
      "Epoch 51/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.9983 - categorical_accuracy: 1.0000\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.9982 - categorical_accuracy: 1.0000 - val_loss: 2.9361 - val_categorical_accuracy: 0.7580\n",
      "Epoch 52/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.9836 - categorical_accuracy: 1.0000\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.9835 - categorical_accuracy: 1.0000 - val_loss: 2.8897 - val_categorical_accuracy: 0.7643\n",
      "Epoch 53/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.9690 - categorical_accuracy: 1.0000\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.9689 - categorical_accuracy: 1.0000 - val_loss: 2.8694 - val_categorical_accuracy: 0.7745\n",
      "Epoch 54/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.9553 - categorical_accuracy: 1.0000\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.9553 - categorical_accuracy: 1.0000 - val_loss: 2.9005 - val_categorical_accuracy: 0.7529\n",
      "Epoch 55/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.9417 - categorical_accuracy: 1.0000\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.9415 - categorical_accuracy: 1.0000 - val_loss: 2.9002 - val_categorical_accuracy: 0.7580\n",
      "Epoch 56/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.9277 - categorical_accuracy: 1.0000 ETA: 0s - loss: 1.9287 - categori\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.9275 - categorical_accuracy: 1.0000 - val_loss: 2.8672 - val_categorical_accuracy: 0.7592\n",
      "Epoch 57/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.9141 - categorical_accuracy: 1.0000\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.9141 - categorical_accuracy: 1.0000 - val_loss: 2.8508 - val_categorical_accuracy: 0.7669\n",
      "Epoch 58/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.9003 - categorical_accuracy: 1.0000\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.9002 - categorical_accuracy: 1.0000 - val_loss: 2.8630 - val_categorical_accuracy: 0.7758\n",
      "Epoch 59/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.8872 - categorical_accuracy: 1.0000 ETA: 1s - loss: 1\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.8872 - categorical_accuracy: 1.0000 - val_loss: 2.8199 - val_categorical_accuracy: 0.7516\n",
      "Epoch 60/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.8743 - categorical_accuracy: 1.0000\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.8743 - categorical_accuracy: 1.0000 - val_loss: 2.8191 - val_categorical_accuracy: 0.7771\n",
      "Epoch 61/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.8606 - categorical_accuracy: 1.0000\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.8607 - categorical_accuracy: 1.0000 - val_loss: 2.8470 - val_categorical_accuracy: 0.7554\n",
      "Epoch 62/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.8490 - categorical_accuracy: 1.0000\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.8490 - categorical_accuracy: 1.0000 - val_loss: 2.8181 - val_categorical_accuracy: 0.7758\n",
      "Epoch 63/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.8347 - categorical_accuracy: 1.0000\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.8347 - categorical_accuracy: 1.0000 - val_loss: 2.7506 - val_categorical_accuracy: 0.7631\n",
      "Epoch 64/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.8220 - categorical_accuracy: 1.0000\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.8219 - categorical_accuracy: 1.0000 - val_loss: 2.6793 - val_categorical_accuracy: 0.7669\n",
      "Epoch 65/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.8093 - categorical_accuracy: 1.0000\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.8092 - categorical_accuracy: 1.0000 - val_loss: 2.7781 - val_categorical_accuracy: 0.7631\n",
      "Epoch 66/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.7967 - categorical_accuracy: 1.0000\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.7966 - categorical_accuracy: 1.0000 - val_loss: 2.6744 - val_categorical_accuracy: 0.7783\n",
      "Epoch 67/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.7841 - categorical_accuracy: 1.0000\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.7841 - categorical_accuracy: 1.0000 - val_loss: 2.7365 - val_categorical_accuracy: 0.7720\n",
      "Epoch 68/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.7716 - categorical_accuracy: 1.0000\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.7716 - categorical_accuracy: 1.0000 - val_loss: 2.7299 - val_categorical_accuracy: 0.7529\n",
      "Epoch 69/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.7596 - categorical_accuracy: 1.0000\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.7596 - categorical_accuracy: 1.0000 - val_loss: 2.6801 - val_categorical_accuracy: 0.7694\n",
      "Epoch 70/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.7475 - categorical_accuracy: 1.0000\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.7474 - categorical_accuracy: 1.0000 - val_loss: 2.6339 - val_categorical_accuracy: 0.7783\n",
      "Epoch 71/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.7354 - categorical_accuracy: 1.0000\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.7354 - categorical_accuracy: 1.0000 - val_loss: 2.7162 - val_categorical_accuracy: 0.7541\n",
      "Epoch 72/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.7233 - categorical_accuracy: 1.0000\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.7233 - categorical_accuracy: 1.0000 - val_loss: 2.6236 - val_categorical_accuracy: 0.7732\n",
      "Epoch 73/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.7115 - categorical_accuracy: 1.0000\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.7115 - categorical_accuracy: 1.0000 - val_loss: 2.6703 - val_categorical_accuracy: 0.7580\n",
      "Epoch 74/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.7002 - categorical_accuracy: 1.0000\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.7001 - categorical_accuracy: 1.0000 - val_loss: 2.7297 - val_categorical_accuracy: 0.7490\n",
      "Epoch 75/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.6881 - categorical_accuracy: 1.0000\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.6881 - categorical_accuracy: 1.0000 - val_loss: 2.6105 - val_categorical_accuracy: 0.7732\n",
      "Epoch 76/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.6769 - categorical_accuracy: 1.0000\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.6769 - categorical_accuracy: 1.0000 - val_loss: 2.5956 - val_categorical_accuracy: 0.7834\n",
      "Epoch 77/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.6656 - categorical_accuracy: 1.0000\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.6656 - categorical_accuracy: 1.0000 - val_loss: 2.5767 - val_categorical_accuracy: 0.7694\n",
      "Epoch 78/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.6538 - categorical_accuracy: 1.0000\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.6539 - categorical_accuracy: 1.0000 - val_loss: 2.5874 - val_categorical_accuracy: 0.7732\n",
      "Epoch 79/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.6440 - categorical_accuracy: 1.0000\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.6440 - categorical_accuracy: 1.0000 - val_loss: 2.5847 - val_categorical_accuracy: 0.7707\n",
      "Epoch 80/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.6317 - categorical_accuracy: 1.0000\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.6316 - categorical_accuracy: 1.0000 - val_loss: 2.5622 - val_categorical_accuracy: 0.7732\n",
      "Epoch 81/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.6208 - categorical_accuracy: 1.0000\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.6208 - categorical_accuracy: 1.0000 - val_loss: 2.5978 - val_categorical_accuracy: 0.7707\n",
      "Epoch 82/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.6098 - categorical_accuracy: 1.0000\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.6098 - categorical_accuracy: 1.0000 - val_loss: 2.5569 - val_categorical_accuracy: 0.7745\n",
      "Epoch 83/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.5991 - categorical_accuracy: 1.0000\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.5990 - categorical_accuracy: 1.0000 - val_loss: 2.5437 - val_categorical_accuracy: 0.7771\n",
      "Epoch 84/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.5883 - categorical_accuracy: 1.0000\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.5883 - categorical_accuracy: 1.0000 - val_loss: 2.5170 - val_categorical_accuracy: 0.7720\n",
      "Epoch 85/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.5776 - categorical_accuracy: 1.0000\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.5775 - categorical_accuracy: 1.0000 - val_loss: 2.5069 - val_categorical_accuracy: 0.7771\n",
      "Epoch 86/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.5668 - categorical_accuracy: 1.0000\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.5668 - categorical_accuracy: 1.0000 - val_loss: 2.5208 - val_categorical_accuracy: 0.7669\n",
      "Epoch 87/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.5563 - categorical_accuracy: 1.0000\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.5563 - categorical_accuracy: 1.0000 - val_loss: 2.5117 - val_categorical_accuracy: 0.7669\n",
      "Epoch 88/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.5462 - categorical_accuracy: 1.0000\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.5462 - categorical_accuracy: 1.0000 - val_loss: 2.5470 - val_categorical_accuracy: 0.7682\n",
      "Epoch 89/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.5358 - categorical_accuracy: 1.0000\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.5358 - categorical_accuracy: 1.0000 - val_loss: 2.4686 - val_categorical_accuracy: 0.7580\n",
      "Epoch 90/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.5256 - categorical_accuracy: 1.0000 ETA: 0s - loss: 1.5267 - ca\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.5256 - categorical_accuracy: 1.0000 - val_loss: 2.4945 - val_categorical_accuracy: 0.7694\n",
      "Epoch 91/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.5156 - categorical_accuracy: 1.0000\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 2ms/step - loss: 1.5155 - categorical_accuracy: 1.0000 - val_loss: 2.4384 - val_categorical_accuracy: 0.7707\n",
      "Epoch 92/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.5052 - categorical_accuracy: 1.0000\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.5052 - categorical_accuracy: 1.0000 - val_loss: 2.4663 - val_categorical_accuracy: 0.7592\n",
      "Epoch 93/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.4954 - categorical_accuracy: 1.0000\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.4954 - categorical_accuracy: 1.0000 - val_loss: 2.5597 - val_categorical_accuracy: 0.7312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.4856 - categorical_accuracy: 1.0000\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.4856 - categorical_accuracy: 1.0000 - val_loss: 2.4308 - val_categorical_accuracy: 0.7682\n",
      "Epoch 95/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.4757 - categorical_accuracy: 1.0000\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.4757 - categorical_accuracy: 1.0000 - val_loss: 2.4214 - val_categorical_accuracy: 0.7732\n",
      "Epoch 96/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.4662 - categorical_accuracy: 1.0000\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.4661 - categorical_accuracy: 1.0000 - val_loss: 2.4167 - val_categorical_accuracy: 0.7631\n",
      "Epoch 97/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.4566 - categorical_accuracy: 1.0000\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.4566 - categorical_accuracy: 1.0000 - val_loss: 2.4278 - val_categorical_accuracy: 0.7809\n",
      "Epoch 98/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.4469 - categorical_accuracy: 1.0000\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.4469 - categorical_accuracy: 1.0000 - val_loss: 2.4204 - val_categorical_accuracy: 0.7707\n",
      "Epoch 99/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.4375 - categorical_accuracy: 1.0000\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.4375 - categorical_accuracy: 1.0000 - val_loss: 2.4056 - val_categorical_accuracy: 0.7592\n",
      "Epoch 100/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.4285 - categorical_accuracy: 1.0000\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.78344\n",
      "3109/3109 [==============================] - 5s 1ms/step - loss: 1.4285 - categorical_accuracy: 1.0000 - val_loss: 2.4200 - val_categorical_accuracy: 0.7656\n",
      "785/785 [==============================] - 0s 540us/step\n",
      "Test Accuracy = 0.7656050959969781\n",
      "785/785 [==============================] - 1s 1ms/step\n",
      "\n",
      "===============================================================================================================================\n",
      "=============================== Confusion_matrix for data with overlap ratio of 95% is as below ===============================\n",
      "===============================================================================================================================\n",
      "\n",
      "[[  5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 101   0   2   8   1   0   0   0   0  20   2   0   0   0   0]\n",
      " [  0   0   7   0   0   0   0   0   0   0  28   0   0   1   0   0]\n",
      " [  0   4   0   5   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  20   4   0   4   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1  63   0   0   0   0   0   0   0   9   0   0]\n",
      " [  0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  22   1   0   0   0   0   0   0  52   7   0   0   0   0   0]\n",
      " [  0   5   0   0  10   2   0   0   0   0 188   0   9   0   0   0]\n",
      " [  0  14   9   0   0   0   0   0   0   8   4   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  20   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  93   0   0]\n",
      " [  0   2   1   0   0   0   0   0   0   0   0   0   0   0   7   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   8]]\n",
      "==============================================================================================================================\n",
      "[  5 134  36   9  28  73   3  29   2  82 214  37  21  93  10   9]\n",
      "==============================================================================================================================\n",
      "\n",
      "==============================================================================================================================\n",
      "=============================== Sub Model below will be saved to be used for transfer learning  ==============================\n",
      "==============================================================================================================================\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_3 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 106,544\n",
      "Trainable params: 105,808\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Acc_Table = Train(overlap_ratio_List = [50,75,85,95],\n",
    "                  range_of_class = range_of_class,\n",
    "                  Cube_size= 25,\n",
    "                  Data = data_IN,\n",
    "                  Gt = gt_IN,\n",
    "                  Train_Test_split = 80,\n",
    "                  channel = 103,\n",
    "                  epochs_list = [100, 100, 100, 100],\n",
    "                  batch_size_list = [2, 4, 8, 16],\n",
    "                  data_name = 'Indian Pines',\n",
    "                  Verbosity  = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test Accuracy Table</td>\n",
       "      <td>Indian Pines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data_Overlap_50</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data_Overlap_75</td>\n",
       "      <td>0.508197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data_Overlap_85</td>\n",
       "      <td>0.727811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data_Overlap_95</td>\n",
       "      <td>0.765605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0             1\n",
       "0  Test Accuracy Table  Indian Pines\n",
       "1      Data_Overlap_50      0.454545\n",
       "2      Data_Overlap_75      0.508197\n",
       "3      Data_Overlap_85      0.727811\n",
       "4      Data_Overlap_95      0.765605"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acc_Table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

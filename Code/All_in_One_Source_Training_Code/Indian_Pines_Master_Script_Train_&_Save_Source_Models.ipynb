{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indian Pines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source_Model_Utils import *\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 145, 200) (145, 145)\n",
      "(200, 145, 145) (145, 145)\n"
     ]
    }
   ],
   "source": [
    "uIndian_pines = sio.loadmat('..\\\\..\\\\Indian Pines\\\\Indian_pines_corrected.mat')\n",
    "gt_uIndian_pines = sio.loadmat('..\\\\..\\\\Indian Pines\\\\Indian_pines_gt.mat')\n",
    "data_IN = uIndian_pines['indian_pines_corrected']\n",
    "gt_IN = gt_uIndian_pines['indian_pines_gt']\n",
    "print(data_IN.shape, gt_IN.shape)\n",
    "data_IN = np.moveaxis(data_IN, 2, 0)\n",
    "print(data_IN.shape, gt_IN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16] [10776    46  1428   830   237   483   730    28   478    20   972  2455\n",
      "   593   205  1265   386    93]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values,counts = np.unique(gt_IN, return_counts=True)\n",
    "print(values,counts)\n",
    "range_of_class = list(values)\n",
    "if 0 in range_of_class:\n",
    "    range_of_class.pop(0)\n",
    "range_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0             1\n",
      "0  Test Accuracy Table  Indian_Pines\n",
      "1      Data_Overlap_50          None\n",
      "2      Data_Overlap_75          None\n",
      "3      Data_Overlap_85          None\n",
      "4      Data_Overlap_95          None\n",
      "\n",
      "\n",
      "===============================================================================================================================\n",
      "======================================== Data with overlap ratio of 50% will be trained =======================================\n",
      "===============================================================================================================================\n",
      "\n",
      "\n",
      "(75, 103, 24, 24, 1) (22, 103, 24, 24, 1) (75,) (22,)\n",
      "Total samples per class: [0, 15, 8, 0, 7, 10, 0, 4, 0, 12, 24, 5, 0, 12, 0, 0], Total number of samples is 97.\n",
      "\n",
      "unique classes in Ytest: [ 2  3  5  6  8 10 11 12 14], Total number of samples in Ytest is 22.\n",
      "number of samples per class in Ytest: [3 2 2 2 1 3 5 1 3]\n",
      "\n",
      "Xtrain => (75, 103, 24, 24, 1)\n",
      "Xtest  => (22, 103, 24, 24, 1)\n",
      "Ytrain => (75, 9)\n",
      "Ytest  => (22, 9)\n",
      "\n",
      "Model: \"3D-SRNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 103, 24, 24, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d (GlobalMax (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fc_256 (Dense)                  (None, 256)          16640       global_max_pooling3d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fc9 (Dense)                     (None, 9)            2313        fc_256[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 125,497\n",
      "Trainable params: 124,761\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 6.0804 - categorical_accuracy: 0.2027\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.13636, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 6s 82ms/sample - loss: 6.0534 - categorical_accuracy: 0.2000 - val_loss: 8.0386 - val_categorical_accuracy: 0.1364\n",
      "Epoch 2/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 5.3141 - categorical_accuracy: 0.2703\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.13636\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 5.2940 - categorical_accuracy: 0.2800 - val_loss: 6.7805 - val_categorical_accuracy: 0.1364\n",
      "Epoch 3/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 5.0527 - categorical_accuracy: 0.2639\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.13636\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 5.0878 - categorical_accuracy: 0.2533 - val_loss: 6.7967 - val_categorical_accuracy: 0.1364\n",
      "Epoch 4/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 5.1304 - categorical_accuracy: 0.2639\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.13636\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 5.1467 - categorical_accuracy: 0.2533 - val_loss: 5.7093 - val_categorical_accuracy: 0.1364\n",
      "Epoch 5/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 4.9642 - categorical_accuracy: 0.2714\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.13636\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 5.0108 - categorical_accuracy: 0.2533 - val_loss: 6.0577 - val_categorical_accuracy: 0.1364\n",
      "Epoch 6/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 4.8669 - categorical_accuracy: 0.2917\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.13636\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 4.8492 - categorical_accuracy: 0.2933 - val_loss: 5.5524 - val_categorical_accuracy: 0.1364\n",
      "Epoch 7/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 4.7382 - categorical_accuracy: 0.3750\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.13636 to 0.22727, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 4.7159 - categorical_accuracy: 0.3867 - val_loss: 4.9423 - val_categorical_accuracy: 0.2273\n",
      "Epoch 8/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 4.7078 - categorical_accuracy: 0.3514\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.22727 to 0.31818, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 4.7266 - categorical_accuracy: 0.3467 - val_loss: 5.0088 - val_categorical_accuracy: 0.3182\n",
      "Epoch 9/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 4.4706 - categorical_accuracy: 0.4324\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.31818\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 4.4500 - categorical_accuracy: 0.4400 - val_loss: 5.0338 - val_categorical_accuracy: 0.3182\n",
      "Epoch 10/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 4.1643 - categorical_accuracy: 0.5571\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.31818\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 4.2310 - categorical_accuracy: 0.5333 - val_loss: 4.9148 - val_categorical_accuracy: 0.1364\n",
      "Epoch 11/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 4.1398 - categorical_accuracy: 0.5286\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.31818\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 4.1544 - categorical_accuracy: 0.5067 - val_loss: 4.9585 - val_categorical_accuracy: 0.3182\n",
      "Epoch 12/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 4.0281 - categorical_accuracy: 0.6286\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.31818\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 4.0312 - categorical_accuracy: 0.6267 - val_loss: 5.0625 - val_categorical_accuracy: 0.2273\n",
      "Epoch 13/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 3.8398 - categorical_accuracy: 0.6944\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.31818\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 3.8773 - categorical_accuracy: 0.6800 - val_loss: 4.9530 - val_categorical_accuracy: 0.2273\n",
      "Epoch 14/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 3.8004 - categorical_accuracy: 0.6622\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.31818\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 3.7949 - categorical_accuracy: 0.6667 - val_loss: 5.0992 - val_categorical_accuracy: 0.1818\n",
      "Epoch 15/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 3.6198 - categorical_accuracy: 0.8143\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.31818\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 3.6321 - categorical_accuracy: 0.8133 - val_loss: 4.8739 - val_categorical_accuracy: 0.3182\n",
      "Epoch 16/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 3.5212 - categorical_accuracy: 0.8472\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.31818 to 0.36364, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 13ms/sample - loss: 3.5171 - categorical_accuracy: 0.8533 - val_loss: 4.5968 - val_categorical_accuracy: 0.3636\n",
      "Epoch 17/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 3.3962 - categorical_accuracy: 0.9000\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.36364\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 3.3741 - categorical_accuracy: 0.9067 - val_loss: 4.7147 - val_categorical_accuracy: 0.3182\n",
      "Epoch 18/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 3.3433 - categorical_accuracy: 0.9054\n",
      "Epoch 00018: val_categorical_accuracy improved from 0.36364 to 0.45455, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_50_percent.h5\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 3.3402 - categorical_accuracy: 0.9067 - val_loss: 4.5667 - val_categorical_accuracy: 0.4545\n",
      "Epoch 19/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 3.2130 - categorical_accuracy: 0.9583\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 3.2338 - categorical_accuracy: 0.9467 - val_loss: 4.7880 - val_categorical_accuracy: 0.3182\n",
      "Epoch 20/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 3.2036 - categorical_accuracy: 1.0000\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 3.1984 - categorical_accuracy: 1.0000 - val_loss: 4.6018 - val_categorical_accuracy: 0.4091\n",
      "Epoch 21/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 3.1498 - categorical_accuracy: 0.9595\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 3.1471 - categorical_accuracy: 0.9600 - val_loss: 4.7660 - val_categorical_accuracy: 0.3182\n",
      "Epoch 22/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 3.1064 - categorical_accuracy: 1.0000\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 3.0958 - categorical_accuracy: 1.0000 - val_loss: 4.7412 - val_categorical_accuracy: 0.3182\n",
      "Epoch 23/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 3.0634 - categorical_accuracy: 1.0000\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 3.0703 - categorical_accuracy: 1.0000 - val_loss: 4.6293 - val_categorical_accuracy: 0.3636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 3.0104 - categorical_accuracy: 1.0000\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 3.0102 - categorical_accuracy: 1.0000 - val_loss: 4.8457 - val_categorical_accuracy: 0.4091\n",
      "Epoch 25/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.9888 - categorical_accuracy: 0.9861\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 3.0037 - categorical_accuracy: 0.9733 - val_loss: 4.6547 - val_categorical_accuracy: 0.4091\n",
      "Epoch 26/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 3.0137 - categorical_accuracy: 1.0000\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 3.0120 - categorical_accuracy: 1.0000 - val_loss: 4.8681 - val_categorical_accuracy: 0.3636\n",
      "Epoch 27/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.9739 - categorical_accuracy: 1.0000\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.9724 - categorical_accuracy: 1.0000 - val_loss: 4.7769 - val_categorical_accuracy: 0.4091\n",
      "Epoch 28/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.9281 - categorical_accuracy: 1.0000\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.9273 - categorical_accuracy: 1.0000 - val_loss: 4.6894 - val_categorical_accuracy: 0.4091\n",
      "Epoch 29/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.9050 - categorical_accuracy: 1.0000\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.9046 - categorical_accuracy: 1.0000 - val_loss: 4.7887 - val_categorical_accuracy: 0.2273\n",
      "Epoch 30/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.9085 - categorical_accuracy: 1.0000\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.9070 - categorical_accuracy: 1.0000 - val_loss: 4.8364 - val_categorical_accuracy: 0.3182\n",
      "Epoch 31/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.8690 - categorical_accuracy: 1.0000\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.8724 - categorical_accuracy: 1.0000 - val_loss: 4.8557 - val_categorical_accuracy: 0.3636\n",
      "Epoch 32/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.8709 - categorical_accuracy: 1.0000\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.8701 - categorical_accuracy: 1.0000 - val_loss: 4.9314 - val_categorical_accuracy: 0.3636\n",
      "Epoch 33/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.8501 - categorical_accuracy: 1.0000\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.8494 - categorical_accuracy: 1.0000 - val_loss: 4.8115 - val_categorical_accuracy: 0.4091\n",
      "Epoch 34/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.8547 - categorical_accuracy: 1.0000\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.8523 - categorical_accuracy: 1.0000 - val_loss: 4.7594 - val_categorical_accuracy: 0.3636\n",
      "Epoch 35/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.8371 - categorical_accuracy: 1.0000\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.8359 - categorical_accuracy: 1.0000 - val_loss: 4.8207 - val_categorical_accuracy: 0.3636\n",
      "Epoch 36/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.8319 - categorical_accuracy: 1.0000\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.8314 - categorical_accuracy: 1.0000 - val_loss: 4.8320 - val_categorical_accuracy: 0.3636\n",
      "Epoch 37/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.8212 - categorical_accuracy: 1.0000\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.8205 - categorical_accuracy: 1.0000 - val_loss: 4.9113 - val_categorical_accuracy: 0.3182\n",
      "Epoch 38/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.8184 - categorical_accuracy: 1.0000\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.8178 - categorical_accuracy: 1.0000 - val_loss: 4.9553 - val_categorical_accuracy: 0.3182\n",
      "Epoch 39/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.8129 - categorical_accuracy: 1.0000\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.8115 - categorical_accuracy: 1.0000 - val_loss: 4.8437 - val_categorical_accuracy: 0.3636\n",
      "Epoch 40/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.8084 - categorical_accuracy: 1.0000\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.8066 - categorical_accuracy: 1.0000 - val_loss: 4.9157 - val_categorical_accuracy: 0.3636\n",
      "Epoch 41/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7930 - categorical_accuracy: 1.0000\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7928 - categorical_accuracy: 1.0000 - val_loss: 4.9022 - val_categorical_accuracy: 0.3182\n",
      "Epoch 42/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.7899 - categorical_accuracy: 1.0000\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7893 - categorical_accuracy: 1.0000 - val_loss: 4.9312 - val_categorical_accuracy: 0.3182\n",
      "Epoch 43/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.7834 - categorical_accuracy: 1.0000\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7842 - categorical_accuracy: 1.0000 - val_loss: 4.8369 - val_categorical_accuracy: 0.4091\n",
      "Epoch 44/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.7759 - categorical_accuracy: 1.0000\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7748 - categorical_accuracy: 1.0000 - val_loss: 4.8720 - val_categorical_accuracy: 0.4091\n",
      "Epoch 45/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7680 - categorical_accuracy: 1.0000\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7679 - categorical_accuracy: 1.0000 - val_loss: 4.9264 - val_categorical_accuracy: 0.4091\n",
      "Epoch 46/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.7709 - categorical_accuracy: 1.0000\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7699 - categorical_accuracy: 1.0000 - val_loss: 4.8748 - val_categorical_accuracy: 0.4091\n",
      "Epoch 47/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7665 - categorical_accuracy: 1.0000\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7663 - categorical_accuracy: 1.0000 - val_loss: 4.8930 - val_categorical_accuracy: 0.3182\n",
      "Epoch 48/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.7587 - categorical_accuracy: 1.0000\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7617 - categorical_accuracy: 1.0000 - val_loss: 4.9453 - val_categorical_accuracy: 0.3636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.7465 - categorical_accuracy: 1.0000\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7461 - categorical_accuracy: 1.0000 - val_loss: 4.9929 - val_categorical_accuracy: 0.3182\n",
      "Epoch 50/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7443 - categorical_accuracy: 1.0000\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7441 - categorical_accuracy: 1.0000 - val_loss: 4.9212 - val_categorical_accuracy: 0.3636\n",
      "Epoch 51/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.7405 - categorical_accuracy: 1.0000\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7413 - categorical_accuracy: 1.0000 - val_loss: 5.0145 - val_categorical_accuracy: 0.3636\n",
      "Epoch 52/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7393 - categorical_accuracy: 1.0000\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7392 - categorical_accuracy: 1.0000 - val_loss: 5.0369 - val_categorical_accuracy: 0.3636\n",
      "Epoch 53/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7275 - categorical_accuracy: 1.0000\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7276 - categorical_accuracy: 1.0000 - val_loss: 4.9931 - val_categorical_accuracy: 0.3636\n",
      "Epoch 54/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.7337 - categorical_accuracy: 1.0000\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7328 - categorical_accuracy: 1.0000 - val_loss: 4.9112 - val_categorical_accuracy: 0.3636\n",
      "Epoch 55/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7173 - categorical_accuracy: 1.0000\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7172 - categorical_accuracy: 1.0000 - val_loss: 4.9317 - val_categorical_accuracy: 0.3636\n",
      "Epoch 56/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.7113 - categorical_accuracy: 1.0000\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7117 - categorical_accuracy: 1.0000 - val_loss: 4.9131 - val_categorical_accuracy: 0.3636\n",
      "Epoch 57/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.7233 - categorical_accuracy: 1.0000\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7215 - categorical_accuracy: 1.0000 - val_loss: 4.8892 - val_categorical_accuracy: 0.3182\n",
      "Epoch 58/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7050 - categorical_accuracy: 1.0000\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7047 - categorical_accuracy: 1.0000 - val_loss: 4.9001 - val_categorical_accuracy: 0.3636\n",
      "Epoch 59/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.7002 - categorical_accuracy: 1.0000\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.7000 - categorical_accuracy: 1.0000 - val_loss: 4.9105 - val_categorical_accuracy: 0.3636\n",
      "Epoch 60/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6969 - categorical_accuracy: 1.0000\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6992 - categorical_accuracy: 1.0000 - val_loss: 4.9540 - val_categorical_accuracy: 0.3636\n",
      "Epoch 61/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.6950 - categorical_accuracy: 1.0000\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6948 - categorical_accuracy: 1.0000 - val_loss: 4.9122 - val_categorical_accuracy: 0.4091\n",
      "Epoch 62/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6870 - categorical_accuracy: 1.0000\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6867 - categorical_accuracy: 1.0000 - val_loss: 4.9189 - val_categorical_accuracy: 0.4091\n",
      "Epoch 63/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6831 - categorical_accuracy: 1.0000\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6823 - categorical_accuracy: 1.0000 - val_loss: 4.9441 - val_categorical_accuracy: 0.4091\n",
      "Epoch 64/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.6814 - categorical_accuracy: 1.0000\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6811 - categorical_accuracy: 1.0000 - val_loss: 4.9141 - val_categorical_accuracy: 0.3636\n",
      "Epoch 65/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.6719 - categorical_accuracy: 1.0000\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6717 - categorical_accuracy: 1.0000 - val_loss: 4.9151 - val_categorical_accuracy: 0.3636\n",
      "Epoch 66/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.6693 - categorical_accuracy: 1.0000\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6691 - categorical_accuracy: 1.0000 - val_loss: 4.9390 - val_categorical_accuracy: 0.3636\n",
      "Epoch 67/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.6680 - categorical_accuracy: 1.0000\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6678 - categorical_accuracy: 1.0000 - val_loss: 4.8779 - val_categorical_accuracy: 0.4091\n",
      "Epoch 68/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6601 - categorical_accuracy: 1.0000\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6597 - categorical_accuracy: 1.0000 - val_loss: 4.9463 - val_categorical_accuracy: 0.4091\n",
      "Epoch 69/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6563 - categorical_accuracy: 1.0000\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6558 - categorical_accuracy: 1.0000 - val_loss: 4.8904 - val_categorical_accuracy: 0.3636\n",
      "Epoch 70/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6529 - categorical_accuracy: 1.0000\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6525 - categorical_accuracy: 1.0000 - val_loss: 4.9391 - val_categorical_accuracy: 0.3182\n",
      "Epoch 71/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6474 - categorical_accuracy: 1.0000\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6466 - categorical_accuracy: 1.0000 - val_loss: 4.9407 - val_categorical_accuracy: 0.3636\n",
      "Epoch 72/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6429 - categorical_accuracy: 1.0000\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6426 - categorical_accuracy: 1.0000 - val_loss: 4.9375 - val_categorical_accuracy: 0.3636\n",
      "Epoch 73/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6361 - categorical_accuracy: 1.0000\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6377 - categorical_accuracy: 1.0000 - val_loss: 4.9224 - val_categorical_accuracy: 0.4091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6352 - categorical_accuracy: 1.0000\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6366 - categorical_accuracy: 1.0000 - val_loss: 4.8872 - val_categorical_accuracy: 0.4091\n",
      "Epoch 75/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.6282 - categorical_accuracy: 1.0000\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6280 - categorical_accuracy: 1.0000 - val_loss: 4.8489 - val_categorical_accuracy: 0.4091\n",
      "Epoch 76/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.6247 - categorical_accuracy: 1.0000\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6246 - categorical_accuracy: 1.0000 - val_loss: 4.9269 - val_categorical_accuracy: 0.4091\n",
      "Epoch 77/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6252 - categorical_accuracy: 1.0000\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6248 - categorical_accuracy: 1.0000 - val_loss: 4.9391 - val_categorical_accuracy: 0.3636\n",
      "Epoch 78/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6214 - categorical_accuracy: 1.0000\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6207 - categorical_accuracy: 1.0000 - val_loss: 4.7238 - val_categorical_accuracy: 0.4545\n",
      "Epoch 79/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.6179 - categorical_accuracy: 1.0000\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6173 - categorical_accuracy: 1.0000 - val_loss: 4.8801 - val_categorical_accuracy: 0.3636\n",
      "Epoch 80/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6087 - categorical_accuracy: 1.0000\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6102 - categorical_accuracy: 1.0000 - val_loss: 4.9187 - val_categorical_accuracy: 0.3636\n",
      "Epoch 81/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6052 - categorical_accuracy: 1.0000\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6053 - categorical_accuracy: 1.0000 - val_loss: 4.9093 - val_categorical_accuracy: 0.4091\n",
      "Epoch 82/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.6020 - categorical_accuracy: 1.0000\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.6015 - categorical_accuracy: 1.0000 - val_loss: 4.9174 - val_categorical_accuracy: 0.3636\n",
      "Epoch 83/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5966 - categorical_accuracy: 1.0000\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5961 - categorical_accuracy: 1.0000 - val_loss: 4.9565 - val_categorical_accuracy: 0.3636\n",
      "Epoch 84/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5955 - categorical_accuracy: 1.0000\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5953 - categorical_accuracy: 1.0000 - val_loss: 4.9125 - val_categorical_accuracy: 0.3636\n",
      "Epoch 85/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5897 - categorical_accuracy: 1.0000\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5896 - categorical_accuracy: 1.0000 - val_loss: 4.9048 - val_categorical_accuracy: 0.4091\n",
      "Epoch 86/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.5839 - categorical_accuracy: 1.0000\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5836 - categorical_accuracy: 1.0000 - val_loss: 4.9315 - val_categorical_accuracy: 0.4091\n",
      "Epoch 87/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 2.5844 - categorical_accuracy: 1.0000\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5835 - categorical_accuracy: 1.0000 - val_loss: 4.9585 - val_categorical_accuracy: 0.3636\n",
      "Epoch 88/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.5807 - categorical_accuracy: 1.0000\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5802 - categorical_accuracy: 1.0000 - val_loss: 4.8244 - val_categorical_accuracy: 0.3636\n",
      "Epoch 89/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5757 - categorical_accuracy: 1.0000\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5755 - categorical_accuracy: 1.0000 - val_loss: 4.8369 - val_categorical_accuracy: 0.3636\n",
      "Epoch 90/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.5702 - categorical_accuracy: 1.00 - ETA: 0s - loss: 2.5697 - categorical_accuracy: 1.0000\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5696 - categorical_accuracy: 1.0000 - val_loss: 4.8884 - val_categorical_accuracy: 0.4091\n",
      "Epoch 91/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5670 - categorical_accuracy: 1.0000\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5671 - categorical_accuracy: 1.0000 - val_loss: 4.8629 - val_categorical_accuracy: 0.3636\n",
      "Epoch 92/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.5621 - categorical_accuracy: 1.0000\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5618 - categorical_accuracy: 1.0000 - val_loss: 4.8893 - val_categorical_accuracy: 0.3636\n",
      "Epoch 93/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5567 - categorical_accuracy: 1.0000\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5569 - categorical_accuracy: 1.0000 - val_loss: 4.8726 - val_categorical_accuracy: 0.3636\n",
      "Epoch 94/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.5525 - categorical_accuracy: 1.0000\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5524 - categorical_accuracy: 1.0000 - val_loss: 4.9252 - val_categorical_accuracy: 0.3636\n",
      "Epoch 95/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.5504 - categorical_accuracy: 1.0000\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5501 - categorical_accuracy: 1.0000 - val_loss: 4.9080 - val_categorical_accuracy: 0.3636\n",
      "Epoch 96/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5442 - categorical_accuracy: 1.0000\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5442 - categorical_accuracy: 1.0000 - val_loss: 4.8866 - val_categorical_accuracy: 0.4545\n",
      "Epoch 97/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5420 - categorical_accuracy: 1.0000\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5424 - categorical_accuracy: 1.0000 - val_loss: 4.8907 - val_categorical_accuracy: 0.3636\n",
      "Epoch 98/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 2.5380 - categorical_accuracy: 1.0000\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 12ms/sample - loss: 2.5378 - categorical_accuracy: 1.0000 - val_loss: 4.9049 - val_categorical_accuracy: 0.3636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 2.5346 - categorical_accuracy: 1.0000\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5342 - categorical_accuracy: 1.0000 - val_loss: 4.8776 - val_categorical_accuracy: 0.4091\n",
      "Epoch 100/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 2.5297 - categorical_accuracy: 1.0000\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.45455\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 2.5294 - categorical_accuracy: 1.0000 - val_loss: 4.8829 - val_categorical_accuracy: 0.4091\n",
      "22/22 [==============================] - 0s 2ms/sample - loss: 4.8829 - categorical_accuracy: 0.4091\n",
      "Test Accuracy = 0.4090909\n",
      "22/22 [==============================] - 0s 8ms/sample\n",
      "\n",
      "===============================================================================================================================\n",
      "=============================== Confusion_matrix for data with overlap ratio of 50% is as below ===============================\n",
      "===============================================================================================================================\n",
      "\n",
      "[[0 1 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 5 0 0]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 3]]\n",
      "==============================================================================================================================\n",
      "[3 2 2 2 1 3 5 1 3]\n",
      "==============================================================================================================================\n",
      "\n",
      "==============================================================================================================================\n",
      "=============================== Sub Model below will be saved to be used for transfer learning  ==============================\n",
      "==============================================================================================================================\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 103, 24, 24, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d (GlobalMax (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 106,544\n",
      "Trainable params: 105,808\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "===============================================================================================================================\n",
      "======================================== Data with overlap ratio of 75% will be trained =======================================\n",
      "===============================================================================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 103, 24, 24, 1) (61, 103, 24, 24, 1) (224,) (61,)\n",
      "Total samples per class: [0, 49, 14, 5, 13, 26, 0, 10, 0, 30, 71, 17, 9, 31, 5, 5], Total number of samples is 285.\n",
      "\n",
      "unique classes in Ytest: [ 2  3  4  5  6  8 10 11 12 13 14 15 16], Total number of samples in Ytest is 61.\n",
      "number of samples per class in Ytest: [10  3  1  3  6  2  6 15  4  2  7  1  1]\n",
      "\n",
      "Xtrain => (224, 103, 24, 24, 1)\n",
      "Xtest  => (61, 103, 24, 24, 1)\n",
      "Ytrain => (224, 13)\n",
      "Ytest  => (61, 13)\n",
      "\n",
      "Model: \"3D-SRNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 103, 24, 24, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_1 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fc_256 (Dense)                  (None, 256)          16640       global_max_pooling3d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fc13 (Dense)                    (None, 13)           3341        fc_256[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 126,525\n",
      "Trainable params: 125,789\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 224 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 5.8387 - categorical_accuracy: 0.2364\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.11475, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 6s 28ms/sample - loss: 5.8293 - categorical_accuracy: 0.2321 - val_loss: 6.4213 - val_categorical_accuracy: 0.1148\n",
      "Epoch 2/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 5.0241 - categorical_accuracy: 0.2955\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.11475\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 5.0225 - categorical_accuracy: 0.2991 - val_loss: 6.1687 - val_categorical_accuracy: 0.1148\n",
      "Epoch 3/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 4.8510 - categorical_accuracy: 0.3632\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.11475\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 4.8738 - categorical_accuracy: 0.3571 - val_loss: 5.5617 - val_categorical_accuracy: 0.0984\n",
      "Epoch 4/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 4.7885 - categorical_accuracy: 0.4009\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.11475\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 4.8154 - categorical_accuracy: 0.3973 - val_loss: 5.9063 - val_categorical_accuracy: 0.0820\n",
      "Epoch 5/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 4.7010 - categorical_accuracy: 0.4120\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.11475 to 0.27869, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 4.7122 - categorical_accuracy: 0.4107 - val_loss: 5.1029 - val_categorical_accuracy: 0.2787\n",
      "Epoch 6/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 4.4986 - categorical_accuracy: 0.4670\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.27869 to 0.29508, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 4.4855 - categorical_accuracy: 0.4732 - val_loss: 4.7903 - val_categorical_accuracy: 0.2951\n",
      "Epoch 7/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 4.3741 - categorical_accuracy: 0.5094\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.29508 to 0.45902, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 4.3817 - categorical_accuracy: 0.5134 - val_loss: 4.6799 - val_categorical_accuracy: 0.4590\n",
      "Epoch 8/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 4.2398 - categorical_accuracy: 0.5377\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 4.2325 - categorical_accuracy: 0.5402 - val_loss: 5.3923 - val_categorical_accuracy: 0.2295\n",
      "Epoch 9/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 4.2079 - categorical_accuracy: 0.5566\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 4.1948 - categorical_accuracy: 0.5580 - val_loss: 5.2489 - val_categorical_accuracy: 0.1639\n",
      "Epoch 10/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 4.0459 - categorical_accuracy: 0.6273\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 4.0452 - categorical_accuracy: 0.6250 - val_loss: 4.6236 - val_categorical_accuracy: 0.3770\n",
      "Epoch 11/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 3.9793 - categorical_accuracy: 0.6636\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.9877 - categorical_accuracy: 0.6652 - val_loss: 4.7220 - val_categorical_accuracy: 0.3770\n",
      "Epoch 12/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 3.8916 - categorical_accuracy: 0.6620\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.8892 - categorical_accuracy: 0.6607 - val_loss: 4.8683 - val_categorical_accuracy: 0.3279\n",
      "Epoch 13/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 3.7914 - categorical_accuracy: 0.6981\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.8007 - categorical_accuracy: 0.7009 - val_loss: 4.4172 - val_categorical_accuracy: 0.4262\n",
      "Epoch 14/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 3.7411 - categorical_accuracy: 0.7406\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.7383 - categorical_accuracy: 0.7366 - val_loss: 4.5954 - val_categorical_accuracy: 0.2951\n",
      "Epoch 15/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 3.6138 - categorical_accuracy: 0.8000\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.6180 - categorical_accuracy: 0.7991 - val_loss: 4.7753 - val_categorical_accuracy: 0.3607\n",
      "Epoch 16/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 3.5238 - categorical_accuracy: 0.8333\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.5167 - categorical_accuracy: 0.8348 - val_loss: 4.7311 - val_categorical_accuracy: 0.2787\n",
      "Epoch 17/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 3.5013 - categorical_accuracy: 0.8056\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.5040 - categorical_accuracy: 0.8036 - val_loss: 4.5741 - val_categorical_accuracy: 0.3279\n",
      "Epoch 18/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 3.4157 - categorical_accuracy: 0.8491\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.4239 - categorical_accuracy: 0.8482 - val_loss: 4.3756 - val_categorical_accuracy: 0.4590\n",
      "Epoch 19/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 3.3216 - categorical_accuracy: 0.8843\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.45902\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.3290 - categorical_accuracy: 0.8795 - val_loss: 4.3718 - val_categorical_accuracy: 0.4590\n",
      "Epoch 20/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 3.2769 - categorical_accuracy: 0.9227\n",
      "Epoch 00020: val_categorical_accuracy improved from 0.45902 to 0.52459, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.2750 - categorical_accuracy: 0.9241 - val_loss: 4.2183 - val_categorical_accuracy: 0.5246\n",
      "Epoch 21/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 3.2066 - categorical_accuracy: 0.9136\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.52459\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.2047 - categorical_accuracy: 0.9152 - val_loss: 4.3277 - val_categorical_accuracy: 0.4262\n",
      "Epoch 22/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 3.1411 - categorical_accuracy: 0.9764\n",
      "Epoch 00022: val_categorical_accuracy improved from 0.52459 to 0.54098, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.1369 - categorical_accuracy: 0.9777 - val_loss: 4.1690 - val_categorical_accuracy: 0.5410\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/224 [===========================>..] - ETA: 0s - loss: 3.0944 - categorical_accuracy: 0.9815\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.54098\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.0963 - categorical_accuracy: 0.9821 - val_loss: 4.1409 - val_categorical_accuracy: 0.5246\n",
      "Epoch 24/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 3.0641 - categorical_accuracy: 0.9764\n",
      "Epoch 00024: val_categorical_accuracy improved from 0.54098 to 0.57377, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.0623 - categorical_accuracy: 0.9732 - val_loss: 4.0995 - val_categorical_accuracy: 0.5738\n",
      "Epoch 25/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 3.0127 - categorical_accuracy: 0.9773\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.57377\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 3.0119 - categorical_accuracy: 0.9777 - val_loss: 4.3622 - val_categorical_accuracy: 0.4098\n",
      "Epoch 26/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.9822 - categorical_accuracy: 0.9815\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.57377\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.9853 - categorical_accuracy: 0.9777 - val_loss: 4.1150 - val_categorical_accuracy: 0.5574\n",
      "Epoch 27/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.9598 - categorical_accuracy: 0.9818\n",
      "Epoch 00027: val_categorical_accuracy improved from 0.57377 to 0.60656, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.9589 - categorical_accuracy: 0.9821 - val_loss: 4.0342 - val_categorical_accuracy: 0.6066\n",
      "Epoch 28/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.9350 - categorical_accuracy: 0.9811\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.9365 - categorical_accuracy: 0.9821 - val_loss: 4.1535 - val_categorical_accuracy: 0.5574\n",
      "Epoch 29/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.9210 - categorical_accuracy: 0.9818\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.9204 - categorical_accuracy: 0.9821 - val_loss: 4.1299 - val_categorical_accuracy: 0.5246\n",
      "Epoch 30/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.8789 - categorical_accuracy: 0.9906\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.8794 - categorical_accuracy: 0.9911 - val_loss: 4.1289 - val_categorical_accuracy: 0.5246\n",
      "Epoch 31/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.8786 - categorical_accuracy: 0.9953\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.8771 - categorical_accuracy: 0.9955 - val_loss: 4.2877 - val_categorical_accuracy: 0.4918\n",
      "Epoch 32/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.8385 - categorical_accuracy: 0.9955\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.8381 - categorical_accuracy: 0.9955 - val_loss: 4.1461 - val_categorical_accuracy: 0.5574\n",
      "Epoch 33/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.8177 - categorical_accuracy: 1.0000\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.60656\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.8174 - categorical_accuracy: 1.0000 - val_loss: 4.0181 - val_categorical_accuracy: 0.6066\n",
      "Epoch 34/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.8034 - categorical_accuracy: 0.9955\n",
      "Epoch 00034: val_categorical_accuracy improved from 0.60656 to 0.65574, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.8075 - categorical_accuracy: 0.9955 - val_loss: 3.9398 - val_categorical_accuracy: 0.6557\n",
      "Epoch 35/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.8090 - categorical_accuracy: 1.0000\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.65574\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.8076 - categorical_accuracy: 1.0000 - val_loss: 4.0577 - val_categorical_accuracy: 0.5902\n",
      "Epoch 36/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.7810 - categorical_accuracy: 0.9954\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.65574\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.7801 - categorical_accuracy: 0.9955 - val_loss: 4.0379 - val_categorical_accuracy: 0.6230\n",
      "Epoch 37/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.7620 - categorical_accuracy: 0.9953\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.65574\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.7597 - categorical_accuracy: 0.9955 - val_loss: 4.1047 - val_categorical_accuracy: 0.5738\n",
      "Epoch 38/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.7493 - categorical_accuracy: 1.0000\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.65574\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.7504 - categorical_accuracy: 1.0000 - val_loss: 4.0344 - val_categorical_accuracy: 0.6393\n",
      "Epoch 39/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.7347 - categorical_accuracy: 1.0000\n",
      "Epoch 00039: val_categorical_accuracy improved from 0.65574 to 0.67213, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_75_percent.h5\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.7336 - categorical_accuracy: 1.0000 - val_loss: 3.9392 - val_categorical_accuracy: 0.6721\n",
      "Epoch 40/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.7307 - categorical_accuracy: 1.0000\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.7301 - categorical_accuracy: 1.0000 - val_loss: 3.9675 - val_categorical_accuracy: 0.6393\n",
      "Epoch 41/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.7176 - categorical_accuracy: 1.0000\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.7189 - categorical_accuracy: 1.0000 - val_loss: 4.1760 - val_categorical_accuracy: 0.5902\n",
      "Epoch 42/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.7101 - categorical_accuracy: 1.0000\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.7096 - categorical_accuracy: 1.0000 - val_loss: 3.9260 - val_categorical_accuracy: 0.6230\n",
      "Epoch 43/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.7013 - categorical_accuracy: 1.0000\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.7004 - categorical_accuracy: 1.0000 - val_loss: 4.0038 - val_categorical_accuracy: 0.6393\n",
      "Epoch 44/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.6975 - categorical_accuracy: 1.0000\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6968 - categorical_accuracy: 1.0000 - val_loss: 3.9185 - val_categorical_accuracy: 0.6721\n",
      "Epoch 45/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.6870 - categorical_accuracy: 1.0000\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6867 - categorical_accuracy: 1.0000 - val_loss: 4.0268 - val_categorical_accuracy: 0.6066\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/224 [===========================>..] - ETA: 0s - loss: 2.6733 - categorical_accuracy: 1.0000\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6734 - categorical_accuracy: 1.0000 - val_loss: 3.9762 - val_categorical_accuracy: 0.5738\n",
      "Epoch 47/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.6746 - categorical_accuracy: 0.9955\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6738 - categorical_accuracy: 0.9955 - val_loss: 3.9225 - val_categorical_accuracy: 0.6721\n",
      "Epoch 48/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.6550 - categorical_accuracy: 1.0000\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6545 - categorical_accuracy: 1.0000 - val_loss: 3.9430 - val_categorical_accuracy: 0.6557\n",
      "Epoch 49/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.6454 - categorical_accuracy: 1.0000\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6466 - categorical_accuracy: 1.0000 - val_loss: 3.9463 - val_categorical_accuracy: 0.6393\n",
      "Epoch 50/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.6429 - categorical_accuracy: 1.0000\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6432 - categorical_accuracy: 1.0000 - val_loss: 3.9826 - val_categorical_accuracy: 0.5738\n",
      "Epoch 51/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.6312 - categorical_accuracy: 1.0000\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6297 - categorical_accuracy: 1.0000 - val_loss: 3.9605 - val_categorical_accuracy: 0.6066\n",
      "Epoch 52/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.6314 - categorical_accuracy: 1.0000\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6312 - categorical_accuracy: 1.0000 - val_loss: 3.8732 - val_categorical_accuracy: 0.6393\n",
      "Epoch 53/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.6150 - categorical_accuracy: 1.0000\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6147 - categorical_accuracy: 1.0000 - val_loss: 3.8905 - val_categorical_accuracy: 0.6557\n",
      "Epoch 54/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.6119 - categorical_accuracy: 1.0000\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6115 - categorical_accuracy: 1.0000 - val_loss: 3.9543 - val_categorical_accuracy: 0.6557\n",
      "Epoch 55/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.6057 - categorical_accuracy: 1.0000\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6052 - categorical_accuracy: 1.0000 - val_loss: 3.9196 - val_categorical_accuracy: 0.6393\n",
      "Epoch 56/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5998 - categorical_accuracy: 1.0000\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.6002 - categorical_accuracy: 1.0000 - val_loss: 3.9537 - val_categorical_accuracy: 0.5902\n",
      "Epoch 57/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5863 - categorical_accuracy: 1.0000\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5876 - categorical_accuracy: 1.0000 - val_loss: 4.0155 - val_categorical_accuracy: 0.6393\n",
      "Epoch 58/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.5794 - categorical_accuracy: 1.0000\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5808 - categorical_accuracy: 1.0000 - val_loss: 3.9552 - val_categorical_accuracy: 0.6557\n",
      "Epoch 59/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5760 - categorical_accuracy: 1.0000\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5758 - categorical_accuracy: 1.0000 - val_loss: 3.9057 - val_categorical_accuracy: 0.6230\n",
      "Epoch 60/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.5726 - categorical_accuracy: 1.0000\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5725 - categorical_accuracy: 1.0000 - val_loss: 4.0344 - val_categorical_accuracy: 0.6721\n",
      "Epoch 61/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5628 - categorical_accuracy: 1.0000\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5628 - categorical_accuracy: 1.0000 - val_loss: 3.9480 - val_categorical_accuracy: 0.6393\n",
      "Epoch 62/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5604 - categorical_accuracy: 1.0000\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5601 - categorical_accuracy: 1.0000 - val_loss: 3.9669 - val_categorical_accuracy: 0.6393\n",
      "Epoch 63/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5492 - categorical_accuracy: 1.0000\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5489 - categorical_accuracy: 1.0000 - val_loss: 3.9559 - val_categorical_accuracy: 0.6393\n",
      "Epoch 64/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5466 - categorical_accuracy: 1.0000\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5461 - categorical_accuracy: 1.0000 - val_loss: 3.9649 - val_categorical_accuracy: 0.6066\n",
      "Epoch 65/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5376 - categorical_accuracy: 1.0000\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5376 - categorical_accuracy: 1.0000 - val_loss: 3.9457 - val_categorical_accuracy: 0.6066\n",
      "Epoch 66/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5344 - categorical_accuracy: 1.0000\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5342 - categorical_accuracy: 1.0000 - val_loss: 3.9237 - val_categorical_accuracy: 0.6721\n",
      "Epoch 67/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.5277 - categorical_accuracy: 1.0000\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5273 - categorical_accuracy: 1.0000 - val_loss: 3.8782 - val_categorical_accuracy: 0.6393\n",
      "Epoch 68/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5242 - categorical_accuracy: 1.0000\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5242 - categorical_accuracy: 1.0000 - val_loss: 3.8448 - val_categorical_accuracy: 0.6393\n",
      "Epoch 69/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5146 - categorical_accuracy: 1.0000\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5149 - categorical_accuracy: 1.0000 - val_loss: 3.9148 - val_categorical_accuracy: 0.6066\n",
      "Epoch 70/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.5092 - categorical_accuracy: 1.0000\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5100 - categorical_accuracy: 1.0000 - val_loss: 3.8589 - val_categorical_accuracy: 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.5039 - categorical_accuracy: 1.0000\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.5037 - categorical_accuracy: 1.0000 - val_loss: 3.8485 - val_categorical_accuracy: 0.6393\n",
      "Epoch 72/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4968 - categorical_accuracy: 1.0000\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4965 - categorical_accuracy: 1.0000 - val_loss: 3.8760 - val_categorical_accuracy: 0.6230\n",
      "Epoch 73/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4915 - categorical_accuracy: 1.0000\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4912 - categorical_accuracy: 1.0000 - val_loss: 4.0156 - val_categorical_accuracy: 0.5738\n",
      "Epoch 74/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4845 - categorical_accuracy: 1.0000\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4843 - categorical_accuracy: 1.0000 - val_loss: 3.8893 - val_categorical_accuracy: 0.6393\n",
      "Epoch 75/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4795 - categorical_accuracy: 1.0000\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4795 - categorical_accuracy: 1.0000 - val_loss: 4.0174 - val_categorical_accuracy: 0.6066\n",
      "Epoch 76/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.4730 - categorical_accuracy: 1.00 - ETA: 0s - loss: 2.4730 - categorical_accuracy: 1.0000\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4727 - categorical_accuracy: 1.0000 - val_loss: 3.8979 - val_categorical_accuracy: 0.6557\n",
      "Epoch 77/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.4692 - categorical_accuracy: 1.0000\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4689 - categorical_accuracy: 1.0000 - val_loss: 3.8193 - val_categorical_accuracy: 0.6393\n",
      "Epoch 78/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4621 - categorical_accuracy: 1.0000\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4631 - categorical_accuracy: 1.0000 - val_loss: 3.8086 - val_categorical_accuracy: 0.6393\n",
      "Epoch 79/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4550 - categorical_accuracy: 1.0000\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4549 - categorical_accuracy: 1.0000 - val_loss: 3.8801 - val_categorical_accuracy: 0.6557\n",
      "Epoch 80/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.4504 - categorical_accuracy: 1.0000\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4499 - categorical_accuracy: 1.0000 - val_loss: 3.8867 - val_categorical_accuracy: 0.6393\n",
      "Epoch 81/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4446 - categorical_accuracy: 1.0000\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4443 - categorical_accuracy: 1.0000 - val_loss: 3.8544 - val_categorical_accuracy: 0.6393\n",
      "Epoch 82/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4365 - categorical_accuracy: 1.0000\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4376 - categorical_accuracy: 1.0000 - val_loss: 3.8886 - val_categorical_accuracy: 0.6557\n",
      "Epoch 83/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.4329 - categorical_accuracy: 1.0000\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4331 - categorical_accuracy: 1.0000 - val_loss: 3.8321 - val_categorical_accuracy: 0.6230\n",
      "Epoch 84/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.4336 - categorical_accuracy: 1.0000\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4337 - categorical_accuracy: 1.0000 - val_loss: 3.8504 - val_categorical_accuracy: 0.6066\n",
      "Epoch 85/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4240 - categorical_accuracy: 1.0000\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4238 - categorical_accuracy: 1.0000 - val_loss: 3.8960 - val_categorical_accuracy: 0.6557\n",
      "Epoch 86/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4179 - categorical_accuracy: 1.0000\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4180 - categorical_accuracy: 1.0000 - val_loss: 3.8685 - val_categorical_accuracy: 0.6393\n",
      "Epoch 87/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4141 - categorical_accuracy: 1.0000\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4137 - categorical_accuracy: 1.0000 - val_loss: 3.8686 - val_categorical_accuracy: 0.6230\n",
      "Epoch 88/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.4060 - categorical_accuracy: 1.0000\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4059 - categorical_accuracy: 1.0000 - val_loss: 3.7763 - val_categorical_accuracy: 0.6393\n",
      "Epoch 89/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.4017 - categorical_accuracy: 1.0000\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.4016 - categorical_accuracy: 1.0000 - val_loss: 3.8904 - val_categorical_accuracy: 0.6721\n",
      "Epoch 90/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.3949 - categorical_accuracy: 1.0000\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3955 - categorical_accuracy: 1.0000 - val_loss: 3.8859 - val_categorical_accuracy: 0.6557\n",
      "Epoch 91/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.3897 - categorical_accuracy: 1.0000\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3896 - categorical_accuracy: 1.0000 - val_loss: 3.8332 - val_categorical_accuracy: 0.6557\n",
      "Epoch 92/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.3854 - categorical_accuracy: 1.0000\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3853 - categorical_accuracy: 1.0000 - val_loss: 3.7094 - val_categorical_accuracy: 0.6393\n",
      "Epoch 93/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.3792 - categorical_accuracy: 1.0000\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3792 - categorical_accuracy: 1.0000 - val_loss: 3.8575 - val_categorical_accuracy: 0.6557\n",
      "Epoch 94/100\n",
      "216/224 [===========================>..] - ETA: 0s - loss: 2.3748 - categorical_accuracy: 1.0000\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3752 - categorical_accuracy: 1.0000 - val_loss: 3.8595 - val_categorical_accuracy: 0.6721\n",
      "Epoch 95/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.3705 - categorical_accuracy: 1.0000\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3703 - categorical_accuracy: 1.0000 - val_loss: 3.7426 - val_categorical_accuracy: 0.6557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.3627 - categorical_accuracy: 1.0000\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3629 - categorical_accuracy: 1.0000 - val_loss: 3.8051 - val_categorical_accuracy: 0.6066\n",
      "Epoch 97/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.3576 - categorical_accuracy: 1.0000\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3575 - categorical_accuracy: 1.0000 - val_loss: 3.8424 - val_categorical_accuracy: 0.6393\n",
      "Epoch 98/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.3521 - categorical_accuracy: 1.0000\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3520 - categorical_accuracy: 1.0000 - val_loss: 3.8219 - val_categorical_accuracy: 0.6393\n",
      "Epoch 99/100\n",
      "212/224 [===========================>..] - ETA: 0s - loss: 2.3469 - categorical_accuracy: 1.0000\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3466 - categorical_accuracy: 1.0000 - val_loss: 3.8277 - val_categorical_accuracy: 0.6557\n",
      "Epoch 100/100\n",
      "220/224 [============================>.] - ETA: 0s - loss: 2.3440 - categorical_accuracy: 1.0000\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.67213\n",
      "224/224 [==============================] - 1s 6ms/sample - loss: 2.3439 - categorical_accuracy: 1.0000 - val_loss: 3.8015 - val_categorical_accuracy: 0.6393\n",
      "61/61 [==============================] - 0s 2ms/sample - loss: 3.8015 - categorical_accuracy: 0.6393\n",
      "Test Accuracy = 0.6393443\n",
      "61/61 [==============================] - 0s 4ms/sample\n",
      "\n",
      "===============================================================================================================================\n",
      "=============================== Confusion_matrix for data with overlap ratio of 75% is as below ===============================\n",
      "===============================================================================================================================\n",
      "\n",
      "[[ 5  0  1  1  1  0  0  2  0  0  0  0  0]\n",
      " [ 0  2  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  4  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  2  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 15  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  7  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0]]\n",
      "==============================================================================================================================\n",
      "[10  3  1  3  6  2  6 15  4  2  7  1  1]\n",
      "==============================================================================================================================\n",
      "\n",
      "==============================================================================================================================\n",
      "=============================== Sub Model below will be saved to be used for transfer learning  ==============================\n",
      "==============================================================================================================================\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 103, 24, 24, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_1 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 106,544\n",
      "Trainable params: 105,808\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "===============================================================================================================================\n",
      "======================================== Data with overlap ratio of 85% will be trained =======================================\n",
      "===============================================================================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639, 103, 24, 24, 1) (169, 103, 24, 24, 1) (639,) (169,)\n",
      "Total samples per class: [6, 135, 36, 11, 33, 77, 4, 29, 4, 83, 216, 43, 21, 89, 11, 10], Total number of samples is 808.\n",
      "\n",
      "unique classes in Ytest: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16], Total number of samples in Ytest is 169.\n",
      "number of samples per class in Ytest: [ 2 27  8  3  7 16  1  6  1 17 44  9  5 18  3  2]\n",
      "\n",
      "Xtrain => (639, 103, 24, 24, 1)\n",
      "Xtest  => (169, 103, 24, 24, 1)\n",
      "Ytrain => (639, 16)\n",
      "Ytest  => (169, 16)\n",
      "\n",
      "Model: \"3D-SRNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 103, 24, 24, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_2 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fc_256 (Dense)                  (None, 256)          16640       global_max_pooling3d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fc16 (Dense)                    (None, 16)           4112        fc_256[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 127,296\n",
      "Trainable params: 126,560\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 639 samples, validate on 169 samples\n",
      "Epoch 1/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 5.7111 - categorical_accuracy: 0.2756\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.13018, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 9s 13ms/sample - loss: 5.7002 - categorical_accuracy: 0.2754 - val_loss: 6.1094 - val_categorical_accuracy: 0.1302\n",
      "Epoch 2/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 4.7821 - categorical_accuracy: 0.3892\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.13018\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 4.7781 - categorical_accuracy: 0.3881 - val_loss: 5.3868 - val_categorical_accuracy: 0.0473\n",
      "Epoch 3/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 4.5330 - categorical_accuracy: 0.5114\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.13018\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 4.5361 - categorical_accuracy: 0.5055 - val_loss: 5.5006 - val_categorical_accuracy: 0.0237\n",
      "Epoch 4/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 4.3513 - categorical_accuracy: 0.5497\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.13018 to 0.28994, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 4.3439 - categorical_accuracy: 0.5509 - val_loss: 5.1957 - val_categorical_accuracy: 0.2899\n",
      "Epoch 5/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 4.2154 - categorical_accuracy: 0.6122\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.28994\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 4.2239 - categorical_accuracy: 0.6119 - val_loss: 5.3210 - val_categorical_accuracy: 0.1657\n",
      "Epoch 6/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 4.0944 - categorical_accuracy: 0.6440\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.28994\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 4.0937 - categorical_accuracy: 0.6448 - val_loss: 5.1243 - val_categorical_accuracy: 0.2840\n",
      "Epoch 7/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 3.9730 - categorical_accuracy: 0.6683\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.28994 to 0.31953, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.9726 - categorical_accuracy: 0.6682 - val_loss: 4.8956 - val_categorical_accuracy: 0.3195\n",
      "Epoch 8/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 3.8482 - categorical_accuracy: 0.7321\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.31953 to 0.49112, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 4ms/sample - loss: 3.8415 - categorical_accuracy: 0.7355 - val_loss: 4.5305 - val_categorical_accuracy: 0.4911\n",
      "Epoch 9/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 3.7431 - categorical_accuracy: 0.7549\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.49112\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.7409 - categorical_accuracy: 0.7574 - val_loss: 4.6382 - val_categorical_accuracy: 0.4320\n",
      "Epoch 10/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 3.6758 - categorical_accuracy: 0.7772\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.49112\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.6752 - categorical_accuracy: 0.7746 - val_loss: 4.5911 - val_categorical_accuracy: 0.4320\n",
      "Epoch 11/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 3.5681 - categorical_accuracy: 0.8084\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.49112\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.5737 - categorical_accuracy: 0.8044 - val_loss: 4.7563 - val_categorical_accuracy: 0.3728\n",
      "Epoch 12/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.4925 - categorical_accuracy: 0.8259\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.49112\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.4935 - categorical_accuracy: 0.8263 - val_loss: 4.9573 - val_categorical_accuracy: 0.2840\n",
      "Epoch 13/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.4470 - categorical_accuracy: 0.8339\n",
      "Epoch 00013: val_categorical_accuracy improved from 0.49112 to 0.56805, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.4429 - categorical_accuracy: 0.8357 - val_loss: 4.2599 - val_categorical_accuracy: 0.5680\n",
      "Epoch 14/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 3.3408 - categorical_accuracy: 0.8847\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.56805\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.3538 - categorical_accuracy: 0.8779 - val_loss: 4.2855 - val_categorical_accuracy: 0.5503\n",
      "Epoch 15/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.2939 - categorical_accuracy: 0.8829\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.56805\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.2910 - categorical_accuracy: 0.8842 - val_loss: 4.3297 - val_categorical_accuracy: 0.5207\n",
      "Epoch 16/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 3.2257 - categorical_accuracy: 0.9183\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.56805\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.2246 - categorical_accuracy: 0.9186 - val_loss: 4.2648 - val_categorical_accuracy: 0.5680\n",
      "Epoch 17/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 3.1667 - categorical_accuracy: 0.9318\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.56805\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.1685 - categorical_accuracy: 0.9311 - val_loss: 4.3771 - val_categorical_accuracy: 0.5266\n",
      "Epoch 18/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.1261 - categorical_accuracy: 0.9320\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.56805\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.1245 - categorical_accuracy: 0.9327 - val_loss: 4.3181 - val_categorical_accuracy: 0.4911\n",
      "Epoch 19/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 3.1060 - categorical_accuracy: 0.9318\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.56805 to 0.57396, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 4ms/sample - loss: 3.1094 - categorical_accuracy: 0.9296 - val_loss: 4.2317 - val_categorical_accuracy: 0.5740\n",
      "Epoch 20/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.0646 - categorical_accuracy: 0.9446\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.57396\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.0663 - categorical_accuracy: 0.9437 - val_loss: 4.2984 - val_categorical_accuracy: 0.5444\n",
      "Epoch 21/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 3.0299 - categorical_accuracy: 0.9478\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.57396\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 3.0290 - categorical_accuracy: 0.9484 - val_loss: 4.6267 - val_categorical_accuracy: 0.4852\n",
      "Epoch 22/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.9748 - categorical_accuracy: 0.9636\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.57396\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.9735 - categorical_accuracy: 0.9640 - val_loss: 4.2988 - val_categorical_accuracy: 0.5385\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/639 [============================>.] - ETA: 0s - loss: 2.9459 - categorical_accuracy: 0.9728\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.57396\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.9454 - categorical_accuracy: 0.9734 - val_loss: 4.2275 - val_categorical_accuracy: 0.5444\n",
      "Epoch 24/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.9053 - categorical_accuracy: 0.9826\n",
      "Epoch 00024: val_categorical_accuracy improved from 0.57396 to 0.59172, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 3s 4ms/sample - loss: 2.9045 - categorical_accuracy: 0.9828 - val_loss: 4.0893 - val_categorical_accuracy: 0.5917\n",
      "Epoch 25/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.8828 - categorical_accuracy: 0.9789\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.59172\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.8857 - categorical_accuracy: 0.9781 - val_loss: 4.2209 - val_categorical_accuracy: 0.5207\n",
      "Epoch 26/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.8673 - categorical_accuracy: 0.9792\n",
      "Epoch 00026: val_categorical_accuracy improved from 0.59172 to 0.60947, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.8742 - categorical_accuracy: 0.9765 - val_loss: 4.0111 - val_categorical_accuracy: 0.6095\n",
      "Epoch 27/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.8362 - categorical_accuracy: 0.9889\n",
      "Epoch 00027: val_categorical_accuracy improved from 0.60947 to 0.62130, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.8365 - categorical_accuracy: 0.9890 - val_loss: 3.9249 - val_categorical_accuracy: 0.6213\n",
      "Epoch 28/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.8172 - categorical_accuracy: 0.9919\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.62130\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.8160 - categorical_accuracy: 0.9922 - val_loss: 4.0909 - val_categorical_accuracy: 0.5562\n",
      "Epoch 29/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.7983 - categorical_accuracy: 0.9886\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.62130\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.7990 - categorical_accuracy: 0.9875 - val_loss: 4.1655 - val_categorical_accuracy: 0.5799\n",
      "Epoch 30/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.7760 - categorical_accuracy: 0.9920\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.62130\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.7755 - categorical_accuracy: 0.9922 - val_loss: 3.9985 - val_categorical_accuracy: 0.5858\n",
      "Epoch 31/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.7682 - categorical_accuracy: 0.9921\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.62130\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.7699 - categorical_accuracy: 0.9922 - val_loss: 3.9795 - val_categorical_accuracy: 0.5621\n",
      "Epoch 32/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.7430 - categorical_accuracy: 0.9968\n",
      "Epoch 00032: val_categorical_accuracy improved from 0.62130 to 0.64497, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.7423 - categorical_accuracy: 0.9969 - val_loss: 4.0404 - val_categorical_accuracy: 0.6450\n",
      "Epoch 33/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.7300 - categorical_accuracy: 0.9953\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.7303 - categorical_accuracy: 0.9953 - val_loss: 3.9275 - val_categorical_accuracy: 0.5858\n",
      "Epoch 34/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.7128 - categorical_accuracy: 0.9968\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.7126 - categorical_accuracy: 0.9969 - val_loss: 3.9518 - val_categorical_accuracy: 0.6213\n",
      "Epoch 35/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.7020 - categorical_accuracy: 1.0000\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.7007 - categorical_accuracy: 1.0000 - val_loss: 4.0657 - val_categorical_accuracy: 0.5680\n",
      "Epoch 36/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.6897 - categorical_accuracy: 0.9951\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.6891 - categorical_accuracy: 0.9953 - val_loss: 4.1588 - val_categorical_accuracy: 0.5385\n",
      "Epoch 37/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.6733 - categorical_accuracy: 1.0000\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.6732 - categorical_accuracy: 1.0000 - val_loss: 3.9087 - val_categorical_accuracy: 0.6213\n",
      "Epoch 38/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.6622 - categorical_accuracy: 0.9984\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.6623 - categorical_accuracy: 0.9984 - val_loss: 4.0008 - val_categorical_accuracy: 0.5976\n",
      "Epoch 39/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.6547 - categorical_accuracy: 0.9984\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.6532 - categorical_accuracy: 0.9984 - val_loss: 3.9522 - val_categorical_accuracy: 0.6036\n",
      "Epoch 40/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.6413 - categorical_accuracy: 0.9968\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.6418 - categorical_accuracy: 0.9969 - val_loss: 4.3622 - val_categorical_accuracy: 0.4970\n",
      "Epoch 41/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.6259 - categorical_accuracy: 1.0000\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.6249 - categorical_accuracy: 1.0000 - val_loss: 3.9295 - val_categorical_accuracy: 0.6154\n",
      "Epoch 42/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.6151 - categorical_accuracy: 0.9984\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.6143 - categorical_accuracy: 0.9984 - val_loss: 3.9500 - val_categorical_accuracy: 0.6154\n",
      "Epoch 43/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.6018 - categorical_accuracy: 1.0000\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.6024 - categorical_accuracy: 1.0000 - val_loss: 4.0488 - val_categorical_accuracy: 0.5444\n",
      "Epoch 44/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.5967 - categorical_accuracy: 0.9984\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.5966 - categorical_accuracy: 0.9984 - val_loss: 4.0201 - val_categorical_accuracy: 0.5680\n",
      "Epoch 45/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.5833 - categorical_accuracy: 1.0000\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.5830 - categorical_accuracy: 1.0000 - val_loss: 4.0052 - val_categorical_accuracy: 0.5503\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/639 [============================>.] - ETA: 0s - loss: 2.5727 - categorical_accuracy: 1.0000\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.5737 - categorical_accuracy: 1.0000 - val_loss: 3.9808 - val_categorical_accuracy: 0.5740\n",
      "Epoch 47/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.5679 - categorical_accuracy: 1.0000\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.64497\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.5673 - categorical_accuracy: 1.0000 - val_loss: 4.0192 - val_categorical_accuracy: 0.5562\n",
      "Epoch 48/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.5570 - categorical_accuracy: 1.0000\n",
      "Epoch 00048: val_categorical_accuracy improved from 0.64497 to 0.66272, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_85_percent.h5\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.5570 - categorical_accuracy: 1.0000 - val_loss: 3.9319 - val_categorical_accuracy: 0.6627\n",
      "Epoch 49/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.5515 - categorical_accuracy: 1.0000 ETA: 0s - loss: 2.5523 - categorical_accuracy: 1.00\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.5518 - categorical_accuracy: 1.0000 - val_loss: 4.0052 - val_categorical_accuracy: 0.5621\n",
      "Epoch 50/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.5409 - categorical_accuracy: 1.0000\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.5413 - categorical_accuracy: 1.0000 - val_loss: 3.9041 - val_categorical_accuracy: 0.5799\n",
      "Epoch 51/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.5296 - categorical_accuracy: 1.0000\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.5286 - categorical_accuracy: 1.0000 - val_loss: 3.9371 - val_categorical_accuracy: 0.6331\n",
      "Epoch 52/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.5178 - categorical_accuracy: 1.0000\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.5175 - categorical_accuracy: 1.0000 - val_loss: 3.8818 - val_categorical_accuracy: 0.6509\n",
      "Epoch 53/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.5103 - categorical_accuracy: 1.0000\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.5102 - categorical_accuracy: 1.0000 - val_loss: 3.9994 - val_categorical_accuracy: 0.6154\n",
      "Epoch 54/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4992 - categorical_accuracy: 1.0000\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4992 - categorical_accuracy: 1.0000 - val_loss: 3.9019 - val_categorical_accuracy: 0.6036\n",
      "Epoch 55/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4920 - categorical_accuracy: 1.0000\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4924 - categorical_accuracy: 1.0000 - val_loss: 3.9296 - val_categorical_accuracy: 0.6095\n",
      "Epoch 56/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.4831 - categorical_accuracy: 1.0000\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4830 - categorical_accuracy: 1.0000 - val_loss: 3.8571 - val_categorical_accuracy: 0.6154\n",
      "Epoch 57/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4761 - categorical_accuracy: 1.0000 ETA: 0s - loss: 2.4756 - categori\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4760 - categorical_accuracy: 1.0000 - val_loss: 3.8698 - val_categorical_accuracy: 0.5976\n",
      "Epoch 58/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4643 - categorical_accuracy: 1.0000\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4645 - categorical_accuracy: 1.0000 - val_loss: 3.8401 - val_categorical_accuracy: 0.6272\n",
      "Epoch 59/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4586 - categorical_accuracy: 1.0000\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4584 - categorical_accuracy: 1.0000 - val_loss: 3.8495 - val_categorical_accuracy: 0.6154\n",
      "Epoch 60/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.4517 - categorical_accuracy: 1.0000\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4515 - categorical_accuracy: 1.0000 - val_loss: 4.0118 - val_categorical_accuracy: 0.5385\n",
      "Epoch 61/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.4418 - categorical_accuracy: 1.0000\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4418 - categorical_accuracy: 1.0000 - val_loss: 3.8898 - val_categorical_accuracy: 0.6095\n",
      "Epoch 62/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.4341 - categorical_accuracy: 1.0000\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4339 - categorical_accuracy: 1.0000 - val_loss: 3.8794 - val_categorical_accuracy: 0.6154\n",
      "Epoch 63/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.4297 - categorical_accuracy: 1.0000\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4293 - categorical_accuracy: 1.0000 - val_loss: 3.7635 - val_categorical_accuracy: 0.6036\n",
      "Epoch 64/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4166 - categorical_accuracy: 1.0000\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4165 - categorical_accuracy: 1.0000 - val_loss: 3.8189 - val_categorical_accuracy: 0.6036\n",
      "Epoch 65/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.4102 - categorical_accuracy: 1.0000\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4099 - categorical_accuracy: 1.0000 - val_loss: 4.0049 - val_categorical_accuracy: 0.5740\n",
      "Epoch 66/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.4008 - categorical_accuracy: 1.0000\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.4011 - categorical_accuracy: 1.0000 - val_loss: 3.8195 - val_categorical_accuracy: 0.6272\n",
      "Epoch 67/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.3956 - categorical_accuracy: 1.0000\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3956 - categorical_accuracy: 1.0000 - val_loss: 3.8208 - val_categorical_accuracy: 0.6213\n",
      "Epoch 68/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.3872 - categorical_accuracy: 1.0000\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3873 - categorical_accuracy: 1.0000 - val_loss: 3.8234 - val_categorical_accuracy: 0.6036\n",
      "Epoch 69/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3772 - categorical_accuracy: 1.0000\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3783 - categorical_accuracy: 1.0000 - val_loss: 3.8409 - val_categorical_accuracy: 0.6213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3732 - categorical_accuracy: 1.0000\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3732 - categorical_accuracy: 1.0000 - val_loss: 3.8610 - val_categorical_accuracy: 0.6154\n",
      "Epoch 71/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.3643 - categorical_accuracy: 1.0000\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3643 - categorical_accuracy: 1.0000 - val_loss: 3.8922 - val_categorical_accuracy: 0.5976\n",
      "Epoch 72/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.3616 - categorical_accuracy: 1.0000\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3617 - categorical_accuracy: 1.0000 - val_loss: 3.8692 - val_categorical_accuracy: 0.5740\n",
      "Epoch 73/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.3496 - categorical_accuracy: 1.0000\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3493 - categorical_accuracy: 1.0000 - val_loss: 3.8736 - val_categorical_accuracy: 0.6095\n",
      "Epoch 74/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.3407 - categorical_accuracy: 1.0000\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3406 - categorical_accuracy: 1.0000 - val_loss: 3.7572 - val_categorical_accuracy: 0.5799\n",
      "Epoch 75/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.3386 - categorical_accuracy: 1.0000\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3394 - categorical_accuracy: 1.0000 - val_loss: 3.8170 - val_categorical_accuracy: 0.6391\n",
      "Epoch 76/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.3283 - categorical_accuracy: 1.0000\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3280 - categorical_accuracy: 1.0000 - val_loss: 3.7763 - val_categorical_accuracy: 0.5858\n",
      "Epoch 77/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.3188 - categorical_accuracy: 1.0000\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3191 - categorical_accuracy: 1.0000 - val_loss: 3.7692 - val_categorical_accuracy: 0.6213\n",
      "Epoch 78/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.3125 - categorical_accuracy: 1.0000\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3128 - categorical_accuracy: 1.0000 - val_loss: 3.8840 - val_categorical_accuracy: 0.5976\n",
      "Epoch 79/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.3071 - categorical_accuracy: 1.0000\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.3068 - categorical_accuracy: 1.0000 - val_loss: 3.7779 - val_categorical_accuracy: 0.6095\n",
      "Epoch 80/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.2985 - categorical_accuracy: 1.0000\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2984 - categorical_accuracy: 1.0000 - val_loss: 3.6710 - val_categorical_accuracy: 0.6272\n",
      "Epoch 81/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.2913 - categorical_accuracy: 1.0000\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2914 - categorical_accuracy: 1.0000 - val_loss: 3.7211 - val_categorical_accuracy: 0.6213\n",
      "Epoch 82/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.2844 - categorical_accuracy: 1.0000\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2845 - categorical_accuracy: 1.0000 - val_loss: 3.7703 - val_categorical_accuracy: 0.6331\n",
      "Epoch 83/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.2768 - categorical_accuracy: 1.0000\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2766 - categorical_accuracy: 1.0000 - val_loss: 3.7436 - val_categorical_accuracy: 0.6272\n",
      "Epoch 84/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.2696 - categorical_accuracy: 1.0000\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2694 - categorical_accuracy: 1.0000 - val_loss: 3.7090 - val_categorical_accuracy: 0.5799\n",
      "Epoch 85/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.2635 - categorical_accuracy: 1.0000\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2633 - categorical_accuracy: 1.0000 - val_loss: 3.8587 - val_categorical_accuracy: 0.5621\n",
      "Epoch 86/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2552 - categorical_accuracy: 1.0000\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2552 - categorical_accuracy: 1.0000 - val_loss: 3.7031 - val_categorical_accuracy: 0.5917\n",
      "Epoch 87/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.2496 - categorical_accuracy: 1.0000\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2494 - categorical_accuracy: 1.0000 - val_loss: 3.6744 - val_categorical_accuracy: 0.6036\n",
      "Epoch 88/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.2429 - categorical_accuracy: 1.0000\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2426 - categorical_accuracy: 1.0000 - val_loss: 3.7885 - val_categorical_accuracy: 0.6095\n",
      "Epoch 89/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.2354 - categorical_accuracy: 1.0000\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2350 - categorical_accuracy: 1.0000 - val_loss: 3.7936 - val_categorical_accuracy: 0.5917\n",
      "Epoch 90/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.2285 - categorical_accuracy: 1.0000\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2284 - categorical_accuracy: 1.0000 - val_loss: 3.6751 - val_categorical_accuracy: 0.6331\n",
      "Epoch 91/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.2205 - categorical_accuracy: 1.0000\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2203 - categorical_accuracy: 1.0000 - val_loss: 3.7331 - val_categorical_accuracy: 0.6095\n",
      "Epoch 92/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.2145 - categorical_accuracy: 1.0000\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2144 - categorical_accuracy: 1.0000 - val_loss: 3.7284 - val_categorical_accuracy: 0.6154\n",
      "Epoch 93/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.2111 - categorical_accuracy: 0.9984\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2108 - categorical_accuracy: 0.9984 - val_loss: 3.7259 - val_categorical_accuracy: 0.6154\n",
      "Epoch 94/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.2013 - categorical_accuracy: 1.0000\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.2014 - categorical_accuracy: 1.0000 - val_loss: 3.7046 - val_categorical_accuracy: 0.5917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.1940 - categorical_accuracy: 1.0000\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.1940 - categorical_accuracy: 1.0000 - val_loss: 3.6972 - val_categorical_accuracy: 0.6331\n",
      "Epoch 96/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.1886 - categorical_accuracy: 1.0000\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.1888 - categorical_accuracy: 1.0000 - val_loss: 3.7373 - val_categorical_accuracy: 0.5858\n",
      "Epoch 97/100\n",
      "616/639 [===========================>..] - ETA: 0s - loss: 2.1821 - categorical_accuracy: 1.0000\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.1820 - categorical_accuracy: 1.0000 - val_loss: 3.8107 - val_categorical_accuracy: 0.5740\n",
      "Epoch 98/100\n",
      "624/639 [============================>.] - ETA: 0s - loss: 2.1737 - categorical_accuracy: 1.0000\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.1735 - categorical_accuracy: 1.0000 - val_loss: 3.7047 - val_categorical_accuracy: 0.6036\n",
      "Epoch 99/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.1682 - categorical_accuracy: 1.0000\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.1682 - categorical_accuracy: 1.0000 - val_loss: 3.6938 - val_categorical_accuracy: 0.6036\n",
      "Epoch 100/100\n",
      "632/639 [============================>.] - ETA: 0s - loss: 2.1611 - categorical_accuracy: 1.0000\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.66272\n",
      "639/639 [==============================] - 2s 3ms/sample - loss: 2.1610 - categorical_accuracy: 1.0000 - val_loss: 3.6705 - val_categorical_accuracy: 0.6036\n",
      "169/169 [==============================] - 0s 713us/sample - loss: 3.6705 - categorical_accuracy: 0.6036\n",
      "Test Accuracy = 0.6035503\n",
      "169/169 [==============================] - 0s 2ms/sample\n",
      "\n",
      "===============================================================================================================================\n",
      "=============================== Confusion_matrix for data with overlap ratio of 85% is as below ===============================\n",
      "===============================================================================================================================\n",
      "\n",
      "[[ 0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 11  0  0  7  3  0  4  0  0  2  0  0  0  0  0]\n",
      " [ 0  5  0  0  0  1  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  3  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  4  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  5  0  0  0  0  0  0  0  9  3  0  0  0  0  0]\n",
      " [ 0  3  0  0  1  2  0  0  0  0 37  0  0  1  0  0]\n",
      " [ 0  6  0  0  0  1  0  1  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0]]\n",
      "==============================================================================================================================\n",
      "[ 2 27  8  3  7 16  1  6  1 17 44  9  5 18  3  2]\n",
      "==============================================================================================================================\n",
      "\n",
      "==============================================================================================================================\n",
      "=============================== Sub Model below will be saved to be used for transfer learning  ==============================\n",
      "==============================================================================================================================\n",
      "\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 103, 24, 24, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_2 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 106,544\n",
      "Trainable params: 105,808\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "===============================================================================================================================\n",
      "======================================== Data with overlap ratio of 95% will be trained =======================================\n",
      "===============================================================================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3109, 103, 24, 24, 1) (785, 103, 24, 24, 1) (3109,) (785,)\n",
      "Total samples per class: [24, 668, 177, 45, 137, 365, 14, 141, 10, 408, 1067, 181, 101, 465, 46, 45], Total number of samples is 3894.\n",
      "\n",
      "unique classes in Ytest: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16], Total number of samples in Ytest is 785.\n",
      "number of samples per class in Ytest: [  5 134  36   9  28  73   3  29   2  82 214  37  21  93  10   9]\n",
      "\n",
      "Xtrain => (3109, 103, 24, 24, 1)\n",
      "Xtest  => (785, 103, 24, 24, 1)\n",
      "Ytrain => (3109, 16)\n",
      "Ytest  => (785, 16)\n",
      "\n",
      "Model: \"3D-SRNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 103, 24, 24, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_3 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fc_256 (Dense)                  (None, 256)          16640       global_max_pooling3d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fc16 (Dense)                    (None, 16)           4112        fc_256[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 127,296\n",
      "Trainable params: 126,560\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3109 samples, validate on 785 samples\n",
      "Epoch 1/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 4.9185 - categorical_accuracy: 0.4284\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.03822, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 15s 5ms/sample - loss: 4.9139 - categorical_accuracy: 0.4294 - val_loss: 5.4153 - val_categorical_accuracy: 0.0382\n",
      "Epoch 2/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 4.1447 - categorical_accuracy: 0.6185\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.03822 to 0.20255, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 4.1446 - categorical_accuracy: 0.6195 - val_loss: 5.3445 - val_categorical_accuracy: 0.2025\n",
      "Epoch 3/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 3.8131 - categorical_accuracy: 0.7209\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.20255 to 0.42930, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 3.8102 - categorical_accuracy: 0.7224 - val_loss: 4.4428 - val_categorical_accuracy: 0.4293\n",
      "Epoch 4/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 3.5809 - categorical_accuracy: 0.7921\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.42930\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 3.5797 - categorical_accuracy: 0.7925 - val_loss: 4.5956 - val_categorical_accuracy: 0.3898\n",
      "Epoch 5/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 3.3821 - categorical_accuracy: 0.8618\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.42930 to 0.60382, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 3.3830 - categorical_accuracy: 0.8614 - val_loss: 4.0446 - val_categorical_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 3.2463 - categorical_accuracy: 0.8938\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.60382\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 3.2448 - categorical_accuracy: 0.8942 - val_loss: 4.1381 - val_categorical_accuracy: 0.5554\n",
      "Epoch 7/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 3.1289 - categorical_accuracy: 0.9182\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.60382\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 3.1286 - categorical_accuracy: 0.9183 - val_loss: 4.0711 - val_categorical_accuracy: 0.5554\n",
      "Epoch 8/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 3.0444 - categorical_accuracy: 0.9359\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.60382\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 3.0433 - categorical_accuracy: 0.9363 - val_loss: 4.0345 - val_categorical_accuracy: 0.5197\n",
      "Epoch 9/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.9654 - categorical_accuracy: 0.9536\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.60382\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.9655 - categorical_accuracy: 0.9537 - val_loss: 4.3555 - val_categorical_accuracy: 0.5631\n",
      "Epoch 10/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.9005 - categorical_accuracy: 0.9678\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.60382\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.9009 - categorical_accuracy: 0.9675 - val_loss: 4.0362 - val_categorical_accuracy: 0.5516\n",
      "Epoch 11/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.8533 - categorical_accuracy: 0.9741\n",
      "Epoch 00011: val_categorical_accuracy improved from 0.60382 to 0.64076, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.8525 - categorical_accuracy: 0.9743 - val_loss: 3.7908 - val_categorical_accuracy: 0.6408\n",
      "Epoch 12/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.8058 - categorical_accuracy: 0.9815\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.64076 to 0.65860, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.8050 - categorical_accuracy: 0.9817 - val_loss: 3.7249 - val_categorical_accuracy: 0.6586\n",
      "Epoch 13/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.7638 - categorical_accuracy: 0.9813\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.65860\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.7637 - categorical_accuracy: 0.9813 - val_loss: 3.6723 - val_categorical_accuracy: 0.6522\n",
      "Epoch 14/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.7239 - categorical_accuracy: 0.9861\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.65860 to 0.71975, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.7234 - categorical_accuracy: 0.9862 - val_loss: 3.4437 - val_categorical_accuracy: 0.7197\n",
      "Epoch 15/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.6891 - categorical_accuracy: 0.9909\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.71975\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.6892 - categorical_accuracy: 0.9910 - val_loss: 3.6088 - val_categorical_accuracy: 0.6904\n",
      "Epoch 16/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.6596 - categorical_accuracy: 0.9910\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.71975\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.6596 - categorical_accuracy: 0.9910 - val_loss: 3.8613 - val_categorical_accuracy: 0.6038\n",
      "Epoch 17/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.6307 - categorical_accuracy: 0.9910\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.71975\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.6306 - categorical_accuracy: 0.9910 - val_loss: 3.6069 - val_categorical_accuracy: 0.6318\n",
      "Epoch 18/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.6040 - categorical_accuracy: 0.9938\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.71975\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.6041 - categorical_accuracy: 0.9939 - val_loss: 3.4813 - val_categorical_accuracy: 0.6968\n",
      "Epoch 19/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.5792 - categorical_accuracy: 0.9942\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.71975\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.5789 - categorical_accuracy: 0.9942 - val_loss: 3.4030 - val_categorical_accuracy: 0.7185\n",
      "Epoch 20/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.5562 - categorical_accuracy: 0.9942\n",
      "Epoch 00020: val_categorical_accuracy improved from 0.71975 to 0.72866, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.5558 - categorical_accuracy: 0.9942 - val_loss: 3.3565 - val_categorical_accuracy: 0.7287\n",
      "Epoch 21/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.5285 - categorical_accuracy: 0.9971\n",
      "Epoch 00021: val_categorical_accuracy improved from 0.72866 to 0.73631, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.5287 - categorical_accuracy: 0.9971 - val_loss: 3.4905 - val_categorical_accuracy: 0.7363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.5061 - categorical_accuracy: 0.9981\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.73631\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.5061 - categorical_accuracy: 0.9981 - val_loss: 3.4684 - val_categorical_accuracy: 0.6943\n",
      "Epoch 23/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.4820 - categorical_accuracy: 0.9981\n",
      "Epoch 00023: val_categorical_accuracy improved from 0.73631 to 0.73885, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.4819 - categorical_accuracy: 0.9981 - val_loss: 3.2130 - val_categorical_accuracy: 0.7389\n",
      "Epoch 24/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.4612 - categorical_accuracy: 0.9990 ETA: 0s - loss: 2.4614 - categorical_accuracy: \n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.73885\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.4613 - categorical_accuracy: 0.9990 - val_loss: 3.4639 - val_categorical_accuracy: 0.7096\n",
      "Epoch 25/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.4395 - categorical_accuracy: 0.9990\n",
      "Epoch 00025: val_categorical_accuracy improved from 0.73885 to 0.74013, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.4396 - categorical_accuracy: 0.9987 - val_loss: 3.2630 - val_categorical_accuracy: 0.7401\n",
      "Epoch 26/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.4203 - categorical_accuracy: 0.9984\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.74013\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.4203 - categorical_accuracy: 0.9984 - val_loss: 3.3100 - val_categorical_accuracy: 0.7121\n",
      "Epoch 27/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.4016 - categorical_accuracy: 0.9987\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.74013\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.4015 - categorical_accuracy: 0.9987 - val_loss: 3.1913 - val_categorical_accuracy: 0.7299\n",
      "Epoch 28/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 2.3785 - categorical_accuracy: 0.9993\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.74013\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.3784 - categorical_accuracy: 0.9994 - val_loss: 3.2526 - val_categorical_accuracy: 0.7032\n",
      "Epoch 29/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.3611 - categorical_accuracy: 0.9997\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.74013\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.3611 - categorical_accuracy: 0.9997 - val_loss: 3.1867 - val_categorical_accuracy: 0.7197\n",
      "Epoch 30/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.3416 - categorical_accuracy: 0.9997\n",
      "Epoch 00030: val_categorical_accuracy improved from 0.74013 to 0.76178, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.3416 - categorical_accuracy: 0.9997 - val_loss: 3.1039 - val_categorical_accuracy: 0.7618\n",
      "Epoch 31/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.3243 - categorical_accuracy: 0.9994\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.3241 - categorical_accuracy: 0.9994 - val_loss: 3.2444 - val_categorical_accuracy: 0.7261\n",
      "Epoch 32/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.3052 - categorical_accuracy: 0.9997\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.3052 - categorical_accuracy: 0.9997 - val_loss: 3.1044 - val_categorical_accuracy: 0.7605\n",
      "Epoch 33/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.2876 - categorical_accuracy: 0.9997\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.2876 - categorical_accuracy: 0.9997 - val_loss: 3.0140 - val_categorical_accuracy: 0.7567\n",
      "Epoch 34/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.2696 - categorical_accuracy: 0.9997\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.2694 - categorical_accuracy: 0.9997 - val_loss: 3.1096 - val_categorical_accuracy: 0.7503\n",
      "Epoch 35/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.2515 - categorical_accuracy: 0.9997\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.2514 - categorical_accuracy: 0.9997 - val_loss: 3.0611 - val_categorical_accuracy: 0.7452\n",
      "Epoch 36/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.2358 - categorical_accuracy: 1.0000\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.2357 - categorical_accuracy: 1.0000 - val_loss: 3.0552 - val_categorical_accuracy: 0.7389\n",
      "Epoch 37/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.2173 - categorical_accuracy: 0.9997\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.2172 - categorical_accuracy: 0.9997 - val_loss: 3.1102 - val_categorical_accuracy: 0.7529\n",
      "Epoch 38/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.2012 - categorical_accuracy: 1.0000\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.2012 - categorical_accuracy: 1.0000 - val_loss: 3.0010 - val_categorical_accuracy: 0.7248\n",
      "Epoch 39/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.1841 - categorical_accuracy: 0.9997\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.1841 - categorical_accuracy: 0.9997 - val_loss: 2.9937 - val_categorical_accuracy: 0.7350\n",
      "Epoch 40/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.1677 - categorical_accuracy: 1.0000\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.1676 - categorical_accuracy: 1.0000 - val_loss: 2.9253 - val_categorical_accuracy: 0.7529\n",
      "Epoch 41/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.1518 - categorical_accuracy: 1.0000\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.76178\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.1518 - categorical_accuracy: 1.0000 - val_loss: 2.9296 - val_categorical_accuracy: 0.7478\n",
      "Epoch 42/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.1357 - categorical_accuracy: 1.0000\n",
      "Epoch 00042: val_categorical_accuracy improved from 0.76178 to 0.76306, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.1356 - categorical_accuracy: 1.0000 - val_loss: 2.8954 - val_categorical_accuracy: 0.7631\n",
      "Epoch 43/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.1198 - categorical_accuracy: 1.0000\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.76306\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.1197 - categorical_accuracy: 1.0000 - val_loss: 3.0934 - val_categorical_accuracy: 0.7172\n",
      "Epoch 44/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.1036 - categorical_accuracy: 1.0000\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.76306\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.1035 - categorical_accuracy: 1.0000 - val_loss: 3.0390 - val_categorical_accuracy: 0.7401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.0880 - categorical_accuracy: 1.0000\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.76306\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.0880 - categorical_accuracy: 1.0000 - val_loss: 3.1233 - val_categorical_accuracy: 0.7172\n",
      "Epoch 46/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.0736 - categorical_accuracy: 1.0000\n",
      "Epoch 00046: val_categorical_accuracy improved from 0.76306 to 0.76433, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.0736 - categorical_accuracy: 1.0000 - val_loss: 2.8622 - val_categorical_accuracy: 0.7643\n",
      "Epoch 47/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.0578 - categorical_accuracy: 1.0000\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.76433\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.0578 - categorical_accuracy: 1.0000 - val_loss: 2.9131 - val_categorical_accuracy: 0.7478\n",
      "Epoch 48/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.0432 - categorical_accuracy: 1.0000\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.76433\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.0432 - categorical_accuracy: 1.0000 - val_loss: 2.8292 - val_categorical_accuracy: 0.7554\n",
      "Epoch 49/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 2.0287 - categorical_accuracy: 1.0000\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.76433\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.0287 - categorical_accuracy: 1.0000 - val_loss: 2.8548 - val_categorical_accuracy: 0.7363\n",
      "Epoch 50/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 2.0139 - categorical_accuracy: 1.0000\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.76433\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 2.0139 - categorical_accuracy: 1.0000 - val_loss: 2.8138 - val_categorical_accuracy: 0.7567\n",
      "Epoch 51/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.9991 - categorical_accuracy: 1.0000\n",
      "Epoch 00051: val_categorical_accuracy improved from 0.76433 to 0.76688, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.9991 - categorical_accuracy: 1.0000 - val_loss: 2.8256 - val_categorical_accuracy: 0.7669\n",
      "Epoch 52/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.9846 - categorical_accuracy: 1.0000\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.76688\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.9846 - categorical_accuracy: 1.0000 - val_loss: 2.7947 - val_categorical_accuracy: 0.7669\n",
      "Epoch 53/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.9713 - categorical_accuracy: 0.9997\n",
      "Epoch 00053: val_categorical_accuracy improved from 0.76688 to 0.76815, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.9713 - categorical_accuracy: 0.9997 - val_loss: 2.8155 - val_categorical_accuracy: 0.7682\n",
      "Epoch 54/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.9568 - categorical_accuracy: 1.0000\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.76815\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.9568 - categorical_accuracy: 1.0000 - val_loss: 2.8386 - val_categorical_accuracy: 0.7363\n",
      "Epoch 55/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.9423 - categorical_accuracy: 1.0000\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.76815\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.9423 - categorical_accuracy: 1.0000 - val_loss: 2.7806 - val_categorical_accuracy: 0.7452\n",
      "Epoch 56/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.9291 - categorical_accuracy: 1.0000\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.76815\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.9291 - categorical_accuracy: 1.0000 - val_loss: 2.7137 - val_categorical_accuracy: 0.7682\n",
      "Epoch 57/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.9148 - categorical_accuracy: 1.0000\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.76815\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.9147 - categorical_accuracy: 1.0000 - val_loss: 2.7261 - val_categorical_accuracy: 0.7554\n",
      "Epoch 58/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.9009 - categorical_accuracy: 1.0000\n",
      "Epoch 00058: val_categorical_accuracy improved from 0.76815 to 0.77452, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.9010 - categorical_accuracy: 1.0000 - val_loss: 2.6815 - val_categorical_accuracy: 0.7745\n",
      "Epoch 59/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.8886 - categorical_accuracy: 1.0000\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.77452\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.8886 - categorical_accuracy: 1.0000 - val_loss: 2.7713 - val_categorical_accuracy: 0.7478\n",
      "Epoch 60/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.8749 - categorical_accuracy: 1.0000\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.77452\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.8749 - categorical_accuracy: 1.0000 - val_loss: 2.6307 - val_categorical_accuracy: 0.7732\n",
      "Epoch 61/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.8611 - categorical_accuracy: 1.0000\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.77452\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.8611 - categorical_accuracy: 1.0000 - val_loss: 2.6814 - val_categorical_accuracy: 0.7541\n",
      "Epoch 62/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.8485 - categorical_accuracy: 1.0000\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.77452\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.8483 - categorical_accuracy: 1.0000 - val_loss: 2.6278 - val_categorical_accuracy: 0.7516\n",
      "Epoch 63/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.8352 - categorical_accuracy: 1.0000\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.77452\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.8352 - categorical_accuracy: 1.0000 - val_loss: 2.6279 - val_categorical_accuracy: 0.7694\n",
      "Epoch 64/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.8222 - categorical_accuracy: 1.0000\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.77452\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.8221 - categorical_accuracy: 1.0000 - val_loss: 2.6092 - val_categorical_accuracy: 0.7669\n",
      "Epoch 65/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.8098 - categorical_accuracy: 1.0000\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.77452\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.8099 - categorical_accuracy: 1.0000 - val_loss: 2.9091 - val_categorical_accuracy: 0.7146\n",
      "Epoch 66/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.7998 - categorical_accuracy: 0.9997\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.77452\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.7998 - categorical_accuracy: 0.9997 - val_loss: 2.5839 - val_categorical_accuracy: 0.7682\n",
      "Epoch 67/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.7848 - categorical_accuracy: 1.0000\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.77452\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.7848 - categorical_accuracy: 1.0000 - val_loss: 2.6953 - val_categorical_accuracy: 0.7439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.7721 - categorical_accuracy: 1.0000\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.77452\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.7720 - categorical_accuracy: 1.0000 - val_loss: 2.5459 - val_categorical_accuracy: 0.7707\n",
      "Epoch 69/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.7605 - categorical_accuracy: 1.0000\n",
      "Epoch 00069: val_categorical_accuracy improved from 0.77452 to 0.77962, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.7605 - categorical_accuracy: 1.0000 - val_loss: 2.5476 - val_categorical_accuracy: 0.7796\n",
      "Epoch 70/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.7477 - categorical_accuracy: 1.0000\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.7477 - categorical_accuracy: 1.0000 - val_loss: 2.4886 - val_categorical_accuracy: 0.7796\n",
      "Epoch 71/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.7358 - categorical_accuracy: 1.0000\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.7357 - categorical_accuracy: 1.0000 - val_loss: 2.5302 - val_categorical_accuracy: 0.7707\n",
      "Epoch 72/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.7240 - categorical_accuracy: 1.0000\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.7239 - categorical_accuracy: 1.0000 - val_loss: 2.5406 - val_categorical_accuracy: 0.7720\n",
      "Epoch 73/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.7119 - categorical_accuracy: 1.0000\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.7119 - categorical_accuracy: 1.0000 - val_loss: 2.5277 - val_categorical_accuracy: 0.7580\n",
      "Epoch 74/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.7005 - categorical_accuracy: 1.0000\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.7005 - categorical_accuracy: 1.0000 - val_loss: 2.5989 - val_categorical_accuracy: 0.7503\n",
      "Epoch 75/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.6885 - categorical_accuracy: 1.0000\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.6885 - categorical_accuracy: 1.0000 - val_loss: 2.4822 - val_categorical_accuracy: 0.7771\n",
      "Epoch 76/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.6770 - categorical_accuracy: 1.0000\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.6769 - categorical_accuracy: 1.0000 - val_loss: 2.4339 - val_categorical_accuracy: 0.7669\n",
      "Epoch 77/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.6657 - categorical_accuracy: 1.0000\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.6656 - categorical_accuracy: 1.0000 - val_loss: 2.4726 - val_categorical_accuracy: 0.7707\n",
      "Epoch 78/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.6545 - categorical_accuracy: 1.0000\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.6545 - categorical_accuracy: 1.0000 - val_loss: 2.4451 - val_categorical_accuracy: 0.7592\n",
      "Epoch 79/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.6432 - categorical_accuracy: 1.0000\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.6432 - categorical_accuracy: 1.0000 - val_loss: 2.4425 - val_categorical_accuracy: 0.7745\n",
      "Epoch 80/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.6325 - categorical_accuracy: 1.0000\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.6325 - categorical_accuracy: 1.0000 - val_loss: 2.4552 - val_categorical_accuracy: 0.7605\n",
      "Epoch 81/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.6210 - categorical_accuracy: 1.0000\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.6210 - categorical_accuracy: 1.0000 - val_loss: 2.4085 - val_categorical_accuracy: 0.7796\n",
      "Epoch 82/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.6100 - categorical_accuracy: 1.0000\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.6100 - categorical_accuracy: 1.0000 - val_loss: 2.4173 - val_categorical_accuracy: 0.7732\n",
      "Epoch 83/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.5990 - categorical_accuracy: 1.0000\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.5989 - categorical_accuracy: 1.0000 - val_loss: 2.4263 - val_categorical_accuracy: 0.7682\n",
      "Epoch 84/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.5885 - categorical_accuracy: 1.0000\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.5885 - categorical_accuracy: 1.0000 - val_loss: 2.4578 - val_categorical_accuracy: 0.7516\n",
      "Epoch 85/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.5776 - categorical_accuracy: 1.0000\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.5776 - categorical_accuracy: 1.0000 - val_loss: 2.3805 - val_categorical_accuracy: 0.7516\n",
      "Epoch 86/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.5676 - categorical_accuracy: 1.0000\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.5676 - categorical_accuracy: 1.0000 - val_loss: 2.3350 - val_categorical_accuracy: 0.7771\n",
      "Epoch 87/100\n",
      "3072/3109 [============================>.] - ETA: 0s - loss: 1.5567 - categorical_accuracy: 1.0000\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.5566 - categorical_accuracy: 1.0000 - val_loss: 2.3799 - val_categorical_accuracy: 0.7580\n",
      "Epoch 88/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.5462 - categorical_accuracy: 1.0000\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 7s 2ms/sample - loss: 1.5463 - categorical_accuracy: 1.0000 - val_loss: 2.3560 - val_categorical_accuracy: 0.7694\n",
      "Epoch 89/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.5361 - categorical_accuracy: 1.0000\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.5360 - categorical_accuracy: 1.0000 - val_loss: 2.3373 - val_categorical_accuracy: 0.7682\n",
      "Epoch 90/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.5259 - categorical_accuracy: 1.0000\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.5259 - categorical_accuracy: 1.0000 - val_loss: 2.2858 - val_categorical_accuracy: 0.7796\n",
      "Epoch 91/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.5182 - categorical_accuracy: 0.9994\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.5182 - categorical_accuracy: 0.9994 - val_loss: 2.4507 - val_categorical_accuracy: 0.7516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.5058 - categorical_accuracy: 1.0000\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.5057 - categorical_accuracy: 1.0000 - val_loss: 2.3339 - val_categorical_accuracy: 0.7656\n",
      "Epoch 93/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.4954 - categorical_accuracy: 1.0000\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.4954 - categorical_accuracy: 1.0000 - val_loss: 2.3676 - val_categorical_accuracy: 0.7694\n",
      "Epoch 94/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.4858 - categorical_accuracy: 1.0000\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.4858 - categorical_accuracy: 1.0000 - val_loss: 2.2892 - val_categorical_accuracy: 0.7707\n",
      "Epoch 95/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.4760 - categorical_accuracy: 1.0000\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.77962\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.4760 - categorical_accuracy: 1.0000 - val_loss: 2.2989 - val_categorical_accuracy: 0.7592\n",
      "Epoch 96/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.4661 - categorical_accuracy: 1.0000\n",
      "Epoch 00096: val_categorical_accuracy improved from 0.77962 to 0.78599, saving model to ..\\..\\Trained Models\\Full_Model\\Indian_Pines\\Full_Model_best_Indian_Pines_overlap_ratio_95_percent.h5\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.4661 - categorical_accuracy: 1.0000 - val_loss: 2.2384 - val_categorical_accuracy: 0.7860\n",
      "Epoch 97/100\n",
      "3088/3109 [============================>.] - ETA: 0s - loss: 1.4564 - categorical_accuracy: 1.0000\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.78599\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.4564 - categorical_accuracy: 1.0000 - val_loss: 2.3146 - val_categorical_accuracy: 0.7694\n",
      "Epoch 98/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.4473 - categorical_accuracy: 1.0000\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.78599\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.4473 - categorical_accuracy: 1.0000 - val_loss: 2.2555 - val_categorical_accuracy: 0.7732\n",
      "Epoch 99/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.4375 - categorical_accuracy: 1.0000\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.78599\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.4375 - categorical_accuracy: 1.0000 - val_loss: 2.2380 - val_categorical_accuracy: 0.7758\n",
      "Epoch 100/100\n",
      "3104/3109 [============================>.] - ETA: 0s - loss: 1.4283 - categorical_accuracy: 1.0000\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.78599\n",
      "3109/3109 [==============================] - 6s 2ms/sample - loss: 1.4283 - categorical_accuracy: 1.0000 - val_loss: 2.2984 - val_categorical_accuracy: 0.7707\n",
      "785/785 [==============================] - 0s 484us/sample - loss: 2.2984 - categorical_accuracy: 0.7707\n",
      "Test Accuracy = 0.77070063\n",
      "785/785 [==============================] - 1s 828us/sample\n",
      "\n",
      "===============================================================================================================================\n",
      "=============================== Confusion_matrix for data with overlap ratio of 95% is as below ===============================\n",
      "===============================================================================================================================\n",
      "\n",
      "[[  5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  82   0   0   4   3   0   4   2   1  38   0   0   0   0   0]\n",
      " [  0   2  16   0   0   0   0   0   0   0  18   0   0   0   0   0]\n",
      " [  0   0   0   8   0   0   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   1   0  14   7   0   1   0   0   0   0   5   0   0   0]\n",
      " [  0   0   0   0   1  68   0   0   0   0   0   0   0   4   0   0]\n",
      " [  0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  22   0   1   0   0   0   0   0  51   8   0   0   0   0   0]\n",
      " [  0   0   0   0   5   2   0   0   0   0 202   0   5   0   0   0]\n",
      " [  0  15   2   1   0   0   0   0   0  10   7   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0  20   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  93   0   0]\n",
      " [  0   4   1   0   0   0   0   0   0   0   0   0   0   0   5   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9]]\n",
      "==============================================================================================================================\n",
      "[  5 134  36   9  28  73   3  29   2  82 214  37  21  93  10   9]\n",
      "==============================================================================================================================\n",
      "\n",
      "==============================================================================================================================\n",
      "=============================== Sub Model below will be saved to be used for transfer learning  ==============================\n",
      "==============================================================================================================================\n",
      "\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 103, 24, 24, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_3 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 106,544\n",
      "Trainable params: 105,808\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Acc_Table = Train(overlap_ratio_List = [50, 75, 85, 95],\n",
    "                  range_of_class = range_of_class,\n",
    "                  Cube_size= 25,\n",
    "                  Data = data_IN,\n",
    "                  Gt = gt_IN,\n",
    "                  Train_Test_split = 80,\n",
    "                  channel = 103,\n",
    "                  epochs_list = [100, 100, 100, 100],\n",
    "                  batch_size_list = [2, 4, 8, 16],\n",
    "                  data_name = 'Indian_Pines',\n",
    "                  Verbosity  = 1,\n",
    "                  LR = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test Accuracy Table</td>\n",
       "      <td>Indian_Pines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data_Overlap_50</td>\n",
       "      <td>40.9091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data_Overlap_75</td>\n",
       "      <td>63.9344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data_Overlap_85</td>\n",
       "      <td>60.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data_Overlap_95</td>\n",
       "      <td>77.0701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0             1\n",
       "0  Test Accuracy Table  Indian_Pines\n",
       "1      Data_Overlap_50       40.9091\n",
       "2      Data_Overlap_75       63.9344\n",
       "3      Data_Overlap_85        60.355\n",
       "4      Data_Overlap_95       77.0701"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acc_Table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
